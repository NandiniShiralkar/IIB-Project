{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct fit SSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from GSM._imports import *\n",
    "from GSM.fogsm import FoGSMModel\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSN._imports import *\n",
    "from SSN.ssn_2dtopoV1 import SSN2DTopoV1\n",
    "from SSN.params import GridParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSNBase(torch.nn.Module):\n",
    "    def __init__(self, n, k, Ne, Ni, tau_e, tau_i, device='cpu', dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.N = self.Ne + self.Ni\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.register_buffer('EI', torch.cat([torch.ones(Ne), torch.zeros(Ni)]).to(device).bool())\n",
    "        self.register_buffer('tau_vec', torch.cat([tau_e * torch.ones(Ne), tau_i * torch.ones(Ni)]).to(device, dtype))\n",
    "        self.W = torch.nn.Parameter(torch.zeros((self.N, self.N), device=device, dtype=dtype))\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def drdt(self, r, inp_vec):\n",
    "        return (-r + self.powlaw(self.W @ r + inp_vec)) / self.tau_vec\n",
    "    \n",
    "    def powlaw(self, u):\n",
    "        return self.k * F.relu(u).pow(self.n)\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def simulate(self, inp_vec, r_init=None, duration=100, dt=0.1):\n",
    "        if r_init is None:\n",
    "            r_init = torch.zeros((self.N,), device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        r = r_init\n",
    "        t = 0\n",
    "        while t < duration:\n",
    "            dr = self.drdt(r, inp_vec)\n",
    "            r += dt * dr\n",
    "            t += dt\n",
    "        return r\n",
    "    \n",
    "    def jacobian(self, r):\n",
    "        Phi = self.gains_from_r(r)\n",
    "        return -torch.eye(self.N, device=self.device, dtype=self.dtype) + Phi[:, None] * self.W\n",
    "    \n",
    "    def gains_from_r(self, r):\n",
    "        return self.n * self.k**(1/self.n) * r.pow(1 - 1/self.n)\n",
    "    \n",
    "    def fixed_point(self, inp_vec, tol=1e-6, max_iter=1000):\n",
    "        r = torch.zeros((self.N,), device=self.device, dtype=self.dtype)\n",
    "        for _ in range(max_iter):\n",
    "            dr = self.drdt(r, inp_vec)\n",
    "            r_new = r + dr\n",
    "            if torch.norm(r_new - r) < tol:\n",
    "                return r_new\n",
    "            r = r_new\n",
    "        raise RuntimeError(f\"Fixed point not found after {max_iter} iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSN2DTopo(SSNBase):\n",
    "    def __init__(self, n, k, tauE, tauI, grid_pars, conn_pars, thetas, device='cpu', dtype=torch.float64):\n",
    "        num_orientations = thetas.shape[0]\n",
    "        grid_size = grid_pars['grid_size_Nx']\n",
    "        \n",
    "        Ne = num_orientations * (grid_size ** 2)\n",
    "        Ni = num_orientations * (grid_size ** 2)\n",
    "\n",
    "        super(SSN2DTopo, self).__init__(n=n, k=k, Ne=Ne, Ni=Ni, tau_e=tauE, tau_i=tauI, device=device, dtype=dtype)\n",
    "        \n",
    "        self.num_orientations = num_orientations\n",
    "        self.grid_size = grid_size\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self._make_maps(thetas)\n",
    "        \n",
    "        self.J_2x2 = nn.Parameter(torch.rand(2, 2, device=device, dtype=dtype))\n",
    "        self.s_2x2 = nn.Parameter(torch.rand(2, 2, device=device, dtype=dtype))\n",
    "        self.p_local = nn.Parameter(torch.rand(2, device=device, dtype=dtype))\n",
    "        self.sigma_oris = nn.Parameter(torch.rand(1, device=device, dtype=dtype))\n",
    "        \n",
    "        self.make_W()\n",
    "\n",
    "    def _make_maps(self,thetas):\n",
    "        \n",
    "        self.ori_map = torch.tensor(thetas, device=self.device, dtype=self.dtype).flatten()\n",
    "        self.ori_vec = self.ori_map.repeat(self.grid_size ** 2)\n",
    "        self.ori_vec = self.ori_vec.repeat(2)\n",
    "\n",
    "        self.x_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations).repeat(self.grid_size)\n",
    "        self.y_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations * self.grid_size)\n",
    "\n",
    "        self.x_vec = self.x_vec.repeat(2)\n",
    "        self.y_vec = self.y_vec.repeat(2)\n",
    "\n",
    "    def make_W(self):\n",
    "        \n",
    "        xy_dist = self.calc_xy_dist()\n",
    "        ori_dist = self.calc_ori_dist()\n",
    "        \n",
    "        W_ee = self.calc_W_block(xy_dist[:self.Ne, :self.Ne], ori_dist[:self.Ne, :self.Ne], self.s_2x2[0, 0], self.sigma_oris)\n",
    "        W_ei = self.calc_W_block(xy_dist[:self.Ne, self.Ne:], ori_dist[:self.Ne, self.Ne:], self.s_2x2[0, 1], self.sigma_oris)\n",
    "        W_ie = self.calc_W_block(xy_dist[self.Ne:, :self.Ne], ori_dist[self.Ne:, :self.Ne], self.s_2x2[1, 0], self.sigma_oris)\n",
    "        W_ii = self.calc_W_block(xy_dist[self.Ne:, self.Ne:], ori_dist[self.Ne:, self.Ne:], self.s_2x2[1, 1], self.sigma_oris)\n",
    "        \n",
    "        W_ee = self.p_local[0] * torch.eye(self.Ne, device=self.device, dtype=self.dtype) + (1 - self.p_local[0]) * W_ee\n",
    "        W_ei = self.p_local[1] * torch.eye(self.Ni, device=self.device, dtype=self.dtype) + (1 - self.p_local[1]) * W_ei\n",
    "        \n",
    "        self.W = nn.Parameter(torch.cat([\n",
    "            torch.cat([self.J_2x2[0, 0] * W_ee, self.J_2x2[0, 1] * W_ei], dim=1),\n",
    "            torch.cat([self.J_2x2[1, 0] * W_ie, self.J_2x2[1, 1] * W_ii], dim=1)\n",
    "        ], dim=0).double())\n",
    "        \n",
    "        return self.W\n",
    "    \n",
    "    def calc_xy_dist(self):\n",
    "        Ne = Ni = self.Ne\n",
    "        x_vec_e = self.x_vec[:Ne]\n",
    "        y_vec_e = self.y_vec[:Ne]\n",
    "        x_vec_i = self.x_vec[Ne:Ne+Ni]\n",
    "        y_vec_i = self.y_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        xy_dist = torch.cdist(torch.stack([x_vec_e, y_vec_e], dim=1), torch.stack([x_vec_i, y_vec_i], dim=1), p=2).repeat(2, 2) #Distance Squared\n",
    "\n",
    "        return xy_dist\n",
    "    \n",
    "    def calc_ori_dist(self,L=np.pi, method=\"absolute\"):\n",
    "\n",
    "        Ne = Ni = self.num_orientations * self.grid_size ** 2\n",
    "        \n",
    "        ori_vec_e = self.ori_vec[:Ne]\n",
    "        ori_vec_i = self.ori_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        if method == \"absolute\":\n",
    "            ori_dist = torch.cdist(ori_vec_e.unsqueeze(1), ori_vec_i.unsqueeze(1)).repeat(2,2)\n",
    "        elif method == \"cos\":\n",
    "            ori_vec_e_norm = ori_vec_e / ori_vec_e.norm(dim=1, keepdim=True)\n",
    "            ori_vec_i_norm = ori_vec_i / ori_vec_i.norm(dim=1, keepdim=True)\n",
    "            ori_dist = 1 - torch.mm(ori_vec_e_norm, ori_vec_i_norm.t())\n",
    "            ori_dist = ori_dist.repeat(2, 2)\n",
    "        else:\n",
    "            #1 - cos(2(pi/L) * |theta1 - theta2|)\n",
    "            ori_dist = 1 - torch.cos((2 * np.pi / L) * torch.abs(ori_vec_e.unsqueeze(1) - ori_vec_i.unsqueeze(1)))\n",
    "            ori_dist = ori_dist.repeat(2, 2)\n",
    "\n",
    "        return ori_dist\n",
    "\n",
    "    def calc_W_block(self, xy_dist, ori_dist, s, sigma_oris,CellWiseNormalised = True):\n",
    "\n",
    "        #Add a small constant to s and sigma_oris to avoid division by zero\n",
    "        s = s + 1e-8\n",
    "        sigma_oris = sigma_oris + 1e-8\n",
    "\n",
    "        W =  torch.exp(-xy_dist / s - ori_dist ** 2 / (2 * sigma_oris ** 2))\n",
    "        W = torch.where(W < 1e-4, torch.zeros_like(W), W)\n",
    "        \n",
    "        sW = torch.sum(W, dim=1, keepdim=True)\n",
    "        if CellWiseNormalised:\n",
    "            W = W / sW[:, None]\n",
    "        else:\n",
    "            sW = sW.mean()\n",
    "            W = W / sW\n",
    "            \n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        super(DirectFit, self).__init__()\n",
    "        self.ssn_model = SSN2DTopo(**ssn_params)\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "    def sample_trajectories(self, input_batch, num_samples_g, duration=500, dt=1):\n",
    "        batch_size = input_batch.shape[0]\n",
    "\n",
    "        # Expand input_batch to match the number of samples\n",
    "        input_expanded = input_batch.unsqueeze(1).expand(batch_size, num_samples_g, *input_batch.shape[1:])\n",
    "        print(\"Input expanded shape: \", input_expanded.shape)\n",
    "\n",
    "        # Reshape input_expanded to (batch_size * num_samples, input_size)\n",
    "        input_reshaped = input_expanded.reshape(-1, *input_batch.shape[1:])\n",
    "\n",
    "        # Generate trajectories for the reshaped input\n",
    "        trajectories = self.ssn_model.simulate(input_reshaped, duration, dt)\n",
    "\n",
    "        # Reshape trajectories to (batch_size, num_samples, N)\n",
    "        trajectories = trajectories.reshape(batch_size, num_samples_g)\n",
    "\n",
    "        return trajectories\n",
    "\n",
    "    def calculate_log_p_g(self, trajectories):\n",
    "        mu = torch.zeros_like(trajectories[0])\n",
    "        log_p_g = MultivariateNormal(mu, self.fogsm_model.K_g).log_prob(trajectories).mean()\n",
    "        return log_p_g\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, trajectories, A_samples):\n",
    "        \n",
    "        # Calculate log p(I|g,A) for each sample\n",
    "        log_likelihood = []\n",
    "        for a in A_samples:\n",
    "            log_p = 0\n",
    "            for g in trajectories:\n",
    "                I = g * a\n",
    "                log_p += self.fogsm_model.log_likelihood(I)\n",
    "            log_likelihood.append(log_p / len(trajectories))\n",
    "        \n",
    "        # Approximate the expectation over A using Monte Carlo sampling\n",
    "        p_I_given_g = torch.exp(torch.stack(log_likelihood)).mean()\n",
    "        log_p_I_given_g = torch.log(p_I_given_g)\n",
    "\n",
    "        return log_p_I_given_g\n",
    "\n",
    "    def calculate_elbo(self, input_batch, num_samples_g, A_samples, duration=500, dt=1):\n",
    "\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories = self.sample_trajectories(input_batch, num_samples_g, duration, dt)\n",
    "\n",
    "        # Calculate the first two terms of the ELBO using Monte Carlo approximation\n",
    "        log_p_g = self.calculate_log_p_g(trajectories)\n",
    "        log_p_I_given_g = self.calculate_log_p_I_given_g(trajectories, A_samples)\n",
    "\n",
    "        # Approximate the entropy term\n",
    "        # cov_matrix = torch.cov(trajectories.reshape(num_samples_g, -1).T)\n",
    "\n",
    "        cov_matrix = torch.cov(trajectories.reshape(trajectories.shape[0], -1))\n",
    "        entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "\n",
    "        elbo = log_p_g + log_p_I_given_g - entropy_term\n",
    "\n",
    "        return elbo\n",
    "    \n",
    "    def optimise_elbo(self, batch_size, num_samples_a, num_samples_g, convergence_threshold=1e-3, optimizer=Adam):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.ssn_model.to(device)\n",
    "        self.fogsm_model.to(device)\n",
    "\n",
    "        batch = 0\n",
    "        prev_elbo = float('-inf')\n",
    "\n",
    "        while True:\n",
    "            elbo_batch = 0\n",
    "\n",
    "            # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "            A_samples = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "\n",
    "            # Generate a mini-batch of input data\n",
    "            input_batch = self.fogsm_model.generate_fogsm_dataset(batch_size)\n",
    "\n",
    "            # Calculate the ELBO for the mini-batch\n",
    "            elbo_batch = self.calculate_elbo(input_batch, num_samples_g, A_samples)\n",
    "            elbo += elbo_batch.item()\n",
    "\n",
    "            # Optimise the ELBO with respect to the model parameters\n",
    "            elbo.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Print the ELBO for monitoring\n",
    "            if (batch + 1) % 100 == 0:\n",
    "                print(f\"Batch [{batch+1}], ELBO: {elbo_batch / batch_size:.4f}\")\n",
    "\n",
    "            # Check for convergence\n",
    "            if abs(elbo_batch - prev_elbo) < convergence_threshold:\n",
    "                print(f\"Converged after {batch+1} batches.\")\n",
    "                break\n",
    "\n",
    "            prev_elbo = elbo_batch\n",
    "            batch += 1\n",
    "        \n",
    "        return self.ssn_model, self.fogsm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khushu/Desktop/IIB_Project FoGSM 2dSSN/GSM/fogsm.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1)\n",
      "/Users/khushu/Desktop/IIB_Project FoGSM 2dSSN/GSM/fogsm.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the parameters for the FoGSM model\n",
    "thetas = torch.linspace(0, 2 * torch.pi, 8)  # 8 orientations from 0 to 2*pi\n",
    "fogsm_params = {\n",
    "        \"thetas\": thetas,\n",
    "        \"length_scale_feature\": 0.5,\n",
    "        \"length_scale_amplitude\": 1.2,\n",
    "        \"kappa\": 1.0,\n",
    "        \"jitter\": 1e-4,\n",
    "        \"grid_size\": 3,\n",
    "        \"frequency\": 0.9,\n",
    "        \"sigma\": 0.1,\n",
    "    }\n",
    "fogsm_model = FoGSMModel(**fogsm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set network parameters\n",
    "n = 2\n",
    "k = 0.4\n",
    "tauE = 20.0\n",
    "tauI = 10.0\n",
    "grid_pars = {'grid_size_Nx': 3}\n",
    "conn_pars = {'num_orientations': 8}\n",
    "thetas = np.linspace(0, np.pi, conn_pars['num_orientations'])\n",
    "\n",
    "ssn_params = {\n",
    "        \"n\": 2,\n",
    "        \"k\": 0.04,\n",
    "        \"tauE\": 20,\n",
    "        \"tauI\": 10,\n",
    "        \"grid_pars\": grid_pars,\n",
    "        \"conn_pars\": conn_pars,\n",
    "        \"thetas\": thetas,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input expanded shape:  torch.Size([32, 100, 3, 3])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ScriptMethodStub' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run the ELBO optimisation\u001b[39;00m\n\u001b[1;32m      7\u001b[0m input_data, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfogsm_dataset.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdirect_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimise_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimiser\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 85\u001b[0m, in \u001b[0;36mDirectFit.optimise_elbo\u001b[0;34m(self, batch_size, num_samples_a, num_samples_g, convergence_threshold, optimizer)\u001b[0m\n\u001b[1;32m     82\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfogsm_model\u001b[38;5;241m.\u001b[39mgenerate_fogsm_dataset(batch_size)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Calculate the ELBO for the mini-batch\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m elbo_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m elbo \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m elbo_batch\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Optimise the ELBO with respect to the model parameters\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 51\u001b[0m, in \u001b[0;36mDirectFit.calculate_elbo\u001b[0;34m(self, input_batch, num_samples_g, A_samples, duration, dt)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_elbo\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_batch, num_samples_g, A_samples, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Sample trajectories from the SSN\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     trajectories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Calculate the first two terms of the ELBO using Monte Carlo approximation\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     log_p_g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_log_p_g(trajectories)\n",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36mDirectFit.sample_trajectories\u001b[0;34m(self, input_batch, num_samples_g, duration, dt)\u001b[0m\n\u001b[1;32m     16\u001b[0m input_reshaped \u001b[38;5;241m=\u001b[39m input_expanded\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39minput_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Generate trajectories for the reshaped input\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Reshape trajectories to (batch_size, num_samples, N)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m trajectories\u001b[38;5;241m.\u001b[39mreshape(batch_size, num_samples_g)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ScriptMethodStub' object is not callable"
     ]
    }
   ],
   "source": [
    "direct_fit = DirectFit(ssn_params, fogsm_params)\n",
    "\n",
    "# Create an optimiser for the ELBO\n",
    "optimiser = Adam(list(direct_fit.ssn_model.parameters()), lr=0.001)\n",
    "\n",
    "# Run the ELBO optimisation\n",
    "input_data, _ = torch.load(\"fogsm_dataset.pt\")\n",
    "direct_fit.optimise_elbo(batch_size=32, num_samples_a=10, num_samples_g=100, optimizer=optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khushu/opt/anaconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1695391836761/work/aten/src/ATen/native/TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/Users/khushu/Desktop/IIB_Project FoGSM 2dSSN/GSM/fogsm.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1)\n",
      "/Users/khushu/Desktop/IIB_Project FoGSM 2dSSN/GSM/fogsm.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSN2DTopoV1.__init__\n",
      "grid_pars:  <SSN.params.GridParameters object at 0x7f9af186e3d0>\n",
      "conn_pars:  {'J_2x2': tensor([[ 2.7331, -2.2638],\n",
      "        [ 2.5507, -1.3058]], dtype=torch.float64), 's_2x2': tensor([[0.2955, 0.0900],\n",
      "        [0.5542, 0.0900]]), 'p_local': [0.72, 0.7], 'sigma_oris': 45}\n",
      "Making W\n",
      "W made\n",
      "SSN2DTopoV1.__init__ done\n",
      "Input expanded shape:  torch.Size([32, 100, 3, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (578) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Run the ELBO optimisation\u001b[39;00m\n\u001b[1;32m     46\u001b[0m input_data, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfogsm_dataset.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mdirect_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimise_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimiser\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 85\u001b[0m, in \u001b[0;36mDirectFit.optimise_elbo\u001b[0;34m(self, batch_size, num_samples_a, num_samples_g, convergence_threshold, optimizer)\u001b[0m\n\u001b[1;32m     82\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfogsm_model\u001b[38;5;241m.\u001b[39mgenerate_fogsm_dataset(batch_size)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Calculate the ELBO for the mini-batch\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m elbo_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m elbo \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m elbo_batch\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Optimise the ELBO with respect to the model parameters\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m, in \u001b[0;36mDirectFit.calculate_elbo\u001b[0;34m(self, input_batch, num_samples_g, A_samples, duration, dt)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_elbo\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_batch, num_samples_g, A_samples, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Sample trajectories from the SSN\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     trajectories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Calculate the first two terms of the ELBO using Monte Carlo approximation\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     log_p_g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_log_p_g(trajectories)\n",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m, in \u001b[0;36mDirectFit.sample_trajectories\u001b[0;34m(self, input_batch, num_samples_g, duration, dt)\u001b[0m\n\u001b[1;32m     16\u001b[0m input_reshaped \u001b[38;5;241m=\u001b[39m input_expanded\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39minput_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Generate trajectories for the reshaped input\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Reshape trajectories to (batch_size, num_samples, N)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m trajectories\u001b[38;5;241m.\u001b[39mreshape(batch_size, num_samples_g)\n",
      "File \u001b[0;32m~/Desktop/IIB_Project FoGSM 2dSSN/SSN/ssn_2dtopoV1.py:415\u001b[0m, in \u001b[0;36mSSN2DTopoV1.run_simulation\u001b[0;34m(self, input_batch, duration, dt, multiplier)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# Loop over time steps\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(duration):\n\u001b[1;32m    413\u001b[0m \n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Euler integration \u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m     r \u001b[38;5;241m=\u001b[39m r \u001b[38;5;241m+\u001b[39m dt\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrdt_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# Store rates\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     rates[:,t] \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/Desktop/IIB_Project FoGSM 2dSSN/SSN/ssn_base.py:47\u001b[0m, in \u001b[0;36m_SSN_Base.drdt_multi\u001b[0;34m(self, r, inp_vec)\u001b[0m\n\u001b[1;32m     44\u001b[0m Wr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW, r_expanded)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Add the input vector to the result\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m Wr_plus_inp \u001b[38;5;241m=\u001b[39m \u001b[43mWr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minp_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Apply the power law function\u001b[39;00m\n\u001b[1;32m     50\u001b[0m pow_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpowlaw(Wr_plus_inp)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (578) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "#SSN2DTopoV1\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "# Define the parameters for the SSN model\n",
    "grid_pars = GridParameters(\n",
    "    gridsize_Nx=17,  # Number of grid points in one dimension\n",
    "    gridsize_deg=3.2,  # Size of the grid in degrees of visual angle\n",
    "    magnif_factor=2,  # Magnification factor to convert degrees to mm\n",
    "    hyper_col=800,  # Hypercolumn\n",
    "    )\n",
    "psi = torch.tensor(0.774)\n",
    "conn_pars = {\n",
    "        'J_2x2': torch.tensor([[1.124, -0.931], [1.049, -0.537]], dtype=torch.float64) * torch.pi * psi,\n",
    "        's_2x2': torch.tensor([[0.2955, 0.09], [0.5542, 0.09]]),\n",
    "        'p_local': [0.72, 0.7],\n",
    "        'sigma_oris': 45,\n",
    "    }\n",
    "ssn_params = {\n",
    "        \"n\": 2,\n",
    "        \"k\": 0.04,\n",
    "        \"tauE\": 20,\n",
    "        \"tauI\": 10,\n",
    "        \"grid_pars\": grid_pars,\n",
    "        \"conn_pars\": conn_pars,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbatched DirectFit archived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        self.ssn_model = SSN2DTopoV1(**ssn_params)\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "    def sample_trajectories(self, input, num_samples, duration=500, dt=1):\n",
    "        trajectories = []\n",
    "        for _ in range(num_samples):\n",
    "            traj = self.ssn_model.run_simulation(input, duration, dt)\n",
    "            trajectories.append(traj)\n",
    "        return torch.stack(trajectories)\n",
    "\n",
    "    def calculate_log_p_g(self, trajectories):\n",
    "        mu = torch.zeros_like(trajectories[0])\n",
    "        log_p_g = MultivariateNormal(mu, self.fogsm_model.K_g).log_prob(trajectories).mean()\n",
    "        return log_p_g\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, trajectories, num_samples_a=10):\n",
    "        # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "        amplitude_fields = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "        \n",
    "        # Calculate log p(I|g,A) for each sample\n",
    "        log_likelihood = []\n",
    "        for a in amplitude_fields:\n",
    "            log_p = 0\n",
    "            for g in trajectories:\n",
    "                I = g * a\n",
    "                log_p += self.fogsm_model.log_likelihood(I)\n",
    "            log_likelihood.append(log_p / len(trajectories))\n",
    "        \n",
    "        # Approximate the expectation over A using Monte Carlo sampling\n",
    "        p_I_given_g = torch.exp(torch.stack(log_likelihood)).mean()\n",
    "        log_p_I_given_g = torch.log(p_I_given_g)\n",
    "\n",
    "        return log_p_I_given_g\n",
    "\n",
    "    def calculate_elbo(self, input, num_samples, duration=500, dt=1):\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories = self.sample_trajectories(input, num_samples, duration, dt)\n",
    "        \n",
    "        # Calculate the first two terms of the ELBO using Monte Carlo approximation\n",
    "        log_p_g = self.calculate_log_p_g(trajectories)\n",
    "        log_p_I_given_g = self.calculate_log_p_I_given_g(trajectories)\n",
    "        \n",
    "        # Approximate the entropy term\n",
    "        cov_matrix = torch.cov(trajectories.reshape(num_samples, -1).T)\n",
    "        entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "        \n",
    "        elbo = log_p_g + log_p_I_given_g - entropy_term\n",
    "        return elbo\n",
    "\n",
    "    def optimise_elbo(self, input, num_samples, num_epochs, optimizer):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Calculate the ELBO\n",
    "            elbo = self.calculate_elbo(input, num_samples)\n",
    "            \n",
    "            #resample As for each minibatch\n",
    "\n",
    "            # Optimise the ELBO with respect to the model parameters\n",
    "            elbo.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Print the ELBO for monitoring\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], ELBO: {elbo.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
