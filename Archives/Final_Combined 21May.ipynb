{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fd3e1785d30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GSM._imports import *\n",
    "from torch.optim import Adam\n",
    "from SSN._imports import *\n",
    "from SSN.params import GridParameters\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FoGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoGSMModel(nn.Module):\n",
    "    def __init__(self,thetas=None, length_scale_feature=1.0, length_scale_amplitude=1.2, kappa=1.0, jitter=1e-5, grid_size=10, frequency=1.0,sigma=0.1):\n",
    "        super(FoGSMModel, self).__init__()\n",
    "\n",
    "        self.dtype = torch.float64\n",
    "\n",
    "        self.length_scale_feature = Parameter(torch.tensor(length_scale_feature, dtype=self.dtype))\n",
    "        self.length_scale_amplitude = Parameter(torch.tensor(length_scale_amplitude, dtype=self.dtype))\n",
    "        self.kappa = Parameter(torch.tensor(kappa, dtype=self.dtype))\n",
    "        self.frequency = Parameter(torch.tensor(frequency, dtype=self.dtype)) \n",
    "        self.sigma = Parameter(torch.tensor(sigma))\n",
    "\n",
    "        if thetas is None:\n",
    "            thetas = torch.linspace(0, 2 * np.pi, 8)  # 8 orientations from 0 to 2*pi\n",
    "        self.thetas = thetas\n",
    "\n",
    "        self.jitter = jitter\n",
    "        self.grid_size = grid_size\n",
    "        self.grid = torch.stack(torch.meshgrid(torch.linspace(-5, 5, grid_size), \n",
    "                                               torch.linspace(-5, 5, grid_size)), \n",
    "                                dim=-1).reshape(-1, 2)\n",
    "        \n",
    "        self.K_g = self.generate_K_g()\n",
    "        \n",
    "    def von_mises_kernel(self, theta1, theta2):\n",
    "        theta_diff = theta1 - theta2  \n",
    "        return torch.clamp(torch.exp(self.kappa * torch.cos(theta_diff)), min=1e-6)\n",
    "    \n",
    "    def squared_exponential_kernel(self, x1, x2, length_scale,jitter=\"True\"):\n",
    "        x1 = x1.unsqueeze(1) # Shape: [N, 1, 2]\n",
    "        x2 = x2.unsqueeze(0) # Shape: [1, N, 2]\n",
    "        sq_dist = torch.sum((x1 - x2) ** 2, dim=2) # Shape: [N, N]\n",
    "\n",
    "        exp_term = torch.exp(-sq_dist / (2*length_scale**2))\n",
    "\n",
    "        if jitter:\n",
    "            return exp_term + self.jitter * torch.eye(x1.size(0))\n",
    "        else:\n",
    "            return exp_term\n",
    "\n",
    "    def composite_feature_kernel(self, theta1, theta2):\n",
    "         \n",
    "        sq_exp_component = self.squared_exponential_kernel(self.grid, self.grid, self.length_scale_feature,jitter=\"False\")        \n",
    "        \n",
    "        # Ensure theta1 and theta2 are tensors\n",
    "        theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
    "        theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n",
    "\n",
    "        x1 = self.grid.unsqueeze(1) # Shape: [N, 1, 2]\n",
    "        x2 = self.grid.unsqueeze(0) # Shape: [1, N, 2]\n",
    "\n",
    "        n1 = torch.tensor([torch.cos(theta1), torch.sin(theta1)]).view(1, 1, 2)  # Shape: [1, 1, 2]\n",
    "        n2 = torch.tensor([torch.cos(theta2), torch.sin(theta2)]).view(1, 1, 2)  # Shape: [1, 1, 2]\n",
    "        average_orientation = (n1 + n2) / 2\n",
    "\n",
    "        # Broadcasting average_orientation for dot product computation\n",
    "        average_orientation = average_orientation.repeat(x1.size(0), x1.size(1), 1)\n",
    "        dot_product = torch.sum((x1 - x2) * average_orientation, dim=2)\n",
    "        periodic_component = torch.cos(2 * torch.pi * self.frequency * dot_product)\n",
    "\n",
    "        # Composite Kernel\n",
    "        return sq_exp_component * periodic_component\n",
    "\n",
    "    def generate_K_g(self):\n",
    "        \n",
    "        theta1_grid, theta2_grid = torch.meshgrid(self.thetas, self.thetas)\n",
    "        ori_kernel_val = self.von_mises_kernel(theta1_grid, theta2_grid)\n",
    "    \n",
    "        # Spatial kernel\n",
    "        loc_kernel_val = torch.zeros((len(self.thetas), len(self.thetas), self.grid_size**2, self.grid_size**2))\n",
    "\n",
    "        for i in range(len(self.thetas)):\n",
    "            for j in range(len(self.thetas)):\n",
    "                loc_kernel_val[i,j] = self.composite_feature_kernel(self.thetas[i], self.thetas[j])\n",
    "        \n",
    "        #print(\"LOC \",loc_kernel_val.size())\n",
    "        K_spatial = torch.sum(loc_kernel_val, dim=[0, 1])\n",
    "        #print(\"K_spatial \",K_spatial.size())\n",
    "        K_g = torch.kron(K_spatial, ori_kernel_val)\n",
    "        \n",
    "        #K_g = ori_kernel_val.unsqueeze(-1).unsqueeze(-1) * loc_kernel_val\n",
    "        #K_g = K_g.transpose(0, 2).transpose(1, 3).reshape((len(self.thetas) * self.grid_size**2, len(self.thetas) * self.grid_size**2))\n",
    "        \n",
    "        K_g = K_g + self.jitter * torch.eye(len(self.thetas)*self.grid_size**2)\n",
    "        return K_g\n",
    "\n",
    "    def compute_A(self):\n",
    "        kernel_vals = self.squared_exponential_kernel(self.grid, self.grid, self.length_scale_amplitude)\n",
    "        return torch.sqrt(torch.exp(MultivariateNormal(torch.zeros(self.grid.size(0)), kernel_vals).sample()))\n",
    "\n",
    "    def samples(self):\n",
    "\n",
    "        g = MultivariateNormal(torch.zeros(len(self.thetas)*(self.grid_size**2)), self.K_g).sample()  \n",
    "        A = self.compute_A()\n",
    "        \n",
    "        # Tile amplitudes to match feature fields \n",
    "        A = A.repeat(len(self.thetas))\n",
    "    \n",
    "        # Combine\n",
    "        I = g * A  + torch.randn_like(g) * self.sigma\n",
    "        #I = torch.sum(I.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "\n",
    "        return I, g\n",
    "    \n",
    "    def log_likelihood(self, I, g,A):\n",
    "        A = A.repeat(len(self.thetas))\n",
    "        I_hat = g * A\n",
    "        #I_hat = torch.sum(I_hat.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "        print(\"Log likelihood I_hat \",I_hat.size())\n",
    "        print(\"Log likelihood I \",I.size())\n",
    "        return MultivariateNormal(I_hat.flatten(), self.sigma * torch.eye(self.grid_size**2)).log_prob(I.flatten())\n",
    "\n",
    "    def likelihood(self, I, g,A):\n",
    "        A = A.repeat(len(self.thetas))\n",
    "        I_hat = g * A     \n",
    "            # Ensure I_hat and I are valid\n",
    "            \n",
    "        if torch.isnan(I_hat).any() or torch.isinf(I_hat).any():\n",
    "            print(\"NaN or inf detected in I_hat calculation\")\n",
    "            return torch.tensor(float('nan'))\n",
    "\n",
    "        if torch.isnan(I).any() or torch.isinf(I).any():\n",
    "            print(\"NaN or inf detected in I calculation\")\n",
    "            return torch.tensor(float('nan'))\n",
    "\n",
    "        # Ensure positive definite covariance matrix\n",
    "        cov_matrix = self.sigma * torch.eye(I_hat.size(0))\n",
    "        if not torch.isfinite(cov_matrix).all():\n",
    "            print(\"Non-finite values in covariance matrix\")\n",
    "            return torch.tensor(float('nan'))\n",
    "        return torch.exp(MultivariateNormal(I_hat, self.sigma * torch.eye(I_hat.size(0))).log_prob(I))\n",
    "\n",
    "    def visualise(self, combined_fields):\n",
    "\n",
    "        # Normalise the combined image for visualisation\n",
    "        combined_fields_normalised = combined_fields / combined_fields.max()\n",
    "\n",
    "        # Reshape to image format\n",
    "        combined_image = combined_fields_normalised.view(self.grid_size, self.grid_size).detach().numpy()\n",
    "\n",
    "        # Visualise the combined image\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(combined_image, cmap='gray') \n",
    "        plt.title('FoGSM Sample')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    def generate_fogsm_dataset(self, num_samples, save=False,save_path=None):\n",
    "        samples = []\n",
    "        for _ in range(num_samples):\n",
    "            I, g = self.samples()\n",
    "            samples.append((I, g))\n",
    "    \n",
    "        # Convert samples to tensors\n",
    "        images, gs = zip(*samples)\n",
    "        images = torch.stack(images)\n",
    "        gs = torch.stack(gs)\n",
    "    \n",
    "        if save:\n",
    "            torch.save(images, gs, save_path)\n",
    "        else:\n",
    "            return images\n",
    "\n",
    "    def visualise_samples(self, save_path, num_samples_to_visualise, grid_size):\n",
    "        # Load the saved samples\n",
    "        images, _ = torch.load(save_path)\n",
    "\n",
    "        # Select a subset of samples to visualise\n",
    "        selected_samples = images[:num_samples_to_visualise]\n",
    "\n",
    "        # Create a grid of images\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))\n",
    "        fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i < num_samples_to_visualise:\n",
    "                image = selected_samples[i].detach().numpy()\n",
    "                image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "                ax.imshow(image, cmap='gray')\n",
    "        \n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3539168761.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3539168761.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the parameters for the FoGSM model\n",
    "thetas = torch.linspace(0, 2 * torch.pi, 8)  # 8 orientations from 0 to 2*pi\n",
    "fogsm_params = {\n",
    "        \"thetas\": thetas,\n",
    "        \"length_scale_feature\": 1.0,\n",
    "        \"length_scale_amplitude\": 1.5,\n",
    "        \"kappa\": .5,\n",
    "        \"jitter\": 1e-4,\n",
    "        \"grid_size\": 3,\n",
    "        \"frequency\": .2,\n",
    "        \"sigma\": 0.1,\n",
    "    }\n",
    "fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "# Generate and visualise a sample from the FoGSM model\n",
    "I, g = fogsm_model.samples()\n",
    "#fogsm_model.visualise(I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSN Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSNBase(torch.nn.Module):\n",
    "    def __init__(self, n, k, Ne, Ni, tau_e, tau_i, device='cpu', dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.N = self.Ne + self.Ni\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.register_buffer('EI', torch.cat([torch.ones(Ne), torch.zeros(Ni)]).to(device).bool())\n",
    "        self.register_buffer('tau_vec', torch.cat([tau_e * torch.ones(Ne), tau_i * torch.ones(Ni)]).to(device, dtype))\n",
    "    \n",
    "    def drdt(self, r, inp_vec):\n",
    "        return (-r + self.powlaw(self.W @ r + inp_vec)) / self.tau_vec\n",
    "\n",
    "    def powlaw(self, u):\n",
    "        return self.k * F.relu(u).pow(self.n)\n",
    "    \n",
    "    def dvdt_batch(self, v, inp_vec):\n",
    "        # Ensure v and inp_vec are 2D tensors for batch processing\n",
    "        if v.ndim == 1:\n",
    "            v = v.unsqueeze(0)\n",
    "        if inp_vec.ndim == 1:\n",
    "            inp_vec = inp_vec.unsqueeze(0)\n",
    "\n",
    "        #print(f\"dvdt: v.shape={v.shape}, inp_vec.shape={inp_vec.shape}, W.shape={self.W.shape}\")\n",
    "\n",
    "        # Compute W @ r for batch processing\n",
    "        W_r = self.W @ self.powlaw(v).T\n",
    "        W_r = W_r.T  # Transpose back to match batch dimension\n",
    "    \n",
    "        return (-v + W_r + inp_vec) / self.tau_vec\n",
    "\n",
    "    def simulate_batch(self, inp_vec, v_init=None, duration=500, dt=0.1):\n",
    "        # inp_vec: [batch_size, num_neurons]\n",
    "        # v_init: [batch_size, num_neurons]\n",
    "        # returns: [batch_size, time_steps, num_neurons]\n",
    "\n",
    "        # Check if inp_vec is a batch of inputs\n",
    "        if inp_vec.ndim == 2:\n",
    "            # inp_vec: [batch_size, num_neurons]\n",
    "            batch_size, self.N = inp_vec.shape\n",
    "            time_steps = int(duration / dt)\n",
    "\n",
    "            #print duration, dt, time_steps\n",
    "            #print(\"duration, dt, time_steps\",duration, dt, time_steps)\n",
    "                  \n",
    "            inp_vec = inp_vec.unsqueeze(1).expand(-1, time_steps, -1)\n",
    "        else:\n",
    "            raise ValueError(\"inp_vec must be a 2D tensor of shape [batch_size, num_neurons].\")\n",
    "\n",
    "        print(f\"simulate: batch_size={batch_size}, time_steps={time_steps}, inp_vec.shape={inp_vec.shape}\")\n",
    "\n",
    "        # Initialise v_init if not provided\n",
    "        if v_init is None:\n",
    "            v_init = torch.zeros((batch_size, self.N), device=self.device, dtype=self.dtype)\n",
    "        else:\n",
    "            if isinstance(v_init, (int, float)):\n",
    "                v_init = torch.full((batch_size, self.N), v_init, device=self.device, dtype=self.dtype)\n",
    "            if v_init.shape[0] != batch_size or v_init.shape[1] != self.N:\n",
    "                raise ValueError(\"v_init shape does not match batch_size or neuron count N.\")\n",
    "\n",
    "        # rates: [batch_size, time_steps, Ne]\n",
    "        rates_E = torch.zeros((batch_size, time_steps, self.Ne), device=self.device, dtype=self.dtype)\n",
    "        v = v_init\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            # Calculate dv for each element in the batch at the current time step\n",
    "            dv = self.dvdt_batch(v, inp_vec[:, t, :])  # dv: [batch_size, num_neurons]\n",
    "\n",
    "            # Update the membrane potentials for the current time step\n",
    "            v += dt * dv\n",
    "\n",
    "            # Compute the firing rates from the updated membrane potentials\n",
    "            r = self.powlaw(v) # r: [batch_size, num_neurons]\n",
    "\n",
    "            # Store the rates for the current time step\n",
    "            rates_E[:, t, :] = r[:, :self.Ne] # rates: [batch_size, time_steps, Ne]\n",
    "\n",
    "            #print(f\"t={t}, v.shape={r.shape}, dv.shape={dv.shape}\")\n",
    "\n",
    "\n",
    "        return rates_E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSN 2DTopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSN2DTopo(SSNBase):\n",
    "    def __init__(self, n, k, tauE, tauI, grid_pars, conn_pars, thetas, L = np.pi,device='cpu', dtype=torch.float64):\n",
    "         \n",
    "        num_orientations = thetas.shape[0]\n",
    "        grid_size = grid_pars['grid_size_Nx']\n",
    "                \n",
    "        Ne = num_orientations * (grid_size ** 2)\n",
    "        Ni = num_orientations * (grid_size ** 2)\n",
    "\n",
    "        super(SSN2DTopo, self).__init__(n=n, k=k, Ne=Ne, Ni=Ni, tau_e=tauE, tau_i=tauI, device=device, dtype=dtype)\n",
    "        \n",
    "        self.num_orientations = num_orientations\n",
    "        self.grid_size = grid_size\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.L = L\n",
    "        self._make_maps(thetas)\n",
    "        \n",
    "        # Initialise trainable parameters\n",
    "        if conn_pars is None:\n",
    "            conn_pars = {\n",
    "                'J_2x2': torch.rand(2, 2, device=device, dtype=dtype),  # Interaction strengths\n",
    "                's_2x2': torch.rand(2, 2, device=device, dtype=dtype),  \n",
    "                'p_local': torch.rand(2, device=device, dtype=dtype),  \n",
    "                'sigma_oris': torch.rand(1, device=device, dtype=dtype)  \n",
    "            }\n",
    "            \n",
    "        self.J_2x2 = nn.Parameter(conn_pars['J_2x2'])  # Interaction strengths\n",
    "        self.s_2x2 = nn.Parameter(conn_pars['s_2x2']) # Spatial length scales\n",
    "        self.p_local = nn.Parameter(conn_pars['p_local']) # Local connectivity strengths\n",
    "        self.sigma_oris = nn.Parameter(conn_pars['sigma_oris']) # Orientation tuning width\n",
    "        \n",
    "        self.make_W()\n",
    "\n",
    "    def _make_maps(self,thetas):\n",
    "\n",
    "        self.ori_map = torch.tensor(thetas, device=self.device, dtype=self.dtype).flatten()\n",
    "        self.ori_vec = self.ori_map.repeat(self.grid_size ** 2)  # Repeat orientation values for each grid cell\n",
    "        self.ori_vec = self.ori_vec.repeat(2) # Repeat for E and I populations\n",
    "\n",
    "        # Create x and y vectors for grid cells\n",
    "        self.x_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations).repeat(self.grid_size)\n",
    "        self.y_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations * self.grid_size)\n",
    "\n",
    "        # Repeat for E and I populations\n",
    "        self.x_vec = self.x_vec.repeat(2)\n",
    "        self.y_vec = self.y_vec.repeat(2)\n",
    "    \n",
    "    def calc_xy_dist(self):\n",
    "        Ne = Ni = self.Ne\n",
    "        x_vec_e = self.x_vec[:Ne]\n",
    "        y_vec_e = self.y_vec[:Ne]\n",
    "        x_vec_i = self.x_vec[Ne:Ne+Ni]\n",
    "        y_vec_i = self.y_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        xy_dist = torch.cdist(torch.stack([x_vec_e, y_vec_e], dim=1), torch.stack([x_vec_i, y_vec_i], dim=1), p=2).repeat(2, 2) #Distance Squared\n",
    "\n",
    "        return xy_dist\n",
    "    \n",
    "    def calc_ori_dist(self,L=np.pi, method=None):\n",
    "\n",
    "        Ne = Ni = self.num_orientations * self.grid_size ** 2\n",
    "        \n",
    "        ori_vec_e = self.ori_vec[:Ne]\n",
    "        ori_vec_i = self.ori_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        # define everything as squared distance ori_sqdist = (ori_vec_e - ori_vec_i) ** 2\n",
    "        if method == \"absolute\":\n",
    "            ori_dist = torch.cdist(ori_vec_e.unsqueeze(1), ori_vec_i.unsqueeze(1)).repeat(2,2)\n",
    "        elif method == \"cos\":\n",
    "            ori_vec_e_norm = ori_vec_e / ori_vec_e.norm(dim=1, keepdim=True)\n",
    "            ori_vec_i_norm = ori_vec_i / ori_vec_i.norm(dim=1, keepdim=True)\n",
    "            ori_dist = 1 - torch.mm(ori_vec_e_norm, ori_vec_i_norm.t())\n",
    "        else:\n",
    "            #1 - cos(2(pi/L) * |theta1 - theta2|^2)\n",
    "            ori_dist = (1 - torch.cos((2 * np.pi / L) * (ori_vec_e.unsqueeze(1) - ori_vec_i.unsqueeze(0))**2)) / (2 * np.pi / L)**2\n",
    "\n",
    "            #ori_vec[:,None] - ori_ve\n",
    "        \n",
    "        ori_dist = ori_dist.repeat(2, 2)\n",
    "\n",
    "        return ori_dist\n",
    "\n",
    "    def make_W(self):\n",
    "        \n",
    "        xy_dist = self.calc_xy_dist()\n",
    "        ori_dist = self.calc_ori_dist()\n",
    "\n",
    "        # Compute weight blocks\n",
    "        W_ee = self.calc_W_block(xy_dist[:self.Ne, :self.Ne], ori_dist[:self.Ne, :self.Ne], self.s_2x2[0][0], self.sigma_oris)\n",
    "        W_ei = self.calc_W_block(xy_dist[:self.Ne, self.Ne:], ori_dist[:self.Ne, self.Ne:], self.s_2x2[0][1], self.sigma_oris)\n",
    "        W_ie = self.calc_W_block(xy_dist[self.Ne:, :self.Ne], ori_dist[self.Ne:, :self.Ne], self.s_2x2[1][0], self.sigma_oris)\n",
    "        W_ii = self.calc_W_block(xy_dist[self.Ne:, self.Ne:], ori_dist[self.Ne:, self.Ne:], self.s_2x2[1][1], self.sigma_oris)\n",
    "        \n",
    "        # Apply local connectivity strengths\n",
    "        W_ee = self.p_local[0] * torch.eye(self.Ne, device=self.device, dtype=self.dtype) + (1 - self.p_local[0]) * W_ee\n",
    "        W_ei = self.p_local[1] * torch.eye(self.Ni, device=self.device, dtype=self.dtype) + (1 - self.p_local[1]) * W_ei\n",
    "        \n",
    "        print(\"J_2x2 shape:\", self.J_2x2.shape)\n",
    "        print(\"W_ie shape:\", W_ie.shape)\n",
    "        print(\"W_ii shape:\", W_ii.shape)\n",
    "    \n",
    "        print(\"Is J_2x2 NaN or Inf?\", torch.isnan(self.J_2x2).any() or torch.isinf(self.J_2x2).any())\n",
    "        print(\"Is W_ie NaN or Inf?\", torch.isnan(W_ie).any() or torch.isinf(W_ie).any())\n",
    "        print(\"Is W_ii NaN or Inf?\", torch.isnan(W_ii).any() or torch.isinf(W_ii).any())\n",
    "    \n",
    "        \n",
    "        # Concatenate submatrices to form W\n",
    "        W = torch.cat([\n",
    "            torch.cat([self.J_2x2[0, 0] * W_ee, self.J_2x2[0, 1] * W_ei], dim=1).clone().detach(),\n",
    "            torch.cat([self.J_2x2[1, 0] * W_ie, self.J_2x2[1, 1] * W_ii], dim=1).clone().detach()\n",
    "        ], dim=0).double()\n",
    "\n",
    "        # Register W as a buffer\n",
    "        self.register_buffer('W', W)\n",
    "        \n",
    "        return self.W\n",
    "\n",
    "    def calc_W_block(self, xy_dist, ori_dist, s, sigma_oris, CellWiseNormalised = True):\n",
    "\n",
    "        #Add a small constant to s and sigma_oris to avoid division by zero\n",
    "        s = s + 1e-8\n",
    "        sigma_oris = 2*np.pi*sigma_oris/self.L + 1e-8\n",
    "        \n",
    "        W =  torch.exp(-xy_dist / s - ori_dist ** 2 / (2 * sigma_oris ** 2))\n",
    "        W = torch.where(W < 1e-4, torch.zeros_like(W), W)\n",
    "\n",
    "        \n",
    "        sW = torch.sum(W, dim=1, keepdim=True)\n",
    "        if CellWiseNormalised:\n",
    "            W = torch.div(W, sW)\n",
    "        else:\n",
    "            sW = sW.mean()\n",
    "            W = W / sW\n",
    "\n",
    "        return W.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSN Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set network parameters - TODO take from echeveste et al, double check that theb weight matrix is set up according to the paper \n",
    "n = 2\n",
    "k = 0.3\n",
    "tauE = 20.0\n",
    "tauI = 10.0\n",
    "grid_pars = {'grid_size_Nx': 3}\n",
    "\n",
    "psi = torch.tensor(0.774)\n",
    "conn_pars = {\n",
    "    'J_2x2': torch.tensor([[1.124, -0.931], [1.049, -0.537]],dtype=torch.float64) *torch.pi * psi, #TODO: take their a and multiply by 2 * num thetas in echeveste\n",
    "    's_2x2': torch.tensor([[0.2955, 0.09], [0.5542, 0.09]]),  # TODO: set to be 10x grid size \n",
    "    'p_local': torch.tensor([0.72,0.7]),  \n",
    "    'sigma_oris': torch.tensor(45.0),\n",
    "    'num_orientations': 8}\n",
    "\n",
    "thetas = np.linspace(0, np.pi, conn_pars['num_orientations'])\n",
    "\n",
    "ssn_params = {\n",
    "        \"n\": 2,\n",
    "        \"k\": k,\n",
    "        \"tauE\": 20,\n",
    "        \"tauI\": 10,\n",
    "        \"grid_pars\": grid_pars,\n",
    "        \"conn_pars\": conn_pars,\n",
    "        \"thetas\": thetas,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        super(DirectFit, self).__init__()\n",
    "        self.ssn_model = SSN2DTopo(**ssn_params)\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "        self.C_E = nn.Parameter(torch.tensor(2.4)) # taken from Echeveste et al. 2020\n",
    "        self.C_I = nn.Parameter(torch.tensor(2.4)) # taken from Echeveste et al. 2020\n",
    "        # TODO: 1.5 * overall standard deviation of an image from FoGSM model - compute the sd over a large number of sample images empirically and set this value\n",
    "        s = 0.1\n",
    "        self.beta = nn.Parameter(torch.tensor(1.5 * s))\n",
    "        self.gamma = nn.Parameter(torch.tensor(0.6)) # taken from Echeveste et al. 2020\n",
    "\n",
    "    def sample_trajectories(self, input_batch, duration=500, dt=.1):\n",
    "\n",
    "        # shape of input_batch: [batch_size, num_neurons]\n",
    "        batch_size = input_batch.shape[0]   \n",
    "        #print(\"Input batch shape: \", input_batch.shape)  \n",
    "\n",
    "        # Non-linearity for the input to the network\n",
    "        input_processed = F.relu(input_batch)\n",
    "        input_processed = (self.beta + input_processed)**self.gamma\n",
    "\n",
    "        # Multiply the input batch by C_E and C_I scalars\n",
    "        input_weighted = torch.cat([\n",
    "            self.C_E * input_processed,\n",
    "            self.C_I * input_processed\n",
    "        ], dim=-1)\n",
    "        #print(\"Input weighted shape: \", input_weighted.shape)\n",
    "\n",
    "        # Ensure input_reshaped has correct dimensions before calling simulate\n",
    "        if input_weighted.shape[1] != self.ssn_model.N:\n",
    "            input_weighted = input_weighted.view(input_weighted.shape[0], self.ssn_model.N)\n",
    "\n",
    "        # Generate trajectories for the reshaped input\n",
    "        trajectories = self.ssn_model.simulate_batch(input_weighted, duration=duration, dt=dt)\n",
    "        #print(\"Trajectories shape after simulation: \", trajectories.shape)\n",
    "\n",
    "        return trajectories\n",
    "\n",
    "    def calculate_log_p_g(self, trajectory):\n",
    "        # trajectory: [num_samples_g, dim]\n",
    "        # expectation over g in Eq (25) (1st term), i.e., (sub-sampled) time-steps of SSN simulation, corresponding to samples from variational posterior of g\n",
    "\n",
    "        num_neurons = trajectory.shape[1]  # Number of neurons\n",
    "        dim = trajectory.shape[0]            # Number of time points\n",
    "\n",
    "        # Mean vector for the multivariate normal (zero mean)\n",
    "        mean = torch.zeros(num_neurons, device=trajectory.device, dtype=trajectory.dtype)\n",
    "    \n",
    "        # Covariance matrix for the multivariate normal\n",
    "        cov = self.fogsm_model.K_g\n",
    "\n",
    "        # Check covariance matrix shape\n",
    "        assert cov.shape == (num_neurons, num_neurons), f\"Expected covariance matrix of shape ({num_neurons}, {num_neurons}), but got {cov.shape}\"\n",
    "\n",
    "        # Multivariate normal distribution\n",
    "        mvg = MultivariateNormal(mean, cov)\n",
    "\n",
    "        #print(\"Logpg Trajectory shape: \", trajectory.shape)  \n",
    "        #print(\"Mean shape: \", mean.shape)\n",
    "        #print(\"Covariance matrix shape: \", cov.shape)\n",
    "\n",
    "        # Calculate log probabilities for all samples in the trajectory\n",
    "        log_probs = []\n",
    "        for g in trajectory:\n",
    "            log_probs.append(mvg.log_prob(g))  # log_probs: [num_samples_g]\n",
    "\n",
    "        log_probs = torch.tensor(log_probs, device=trajectory.device, dtype=trajectory.dtype)\n",
    "        if torch.isnan(log_probs).any():\n",
    "            print(\"NaN detected in log_probs\")\n",
    "\n",
    "        # Return the mean log probability\n",
    "        log_p_g = log_probs.mean()\n",
    "\n",
    "        return log_p_g\n",
    "\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, I_data, trajectory, A_samples, epsilon=1e-6):\n",
    "\n",
    "        log_likelihood = 0\n",
    "\n",
    "        # expectation over g in Eq (25) (2nd term)\n",
    "        for g in trajectory: # runs over (sub-sampled) time-steps of SSN simulation, corresponding to samples from variational posterior of g\n",
    "            p_I_g = 0\n",
    "\n",
    "            # expectation over A in Eq (25)\n",
    "            for a in A_samples: # for computational cost reasons, currently using the same samples for A for all images in a batch (but we resample across mini-batches) \n",
    "                p_I_g = p_I_g + self.fogsm_model.likelihood(I_data, g, a) # I_data is a single image from the dataset and g is a single sample\n",
    "                                                                          # for g from the SSN\n",
    "                #check if p_I_g is zero or negative\n",
    "                if p_I_g < 0:\n",
    "                    print(\"p_I_g is zero\")\n",
    "\n",
    "            avg_p_I_g = p_I_g / len(A_samples)\n",
    "            avg_p_I_g = torch.clamp(avg_p_I_g, min=epsilon) # to avoid log(0)\n",
    "\n",
    "            log_likelihood = log_likelihood + torch.log(avg_p_I_g)\n",
    "        \n",
    "        if torch.isnan(log_likelihood).any():\n",
    "            print(\"NaN detected in log_likelihood\")\n",
    "\n",
    "        return log_likelihood / len(trajectory)\n",
    "\n",
    "        \n",
    "    def calculate_elbo(self, input_batch, A_samples, duration=500, dt=.1):\n",
    "\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories = self.sample_trajectories(input_batch=input_batch, duration=duration, dt=dt)\n",
    "        #print(\"ELBO trajectories received\")\n",
    "\n",
    "        elbo = 0\n",
    "        for I, trajectory in zip(input_batch, trajectories): # trajectory is the trajectory for a single image\n",
    "            #print(\"Trajectory shape for single image: \", trajectory.shape)\n",
    "            log_p_g = self.calculate_log_p_g(trajectory)\n",
    "            #print(\"Log p_g calculated\")\n",
    "            log_p_I_given_g = self.calculate_log_p_I_given_g(I, trajectory, A_samples)\n",
    "            #print(\"Log p_I_given_g calculated\")\n",
    "\n",
    "            # cov_matrix = torch.cov(trajectory.reshape(trajectory.shape[0], -1))\n",
    "            cov_matrix = torch.cov(trajectory.T)\n",
    "            # Ensure covariance matrix is positive definite\n",
    "            if not torch.isfinite(cov_matrix).all():\n",
    "                print(\"Non-finite values in covariance matrix\")\n",
    "            \n",
    "            if torch.isnan(cov_matrix).any():\n",
    "                print(\"NaN detected in cov_matrix\")\n",
    "            \n",
    "            cov_matrix = cov_matrix + 1e-6 * torch.eye(cov_matrix.size(0))\n",
    "            entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "\n",
    "            print(\"ELBO terms: \", log_p_g, log_p_I_given_g, entropy_term)\n",
    "\n",
    "            elbo = elbo + log_p_g + log_p_I_given_g + entropy_term\n",
    "            if torch.isnan(elbo).any():\n",
    "                print(\"NaN detected in elbo\")\n",
    "\n",
    "        return elbo / len(input_batch)\n",
    "        \n",
    "    def optimise_elbo(self, batch_size, num_samples_a, convergence_threshold=1e-3, optimizer_cls=Adam, lr=1e-3):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.ssn_model.to(device)\n",
    "        self.fogsm_model.to(device)\n",
    "\n",
    "        optimizer = optimizer_cls(list(self.ssn_model.parameters()) + \n",
    "                              [self.C_E, self.C_I, self.beta, self.gamma], lr=lr)\n",
    "        batch = 0\n",
    "        prev_elbo = float('-inf')\n",
    "        elbo = 0\n",
    "\n",
    "        # plot the batch elbo values\n",
    "        elbo_values = []  \n",
    "\n",
    "        while True:\n",
    "            \n",
    "            optimizer.zero_grad()  # Zero gradients at the beginning of each batch\n",
    "\n",
    "            elbo_batch = 0\n",
    "\n",
    "            # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "            A_samples = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "\n",
    "            # Generate a mini-batch of input data\n",
    "            input_batch = self.fogsm_model.generate_fogsm_dataset(batch_size).to(device)\n",
    "\n",
    "            # Calculate the ELBO for the mini-batch\n",
    "            elbo_batch = self.calculate_elbo(input_batch, A_samples, duration=10, dt=1)\n",
    "\n",
    "            if torch.isnan(elbo_batch).any():\n",
    "                print(\"NaN detected in elbo_batch\")\n",
    "                break\n",
    "\n",
    "            # Optimise the ELBO with respect to the model parameters\n",
    "            elbo_batch.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print the ELBO for monitoring\n",
    "            if (batch + 1) % 1 == 0:\n",
    "                print(f\"Batch [{batch+1}], ELBO: {elbo_batch / batch_size:.4f}\")\n",
    "\n",
    "            # Check for convergence\n",
    "            if abs(elbo_batch - prev_elbo) < convergence_threshold:\n",
    "                print(f\"Converged after {batch+1} batches.\")\n",
    "                break\n",
    "\n",
    "            prev_elbo = elbo_batch\n",
    "            batch = batch + 1\n",
    "            elbo_values.append(elbo_batch.item())\n",
    "        \n",
    "\n",
    "        return self.ssn_model, self.fogsm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_2x2 shape: torch.Size([2, 2])\n",
      "W_ie shape: torch.Size([72, 72])\n",
      "W_ii shape: torch.Size([72, 72])\n",
      "Is J_2x2 NaN or Inf? tensor(False)\n",
      "Is W_ie NaN or Inf? tensor(False)\n",
      "Is W_ii NaN or Inf? tensor(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3539168761.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3539168761.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-512.9042, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.4622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-734.8602, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.6126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-131.9472, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [1], ELBO: -320.4085\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-192.2749, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-929.1404, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.1540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-565.3376, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.7464, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [2], ELBO: -354.5063\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-4007.3563, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.1338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1360.5029, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.2600, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-158.1576, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.1853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [3], ELBO: -780.4491\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1033.0984, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.6975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-2555.9536, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.4958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-621.9247, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.6565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [4], ELBO: -634.4748\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-623.7909, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-3472.7406, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-483.9601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-869.4825, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [5], ELBO: -718.3186\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-247.3919, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1082.3435, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.3029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-236.1189, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.5073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [6], ELBO: -340.8162\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-143.0737, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-643.0935, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.4841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-168.7774, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [7], ELBO: -273.1555\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-419.6357, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.5966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1328.9260, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.2547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-772.3112, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [8], ELBO: -446.8910\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-2616.9671, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-483.1164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-291.9789, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-233.1653, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [9], ELBO: -515.8911\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-155.7175, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-590.9553, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.7660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-293.9464, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.9493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [10], ELBO: -282.8701\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-342.5616, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-214.0587, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.5134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-935.7674, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.1134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [11], ELBO: -332.7581\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-3153.2432, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.8309, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-643.6829, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.4782, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-836.5181, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [12], ELBO: -681.7813\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-283.8066, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.9887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-7252.9307, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-483.6559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-231.3224, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [13], ELBO: -1029.8491\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-144.6979, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-165.3508, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.0419, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-607.8183, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [14], ELBO: -269.0446\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1044.2843, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.6585, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-917.4200, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3001, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-525.7164, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [15], ELBO: -443.3012\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-551.9780, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-142.5563, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-150.4633, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [16], ELBO: -261.2215\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-4239.9274, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-484.3216, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-138.2244, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3625, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-575.4993, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [17], ELBO: -717.1471\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1472.3360, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.0460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-343.3403, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-197.2221, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [18], ELBO: -390.5064\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-154.8035, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.6959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-305.7256, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.6362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-566.3836, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.1020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [19], ELBO: -281.1993\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-800.4881, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-9057.4807, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-483.6212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-403.5922, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.7970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [20], ELBO: -1306.6670\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-400.3723, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.1663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-190.4159, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.1719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-436.8851, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [21], ELBO: -281.1998\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-168.4595, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.4382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-286.1861, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-149.6150, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [22], ELBO: -234.7038\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-245.1412, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-181.7512, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-388.8083, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8614, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [23], ELBO: -257.7603\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-163.0829, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-227.6384, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8301, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-182.3679, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [24], ELBO: -231.1046\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-541.9190, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-466.2296, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-512.2197, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [25], ELBO: -336.1343\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-148.9920, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-3357.1024, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.8956, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-333.9746, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-484.4267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [26], ELBO: -593.3608\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-163.9065, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.1355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-849.9126, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-340.4598, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.8666, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [27], ELBO: -317.7820\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1484.3749, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-484.9089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-224.1261, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.9151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-136.2658, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [28], ELBO: -371.6540\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-237.1989, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-136.6679, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-181.4707, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [29], ELBO: -228.9919\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-146.1236, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0561, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-954.1831, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.6175, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-133.9846, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [30], ELBO: -304.3350\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1280.5394, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.2164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-587.3679, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-127.8577, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.5427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [31], ELBO: -389.0260\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-147.9584, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.1843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-195.6145, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-280.5545, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1796, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [32], ELBO: -236.5780\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-990.5867, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.5003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1798.7719, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.5695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-170.7022, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.4103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [33], ELBO: -495.6653\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1055.4423, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.1029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-237.8173, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0599, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1096.0254, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [34], ELBO: -432.5134\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1894.2321, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.5213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-124.3698, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.4529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-195.3635, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [35], ELBO: -413.3863\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-213.6787, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.0926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-655.5833, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.0775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-590.3033, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.3177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [36], ELBO: -328.8333\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-176.7449, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.0583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-2218.0946, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-205.9926, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [37], ELBO: -456.2313\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-242.2727, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-251.4831, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.5252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1067.9371, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.4349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [38], ELBO: -340.8314\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-861.3771, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-240.1690, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0477, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-170.4566, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.7471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [39], ELBO: -308.4393\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-946.8637, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.9929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-778.3227, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5222, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1026.2580, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [40], ELBO: -472.7008\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-210.8017, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6566, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1443.3007, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.4355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-381.4965, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.6698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [41], ELBO: -393.0897\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-402.5639, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-125.2981, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-617.7130, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.5695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [42], ELBO: -294.3325\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1030.6184, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.2156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-124.3234, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.6745, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-466.3903, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [43], ELBO: -347.5180\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-401.0037, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-208.3832, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2773, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-435.5079, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [44], ELBO: -283.3348\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-276.4219, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-672.5437, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.8495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-624.4594, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.7231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [45], ELBO: -341.6124\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-365.8831, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.4256, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-127.5558, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-491.0455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-967.2034, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.1281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [46], ELBO: -329.5209\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-124.3285, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.2587, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1624.0099, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8696, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-410.1909, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [47], ELBO: -407.3566\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1501.5955, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.2020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-478.5513, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.4606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-124.3841, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [48], ELBO: -400.8147\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-276.6048, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.7123, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-578.0434, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-259.8158, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [49], ELBO: -291.0249\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-386.0392, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.0312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-159.1623, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.6480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1295.2852, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.6853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [50], ELBO: -371.6997\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-460.8600, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-208.0281, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-500.1948, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.0534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [51], ELBO: -297.0828\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-303.3548, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-364.4410, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1536.3263, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.1519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [52], ELBO: -411.7776\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-190.8724, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.7904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-686.0910, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.6916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-179.2644, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4143, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [53], ELBO: -284.9523\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-137.9646, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8239, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-636.1317, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.1285, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-323.3429, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [54], ELBO: -289.1168\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1467.9850, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.2709, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-380.9540, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-351.7532, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [55], ELBO: -411.5501\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1992.5753, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-213.5687, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.7297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-402.3128, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [56], ELBO: -457.0250\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-895.7354, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.0258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-393.1776, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.8695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-471.7830, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [57], ELBO: -362.5831\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-516.6294, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.2700, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1843.4409, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.1103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-163.1154, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [58], ELBO: -447.4993\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-182.6445, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-800.8362, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-362.6876, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.1231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [59], ELBO: -316.4981\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-293.8657, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-165.6351, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2329, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-310.6863, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.6982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [60], ELBO: -252.9846\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-626.8231, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-707.6301, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.4617, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-230.3745, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [61], ELBO: -340.7595\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1400.6012, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.1053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1183.8916, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.7390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1218.9403, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7549, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [62], ELBO: -589.6088\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-365.5739, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-288.2973, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.6797, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-680.6098, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [63], ELBO: -315.3885\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-353.9089, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8721, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-331.1141, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-250.0790, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [64], ELBO: -271.1851\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-127.9691, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-753.3396, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-481.7097, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.3958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [65], ELBO: -318.6513\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1892.1054, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.7723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-124.5724, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-394.3672, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.0517, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [66], ELBO: -434.8527\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-321.6718, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-424.1031, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.7192, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-249.9370, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1784, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [67], ELBO: -278.0958\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-597.5624, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.4185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-128.0286, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.9166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-311.5955, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [68], ELBO: -282.6994\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-463.6096, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.3850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-189.0954, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-145.5688, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6476, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [69], ELBO: -255.9986\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-289.6863, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.3324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1422.7291, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-125.0758, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.0000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [70], ELBO: -371.4591\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-962.7460, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.0242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-183.1060, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-389.8801, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [71], ELBO: -337.8603\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-290.5997, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-725.0138, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-126.6654, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.9675, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [72], ELBO: -294.2800\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-236.0011, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3655, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-424.4920, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-127.7812, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [73], ELBO: -254.8843\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-143.0876, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-126.6221, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-412.1431, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [74], ELBO: -243.1819\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-141.1175, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.2601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-163.9392, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.8444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-279.6913, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.5850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [75], ELBO: -232.2093\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-404.1254, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-365.9862, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7118, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-137.6935, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [76], ELBO: -268.0432\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-190.2283, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-161.5514, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-186.0750, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [77], ELBO: -227.0921\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-199.2052, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3665, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-354.9692, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.5060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1866.5740, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.7113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [78], ELBO: -436.3088\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-326.2067, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-616.6692, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-832.0398, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [79], ELBO: -364.4009\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-361.6247, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.4403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-139.8280, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1974.3274, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.5799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [80], ELBO: -442.2870\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-147.5251, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-551.5109, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-230.2823, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [81], ELBO: -270.8820\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-261.4823, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-143.2223, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-168.9978, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [82], ELBO: -231.2280\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-426.8302, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.2540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-414.6345, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.4129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-279.7692, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [83], ELBO: -291.6509\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-129.9832, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-169.3985, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3609, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-160.4248, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [84], ELBO: -218.7022\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-180.3371, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.8040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-205.7639, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.7231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-259.5011, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.5896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [85], ELBO: -239.2406\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-497.6334, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-127.3998, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-176.4884, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [86], ELBO: -256.5710\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-2010.9476, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.4764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-125.0991, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-125.1262, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.8098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [87], ELBO: -418.7711\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-417.0270, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4203, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-182.1580, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-462.5307, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [88], ELBO: -285.3015\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-193.9380, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-280.7012, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-212.3223, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [89], ELBO: -243.9140\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-836.2631, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-256.6792, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-289.7520, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.7335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [90], ELBO: -320.8237\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-170.7272, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.0694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-129.3057, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-175.9622, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.9823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [91], ELBO: -220.0357\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-683.7928, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.9131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-274.4376, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-153.7627, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [92], ELBO: -290.9243\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-340.3445, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.5791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-302.9948, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.5929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-2350.0713, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.9363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [93], ELBO: -499.8851\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-439.3716, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2299, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-146.4683, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-404.7215, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.7319, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [94], ELBO: -277.6495\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-1640.3315, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-829.6741, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-485.7193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-174.5071, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1718, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [95], ELBO: -460.7390\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-611.3927, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1593, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-318.8313, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-131.9113, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3642, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [96], ELBO: -285.5880\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-139.7788, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-165.2521, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-438.3753, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [97], ELBO: -250.0183\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-878.2189, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-419.6428, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.8556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-144.1391, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [98], ELBO: -327.6991\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-212.0174, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.6506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-212.7891, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-135.4215, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4632, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [99], ELBO: -229.6773\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-501.8191, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-516.6930, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.7144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-264.7079, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [100], ELBO: -309.9209\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-704.8976, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-163.0362, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1252.7896, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [101], ELBO: -402.8364\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-640.0700, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-474.4997, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-336.5651, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8757, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [102], ELBO: -328.5016\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-124.8269, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-166.8056, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-185.7640, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [103], ELBO: -220.5532\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-145.0532, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-434.8284, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-456.4124, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [104], ELBO: -282.6110\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-127.7518, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.1679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-208.3855, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-200.0208, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6655, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [105], ELBO: -227.2561\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-258.8141, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.7741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-712.6213, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-152.4582, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.9509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [106], ELBO: -292.3740\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-131.3785, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.0112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-137.5746, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.7415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1017.4148, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [107], ELBO: -310.6021\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-268.3902, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-857.8455, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.8220, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-156.4122, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [108], ELBO: -309.9834\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-126.7124, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.3734, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-171.6189, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.5193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-136.6709, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.7188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [109], ELBO: -216.2289\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-130.3036, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-229.8642, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-133.7042, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.5190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [110], ELBO: -222.3694\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-169.7225, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.8414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-141.7773, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.7771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-129.1662, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.1631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [111], ELBO: -216.9882\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-127.1363, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.8432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-294.4391, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-179.9318, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.5264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [112], ELBO: -234.6273\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-128.0294, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-127.3306, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.1948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-189.9009, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [113], ELBO: -217.1723\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-378.6379, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-135.9288, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.8101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-228.6802, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [114], ELBO: -250.3895\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-129.9730, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3256, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-132.1927, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-179.9640, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [115], ELBO: -216.6576\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-131.5924, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-491.8251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-193.5666, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-430.3822, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [116], ELBO: -251.9383\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-524.0312, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.4577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-561.1527, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-537.5390, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.4608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [117], ELBO: -347.3237\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-134.8179, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-235.9794, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.7466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-465.1350, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.7974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [118], ELBO: -260.4222\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-663.4666, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-774.5869, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.4049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-137.8366, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.3253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [119], ELBO: -342.5988\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-376.3028, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-159.1021, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-173.6012, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [120], ELBO: -246.1239\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-180.4039, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8590, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-169.8721, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-500.6785, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.4491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [121], ELBO: -261.9546\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-233.3721, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-184.4364, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.4236, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-161.3714, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [122], ELBO: -232.1034\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-147.1019, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.7477, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-196.5327, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.5286, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-131.1459, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.8937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [123], ELBO: -220.7108\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-214.1761, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-189.4294, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-163.6563, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [124], ELBO: -230.4414\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-154.8436, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-191.2082, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-549.8567, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.2102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [125], ELBO: -267.0017\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-227.2139, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-361.8778, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-337.2440, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [126], ELBO: -270.2448\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-129.8838, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.0987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-1828.2963, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-486.9668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-268.6542, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8979, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [127], ELBO: -414.9160\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-197.7124, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.0984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-133.9891, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-172.1904, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [128], ELBO: -223.6850\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-139.4563, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.8723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-149.0442, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.7081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-449.7588, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.8873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [129], ELBO: -249.7971\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-437.5173, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-143.7462, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.0006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-136.4999, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.7684, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [130], ELBO: -247.4548\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-146.1660, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-162.0667, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-124.6409, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-491.1032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [131], ELBO: -215.9345\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-183.8898, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.7578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-165.4015, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-129.2318, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [132], ELBO: -220.7502\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-295.3238, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.7848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-128.2993, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.5064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-161.8897, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-491.6422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [133], ELBO: -232.9881\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-175.4990, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.8053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-137.7244, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.1203, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-128.1894, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.0755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [134], ELBO: -216.9845\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-338.8742, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-255.1545, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.0899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-175.7500, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6640, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [135], ELBO: -252.9073\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-146.8114, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-146.9317, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.9735, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-135.6439, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.7758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [136], ELBO: -215.4198\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-124.9066, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-132.7540, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.9945, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-243.5740, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [137], ELBO: -223.4121\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-129.2423, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3800, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-159.5504, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.0342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-169.8546, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [138], ELBO: -218.7694\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-172.8335, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.7051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-161.0532, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.2160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-424.6118, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9294, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [139], ELBO: -252.0884\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-124.6922, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-491.4644, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-219.3503, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-374.6670, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [140], ELBO: -247.7284\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-227.4528, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-203.9051, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-148.1511, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [141], ELBO: -231.9562\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-267.4413, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.1725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-353.2925, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-198.5031, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [142], ELBO: -258.7107\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-130.7583, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-172.3371, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.9535, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-180.0562, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [143], ELBO: -221.4297\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-140.3405, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-338.6405, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.3653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-142.6654, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [144], ELBO: -236.6630\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-161.0357, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-166.8425, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-236.7857, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6546, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [145], ELBO: -230.3791\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-522.9860, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.1873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-256.7104, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-152.3064, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3728, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [146], ELBO: -271.1325\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-146.3664, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-175.4448, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-204.0541, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [147], ELBO: -226.1224\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-134.3477, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.6337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-228.0481, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-250.8427, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8442, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [148], ELBO: -235.9771\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-170.8654, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-148.7930, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.6842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-149.7149, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.5473, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [149], ELBO: -220.0384\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-152.1291, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.9770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-204.8583, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1498, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-155.0128, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.5574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [150], ELBO: -224.9034\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-169.5969, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.8735, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-377.6823, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6570, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-239.8873, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.5083, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [151], ELBO: -255.0724\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-175.6295, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.7224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-177.6102, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.0618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-417.9781, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.3619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [152], ELBO: -253.3123\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-166.4598, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.3527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-137.1599, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-201.0106, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [153], ELBO: -223.7947\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-312.4315, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.5952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-167.7957, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-186.8829, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.8011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [154], ELBO: -242.0221\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-302.4536, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2696, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-136.0247, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.3851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-157.0682, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.5088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [155], ELBO: -234.0174\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-174.6595, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.5602, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-448.6512, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.6565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-187.5456, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.9003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [156], ELBO: -257.8244\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-171.5176, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-173.5589, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-130.4017, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.4628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [157], ELBO: -220.6949\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-226.5801, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-138.4242, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.0215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-245.9945, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4147, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [158], ELBO: -235.5484\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-154.6776, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.8878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-408.7690, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-143.9810, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.5522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [159], ELBO: -246.4970\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-192.8581, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-143.2226, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.4740, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-625.1970, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-487.5019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [160], ELBO: -274.1912\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-125.1108, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.5659, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-125.2679, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-491.1492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-212.5027, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.0181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [161], ELBO: -219.4512\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-133.2012, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-149.0181, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.7080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-130.4317, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.1860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [162], ELBO: -213.4740\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-217.8417, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.8692, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-144.1607, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.6128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-433.4313, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.7525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [163], ELBO: -256.1239\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-124.3177, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.1435, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-258.8401, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.2469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-129.7631, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.2955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [164], ELBO: -224.8948\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-131.3699, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.8230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-158.5632, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-126.7743, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.5068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [165], ELBO: -214.2132\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-559.6655, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.2510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-144.4573, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-490.5949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-146.5873, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-488.9505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [166], ELBO: -262.2170\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-186.3787, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-300.4153, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-146.6164, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-491.4160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [167], ELBO: -238.3988\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n",
      "ELBO terms:  tensor(-203.3735, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.4620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-405.8109, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.6543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "ELBO terms:  tensor(-157.8876, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-489.8135, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Batch [168], ELBO: -253.0498\n",
      "simulate: batch_size=3, time_steps=10, inp_vec.shape=torch.Size([3, 10, 144])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected value argument (Tensor of shape (72,)) to be within the support (IndependentConstraint(Real(), 1)) of the distribution MultivariateNormal(loc: torch.Size([72]), covariance_matrix: torch.Size([72, 72])), but found invalid values:\ntensor([       nan,        nan,        nan, 2.3147e-03,        nan,        nan,\n               nan,        nan,        nan,        nan,        nan,        nan,\n               nan,        nan,        nan,        nan,        nan, 9.6659e-04,\n        5.4105e-04, 4.1823e-04,        nan,        nan,        nan,        nan,\n        9.5371e-05, 5.1511e-04,        nan,        nan,        nan,        nan,\n        1.5971e-03, 3.1635e-04,        nan,        nan, 7.9127e-04, 3.0797e-03,\n        2.5237e-03, 8.3309e-04,        nan,        nan, 1.9852e-03, 3.1975e-03,\n               nan,        nan,        nan,        nan, 4.7326e-04, 4.1060e-03,\n        3.9048e-03, 2.3637e-03, 7.1334e-03, 1.1836e-03, 1.1492e-03, 7.5205e-04,\n        2.0271e-03, 3.2089e-03,        nan,        nan,        nan,        nan,\n               nan,        nan,        nan,        nan, 3.0704e-03, 3.3934e-03,\n        6.4084e-03, 4.3212e-03, 2.8830e-03,        nan, 5.9421e-04, 3.0603e-03],\n       dtype=torch.float64, grad_fn=<UnbindBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run the ELBO optimisation\u001b[39;00m\n\u001b[1;32m      7\u001b[0m input_data, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfogsm_dataset.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdirect_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimise_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[85], line 168\u001b[0m, in \u001b[0;36mDirectFit.optimise_elbo\u001b[0;34m(self, batch_size, num_samples_a, convergence_threshold, optimizer_cls, lr)\u001b[0m\n\u001b[1;32m    165\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfogsm_model\u001b[38;5;241m.\u001b[39mgenerate_fogsm_dataset(batch_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Calculate the ELBO for the mini-batch\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m elbo_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(elbo_batch)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN detected in elbo_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[85], line 116\u001b[0m, in \u001b[0;36mDirectFit.calculate_elbo\u001b[0;34m(self, input_batch, A_samples, duration, dt)\u001b[0m\n\u001b[1;32m    113\u001b[0m elbo \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m I, trajectory \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(input_batch, trajectories): \u001b[38;5;66;03m# trajectory is the trajectory for a single image\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m#print(\"Trajectory shape for single image: \", trajectory.shape)\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     log_p_g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_log_p_g\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m#print(\"Log p_g calculated\")\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     log_p_I_given_g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_log_p_I_given_g(I, trajectory, A_samples)\n",
      "Cell \u001b[0;32mIn[85], line 68\u001b[0m, in \u001b[0;36mDirectFit.calculate_log_p_g\u001b[0;34m(self, trajectory)\u001b[0m\n\u001b[1;32m     66\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m trajectory:\n\u001b[0;32m---> 68\u001b[0m     log_probs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmvg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# log_probs: [num_samples_g]\u001b[39;00m\n\u001b[1;32m     70\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(log_probs, device\u001b[38;5;241m=\u001b[39mtrajectory\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtrajectory\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(log_probs)\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py:246\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m--> 246\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     diff \u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\n\u001b[1;32m    248\u001b[0m     M \u001b[38;5;241m=\u001b[39m _batch_mahalanobis(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbroadcasted_scale_tril, diff)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/distributions/distribution.py:312\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    310\u001b[0m valid \u001b[38;5;241m=\u001b[39m support\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected value argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto be within the support (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(support)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    318\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected value argument (Tensor of shape (72,)) to be within the support (IndependentConstraint(Real(), 1)) of the distribution MultivariateNormal(loc: torch.Size([72]), covariance_matrix: torch.Size([72, 72])), but found invalid values:\ntensor([       nan,        nan,        nan, 2.3147e-03,        nan,        nan,\n               nan,        nan,        nan,        nan,        nan,        nan,\n               nan,        nan,        nan,        nan,        nan, 9.6659e-04,\n        5.4105e-04, 4.1823e-04,        nan,        nan,        nan,        nan,\n        9.5371e-05, 5.1511e-04,        nan,        nan,        nan,        nan,\n        1.5971e-03, 3.1635e-04,        nan,        nan, 7.9127e-04, 3.0797e-03,\n        2.5237e-03, 8.3309e-04,        nan,        nan, 1.9852e-03, 3.1975e-03,\n               nan,        nan,        nan,        nan, 4.7326e-04, 4.1060e-03,\n        3.9048e-03, 2.3637e-03, 7.1334e-03, 1.1836e-03, 1.1492e-03, 7.5205e-04,\n        2.0271e-03, 3.2089e-03,        nan,        nan,        nan,        nan,\n               nan,        nan,        nan,        nan, 3.0704e-03, 3.3934e-03,\n        6.4084e-03, 4.3212e-03, 2.8830e-03,        nan, 5.9421e-04, 3.0603e-03],\n       dtype=torch.float64, grad_fn=<UnbindBackward0>)"
     ]
    }
   ],
   "source": [
    "direct_fit = DirectFit(ssn_params, fogsm_params)\n",
    "\n",
    "# Create an optimiser for the ELBO\n",
    "optimiser = Adam(list(direct_fit.ssn_model.parameters()), lr=0.001)\n",
    "\n",
    "# Run the ELBO optimisation\n",
    "input_data, _ = torch.load(\"fogsm_dataset.pt\")\n",
    "direct_fit.optimise_elbo(batch_size=3, num_samples_a=10, optimizer_cls=Adam, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
