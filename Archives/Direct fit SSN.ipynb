{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct fit SSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio of value at end for surround suppression should be small "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GSM._imports import *\n",
    "from GSM.fogsm import FoGSMModel\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSN._imports import *\n",
    "from SSN.ssn_2dtopoV1 import SSN2DTopoV1\n",
    "from SSN.params import GridParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSNBase(torch.nn.Module):\n",
    "    def __init__(self, n, k, Ne, Ni, tau_e, tau_i, device='cpu', dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.N = self.Ne + self.Ni\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.register_buffer('EI', torch.cat([torch.ones(Ne), torch.zeros(Ni)]).to(device).bool())\n",
    "        self.register_buffer('tau_vec', torch.cat([tau_e * torch.ones(Ne), tau_i * torch.ones(Ni)]).to(device, dtype))\n",
    "    \n",
    "    def drdt(self, r, inp_vec):\n",
    "        return (-r + self.powlaw(self.W @ r + inp_vec)) / self.tau_vec\n",
    "    \n",
    "    def drdt_batch(self, r, inp_vec):\n",
    "        # Ensure r and inp_vec are 2D tensors for batch processing\n",
    "        if r.ndim == 1:\n",
    "            r = r.unsqueeze(0)\n",
    "        if inp_vec.ndim == 1:\n",
    "            inp_vec = inp_vec.unsqueeze(0)\n",
    "\n",
    "        print(f\"drdt: r.shape={r.shape}, inp_vec.shape={inp_vec.shape}, W.shape={self.W.shape}\")\n",
    "\n",
    "        # Compute W @ r for batch processing\n",
    "        W_r = self.W @ r.T\n",
    "        W_r = W_r.T  # Transpose back to match batch dimension\n",
    "    \n",
    "        return (-r + self.powlaw(W_r + inp_vec)) / self.tau_vec\n",
    "    \n",
    "    def dvdt_batch(self, v, inp_vec):\n",
    "        # Ensure v and inp_vec are 2D tensors for batch processing\n",
    "        if v.ndim == 1:\n",
    "            v = v.unsqueeze(0)\n",
    "        if inp_vec.ndim == 1:\n",
    "            inp_vec = inp_vec.unsqueeze(0)\n",
    "\n",
    "        print(f\"dvdt: v.shape={v.shape}, inp_vec.shape={inp_vec.shape}, W.shape={self.W.shape}\")\n",
    "\n",
    "        # Compute W @ r for batch processing\n",
    "        W_r = self.W @ self.powlaw(v).T\n",
    "        W_r = W_r.T  # Transpose back to match batch dimension\n",
    "    \n",
    "        return (-v + W_r + inp_vec) / self.tau_vec\n",
    "\n",
    "    def powlaw(self, u):\n",
    "        return self.k * F.relu(u).pow(self.n)\n",
    "    \n",
    "    def simulate(self, inp_vec, r_init=None, duration=100, dt=0.1):\n",
    "        if r_init is None:\n",
    "            r_init = torch.zeros((self.N,), device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        r = r_init\n",
    "        t = 0\n",
    "        while t < duration:\n",
    "            dr = self.drdt(r, inp_vec)\n",
    "            r += dt * dr\n",
    "            t += dt\n",
    "        return r\n",
    "    \n",
    "    def simulate_batch(self, inp_vec, r_init=None, duration=100, dt=0.1):\n",
    "\n",
    "        # Check if inp_vec is a batch of inputs\n",
    "        batch_size = inp_vec.shape[0] if inp_vec.ndim > 1 else 1\n",
    "        print(f\"simulate: batch_size={batch_size}, inp_vec.shape={inp_vec.shape}\")\n",
    "\n",
    "    \n",
    "        # Initialize r_init if not provided\n",
    "        if r_init is None:\n",
    "            r_init = torch.zeros((batch_size, self.N), device=self.device, dtype=self.dtype)\n",
    "        else:\n",
    "            if isinstance(r_init, int):\n",
    "                r_init = torch.zeros((batch_size, self.N), device=self.device, dtype=self.dtype)\n",
    "            if r_init.shape[0] != batch_size or r_init.shape[1] != self.N:\n",
    "                raise ValueError(\"r_init shape does not match batch_size or neuron count N.\")\n",
    "    \n",
    "    \n",
    "        r = r_init\n",
    "        t = 0\n",
    "        while t < duration:\n",
    "            # Calculate dr for each element in the batch\n",
    "            dr = self.dvdt_batch(r, inp_vec)\n",
    "            print(f\"t={t}, r.shape={r.shape}, dr.shape={dr.shape}\")\n",
    "\n",
    "            r += dt * dr\n",
    "            t += dt\n",
    "    \n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSN2DTopo(SSNBase):\n",
    "    def __init__(self, n, k, tauE, tauI, grid_pars, thetas, L = np.pi,device='cpu', dtype=torch.float64):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialises the SSN2DTopo model, which represents a two-dimensional topographic Stabilized Supralinear Network (SSN).\n",
    "\n",
    "        Args:\n",
    "            n (float): The power law exponent for the activation function, typically chosen between 1 and 2 to model the supralinear response properties of cortical neurons.\n",
    "            k (float): The gain factor for the activation function, which scales the overall activity levels of the network.\n",
    "            tauE (float): The time constant for excitatory neurons, reflecting their temporal integration properties.\n",
    "            tauI (float): The time constant for inhibitory neurons, typically shorter than tauE to model faster inhibition dynamics.\n",
    "            grid_pars (dict): Dictionary containing grid parameters, such as the grid size.\n",
    "            conn_pars (dict): Dictionary containing connectivity parameters, such as the number of orientations.\n",
    "            thetas (numpy.ndarray): Array of orientation values representing the preferred orientations of neurons.\n",
    "            L (float, optional): Range of orientation values (default: np.pi).\n",
    "            device (str, optional): Device to use for tensor operations (default: 'cpu').\n",
    "            dtype (torch.dtype, optional): Data type for tensors (default: torch.float64).\n",
    "        \"\"\"\n",
    "         \n",
    "        num_orientations = thetas.shape[0]\n",
    "        grid_size = grid_pars['grid_size_Nx']\n",
    "                \n",
    "        Ne = num_orientations * (grid_size ** 2)\n",
    "        Ni = num_orientations * (grid_size ** 2)\n",
    "\n",
    "        super(SSN2DTopo, self).__init__(n=n, k=k, Ne=Ne, Ni=Ni, tau_e=tauE, tau_i=tauI, device=device, dtype=dtype)\n",
    "        \n",
    "        self.num_orientations = num_orientations\n",
    "        self.grid_size = grid_size\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.L = L\n",
    "        self._make_maps(thetas)\n",
    "        \n",
    "        # Initialise trainable parameters\n",
    "        self.J_2x2 = nn.Parameter(torch.rand(2, 2, device=device, dtype=dtype)) # Interaction strengths\n",
    "        self.s_2x2 = nn.Parameter(torch.rand(2, 2, device=device, dtype=dtype)) # Spatial length scales\n",
    "        self.p_local = nn.Parameter(torch.rand(2, device=device, dtype=dtype)) # Local connectivity strengths - set to 0?\n",
    "        self.sigma_oris = nn.Parameter(torch.rand(1, device=device, dtype=dtype)) # Orientation tuning width\n",
    "        \n",
    "        self.make_W()\n",
    "\n",
    "    def _make_maps(self,thetas):\n",
    "        \"\"\"\n",
    "        Creates orientation and spatial maps for the SSN2DTopo model.\n",
    "\n",
    "        Args:\n",
    "            thetas (numpy.ndarray): Array of orientation values representing the preferred orientations of neurons.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ori_map = torch.tensor(thetas, device=self.device, dtype=self.dtype).flatten()\n",
    "        self.ori_vec = self.ori_map.repeat(self.grid_size ** 2)  # Repeat orientation values for each grid cell\n",
    "        self.ori_vec = self.ori_vec.repeat(2) # Repeat for E and I populations\n",
    "\n",
    "        # Create x and y vectors for grid cells\n",
    "        self.x_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations).repeat(self.grid_size)\n",
    "        self.y_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations * self.grid_size)\n",
    "\n",
    "        # Repeat for E and I populations\n",
    "        self.x_vec = self.x_vec.repeat(2)\n",
    "        self.y_vec = self.y_vec.repeat(2)\n",
    "\n",
    "    def make_W(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Computes the weight matrix W for the network, representing the strength of connections between neurons.\n",
    "\n",
    "        The weight matrix W is constructed from four submatrices (W_ee, W_ei, W_ie, W_ii), computed based on the spatial and orientation distances between neurons, \n",
    "        as well as the length scale parameters (s_2x2 and sigma_oris) and local connectivity strengths (p_local).\n",
    "        \"\"\"\n",
    "        \n",
    "        xy_dist = self.calc_xy_dist()\n",
    "        ori_dist = self.calc_ori_dist()\n",
    "        print(f\"xy_dist.shape: {xy_dist.shape}, ori_dist.shape: {ori_dist.shape}\")\n",
    "\n",
    "        # Compute weight blocks\n",
    "        W_ee = self.calc_W_block(xy_dist[:self.Ne, :self.Ne], ori_dist[:self.Ne, :self.Ne], self.s_2x2[0][0], self.sigma_oris)\n",
    "        W_ei = self.calc_W_block(xy_dist[:self.Ne, self.Ne:], ori_dist[:self.Ne, self.Ne:], self.s_2x2[0][1], self.sigma_oris)\n",
    "        W_ie = self.calc_W_block(xy_dist[self.Ne:, :self.Ne], ori_dist[self.Ne:, :self.Ne], self.s_2x2[1][0], self.sigma_oris)\n",
    "        W_ii = self.calc_W_block(xy_dist[self.Ne:, self.Ne:], ori_dist[self.Ne:, self.Ne:], self.s_2x2[1][1], self.sigma_oris)\n",
    "        print(f\"W_ee.shape: {W_ee.shape}, W_ei.shape: {W_ei.shape}, W_ie.shape: {W_ie.shape}, W_ii.shape: {W_ii.shape}\")\n",
    "\n",
    "        \n",
    "        # Apply local connectivity strengths\n",
    "        W_ee = self.p_local[0] * torch.eye(self.Ne, device=self.device, dtype=self.dtype) + (1 - self.p_local[0]) * W_ee\n",
    "        W_ei = self.p_local[1] * torch.eye(self.Ni, device=self.device, dtype=self.dtype) + (1 - self.p_local[1]) * W_ei\n",
    "        \n",
    "        # Concatenate submatrices to form W\n",
    "        W = torch.cat([\n",
    "            torch.cat([self.J_2x2[0, 0] * W_ee, self.J_2x2[0, 1] * W_ei], dim=1),\n",
    "            torch.cat([self.J_2x2[1, 0] * W_ie, self.J_2x2[1, 1] * W_ii], dim=1)\n",
    "        ], dim=0).double()\n",
    "\n",
    "        # Register W as a buffer\n",
    "        self.register_buffer('W', W)\n",
    "\n",
    "        print(\"W shape:\", W.shape)\n",
    "        \n",
    "        return self.W\n",
    "    \n",
    "    def calc_xy_dist(self):\n",
    "        Ne = Ni = self.Ne\n",
    "        x_vec_e = self.x_vec[:Ne]\n",
    "        y_vec_e = self.y_vec[:Ne]\n",
    "        x_vec_i = self.x_vec[Ne:Ne+Ni]\n",
    "        y_vec_i = self.y_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        xy_dist = torch.cdist(torch.stack([x_vec_e, y_vec_e], dim=1), torch.stack([x_vec_i, y_vec_i], dim=1), p=2).repeat(2, 2) #Distance Squared\n",
    "\n",
    "        return xy_dist\n",
    "    \n",
    "    def calc_ori_dist(self,L=np.pi, method=None):\n",
    "\n",
    "        Ne = Ni = self.num_orientations * self.grid_size ** 2\n",
    "        \n",
    "        ori_vec_e = self.ori_vec[:Ne]\n",
    "        ori_vec_i = self.ori_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        # define everything as squared distance ori_sqdist = (ori_vec_e - ori_vec_i) ** 2\n",
    "        if method == \"absolute\":\n",
    "            ori_dist = torch.cdist(ori_vec_e.unsqueeze(1), ori_vec_i.unsqueeze(1)).repeat(2,2)\n",
    "        elif method == \"cos\":\n",
    "            ori_vec_e_norm = ori_vec_e / ori_vec_e.norm(dim=1, keepdim=True)\n",
    "            ori_vec_i_norm = ori_vec_i / ori_vec_i.norm(dim=1, keepdim=True)\n",
    "            ori_dist = 1 - torch.mm(ori_vec_e_norm, ori_vec_i_norm.t())\n",
    "        else:\n",
    "            #1 - cos(2(pi/L) * |theta1 - theta2|^2)\n",
    "            ori_dist = (1 - torch.cos((2 * np.pi / L) * (ori_vec_e.unsqueeze(1) - ori_vec_i.unsqueeze(0))**2)) / (2 * np.pi / L)**2\n",
    "\n",
    "            #ori_vec[:,None] - ori_ve\n",
    "        \n",
    "        ori_dist = ori_dist.repeat(2, 2)\n",
    "\n",
    "        return ori_dist\n",
    "\n",
    "    def calc_W_block(self, xy_dist, ori_dist, s, sigma_oris, CellWiseNormalised = True):\n",
    "\n",
    "        \"\"\"\n",
    "        Computes a weight block for the weight matrix W.\n",
    "\n",
    "        Args:\n",
    "            xy_dist (torch.Tensor): Distance matrix between grid cells.\n",
    "            ori_dist (torch.Tensor): Orientation distance matrix.\n",
    "            s (float): Length scale parameter for the spatial kernel.\n",
    "            sigma_oris (float): Length scale parameter for the orientation kernel.\n",
    "            CellWiseNormalised (bool, optional): Whether to perform cell-wise normalization (default: True).\n",
    "\n",
    "        Returns:\n",
    "            W (torch.Tensor): Weight block.\n",
    "        \"\"\"\n",
    "\n",
    "        #Add a small constant to s and sigma_oris to avoid division by zero\n",
    "        s = s + 1e-8\n",
    "        sigma_oris = 2*np.pi*sigma_oris/self.L + 1e-8\n",
    "        \n",
    "        W =  torch.exp(-xy_dist / s - ori_dist ** 2 / (2 * sigma_oris ** 2))\n",
    "        #print(f\"calc_W_block before sparse: xy_dist.shape={xy_dist.shape}, ori_dist.shape={ori_dist.shape}, W.shape={W.shape}\")\n",
    "        W = torch.where(W < 1e-4, torch.zeros_like(W), W)\n",
    "        #print(f\"calc_W_block after sparse: xy_dist.shape={xy_dist.shape}, ori_dist.shape={ori_dist.shape}, W.shape={W.shape}\")\n",
    "\n",
    "        \n",
    "        sW = torch.sum(W, dim=1, keepdim=True)\n",
    "        if CellWiseNormalised:\n",
    "            W = W / sW\n",
    "        else:\n",
    "            sW = sW.mean()\n",
    "            W = W / sW\n",
    "        #print(f\"calc_W_block: xy_dist.shape={xy_dist.shape}, ori_dist.shape={ori_dist.shape}, W.shape={W.shape}\")\n",
    "\n",
    "        return W.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        super(DirectFit, self).__init__()\n",
    "        self.ssn_model = SSN2DTopo(**ssn_params)\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "    def sample_trajectories(self, input_batch, num_samples_g, duration=500, dt=1):\n",
    "        batch_size = input_batch.shape[0]\n",
    "        print(\"Batch size: \", batch_size)\n",
    "    \n",
    "        print(\"Input shape: \", input_batch.shape)\n",
    "        # Expand input_batch to match the number of samples\n",
    "        input_expanded = input_batch.unsqueeze(1).expand(batch_size, num_samples_g, *input_batch.shape[1:])\n",
    "        print(input_expanded)\n",
    "        print(\"Input expanded shape: \", input_expanded.shape)\n",
    "\n",
    "        #TODO: take the input batch (which should be 72*72) and multiply it by C_E and C_I to get the input to the network (both should be optimised)\n",
    "        #TODO: duplex the input into on and off channels (RELU and -RELU)\n",
    "        #TODO: ignore the phase - phase preference is not important for the model\n",
    "\n",
    "        # Reshape input_expanded to (batch_size * num_samples, input_size)\n",
    "        #input_reshaped = input_expanded.reshape(-1, *input_batch.shape[1:])\n",
    "        #input_reshaped = input_expanded.reshape(batch_size * num_samples_g, -1)\n",
    "\n",
    "        # Calculate total neurons per grid point (16 neurons per grid point: 8 excitatory + 8 inhibitory)\n",
    "        neurons_per_grid_point = 2 * self.ssn_model.num_orientations\n",
    "        grid_height, grid_width = input_batch.shape[1], input_batch.shape[2]\n",
    "        total_neurons = grid_height * grid_width * neurons_per_grid_point  # 3*3*16 = 144\n",
    "\n",
    "        # Reshape input_expanded to (batch_size * num_samples, total_neurons)\n",
    "        input_reshaped = input_expanded.reshape(batch_size * num_samples_g, total_neurons)\n",
    "        print(\"Input reshaped shape: \", input_reshaped.shape)\n",
    "\n",
    "\n",
    "\n",
    "        # Ensure input_reshaped has correct dimensions before calling simulate\n",
    "        if input_reshaped.shape[1] != self.ssn_model.N:\n",
    "            input_reshaped = input_reshaped.view(input_reshaped.shape[0], self.ssn_model.N)\n",
    "\n",
    "        # Generate trajectories for the reshaped input\n",
    "        trajectories = self.ssn_model.simulate_batch(input_reshaped, duration, dt)\n",
    "        print(\"Trajectories shape after simulation: \", trajectories.shape)\n",
    "\n",
    "        # Reshape trajectories to (batch_size, num_samples, N)\n",
    "        trajectories = trajectories.reshape(batch_size, num_samples_g)\n",
    "        print(\"Trajectories final shape: \", trajectories.shape)\n",
    "\n",
    "        return trajectories\n",
    "\n",
    "    def calculate_log_p_g(self, trajectories):\n",
    "        mu = torch.zeros_like(trajectories[0])\n",
    "        log_p_g = MultivariateNormal(mu, self.fogsm_model.K_g).log_prob(trajectories).mean()\n",
    "        return log_p_g\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, I_data, trajectories, A_samples):\n",
    "        \n",
    "        # Calculate log p(I|g,A) for each sample\n",
    "        # log_likelihood = []\n",
    "        # for a in A_samples:\n",
    "        #     log_p = 0\n",
    "        #     for g in trajectories:\n",
    "        #         # I shouyld come from the dataset \n",
    "        #         I = g * a\n",
    "        #         log_p += self.fogsm_model.log_likelihood(I,g,A)\n",
    "        #     log_likelihood.append(log_p / len(trajectories))\n",
    "        \n",
    "        # log_likelihood = []\n",
    "        # for g in trajectories:\n",
    "        #     p_I_g = 0\n",
    "        #     for a in A_samples:\n",
    "        #         # I shouyld come from the dataset \n",
    "        #         I = I_data\n",
    "        #         p_I_g += self.fogsm_model.likelihood(I,g,A)\n",
    "        #     log_likelihood.append(torch.log(p_I_g / len(A_samples)))\n",
    "            \n",
    "        log_likelihood = 0\n",
    "        for g in trajectories:\n",
    "            p_I_g = 0\n",
    "            for a in A_samples:\n",
    "                # I shouyld come from the dataset \n",
    "                I = I_data\n",
    "                p_I_g = p_I_g + self.fogsm_model.likelihood(I, g, A)\n",
    "            log_likelihood = log_likelihood + torch.log(p_I_g / len(A_samples))\n",
    "\n",
    "        return log_likelihood / len(trajectories)\n",
    "    \n",
    "        # # Approximate the expectation over A using Monte Carlo sampling\n",
    "        # p_I_given_g = torch.exp(torch.stack(log_likelihood)).mean()\n",
    "        # log_p_I_given_g = torch.log(p_I_given_g)\n",
    "\n",
    "        # return log_p_I_given_g\n",
    "        \n",
    "\n",
    "    def calculate_elbo(self, input_batch, num_samples_g, A_samples, duration=500, dt=1):\n",
    "\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories = self.sample_trajectories(input_batch, num_samples_g, duration, dt)\n",
    "\n",
    "        elbo = 0\n",
    "        for I, trajectory in zip(input_batch, trajectories): # trajectory is the trajectory for a single image\n",
    "\n",
    "        # Calculate the first two terms of the ELBO using Monte Carlo approximation\n",
    "            log_p_g = self.calculate_log_p_g(trajectories)\n",
    "            log_p_I_given_g = self.calculate_log_p_I_given_g(I, trajectory, A_samples)\n",
    "\n",
    "        # Approximate the entropy term\n",
    "        # cov_matrix = torch.cov(trajectories.reshape(num_samples_g, -1).T)\n",
    "\n",
    "            cov_matrix = torch.cov(trajectory.reshape(trajectory.shape[0], -1))\n",
    "            entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "\n",
    "            elbo = elbo + log_p_g + log_p_I_given_g - entropy_term\n",
    "\n",
    "        return elbo / len(input_batch)\n",
    "        \n",
    "    def optimise_elbo(self, batch_size, num_samples_a, num_samples_g, convergence_threshold=1e-3, optimizer=Adam):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.ssn_model.to(device)\n",
    "        self.fogsm_model.to(device)\n",
    "\n",
    "        batch = 0\n",
    "        prev_elbo = float('-inf')\n",
    "\n",
    "        while True:\n",
    "            elbo_batch = 0\n",
    "\n",
    "            # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "            A_samples = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "\n",
    "            # Generate a mini-batch of input data\n",
    "            input_batch = self.fogsm_model.generate_fogsm_dataset(batch_size)\n",
    "\n",
    "            # Calculate the ELBO for the mini-batch\n",
    "            elbo_batch = self.calculate_elbo(input_batch, num_samples_g, A_samples)\n",
    "            elbo += elbo_batch.item()\n",
    "\n",
    "            # Optimise the ELBO with respect to the model parameters\n",
    "            elbo.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Print the ELBO for monitoring\n",
    "            if (batch + 1) % 100 == 0:\n",
    "                print(f\"Batch [{batch+1}], ELBO: {elbo_batch / batch_size:.4f}\")\n",
    "\n",
    "            # Check for convergence\n",
    "            if abs(elbo_batch - prev_elbo) < convergence_threshold:\n",
    "                print(f\"Converged after {batch+1} batches.\")\n",
    "                break\n",
    "\n",
    "            prev_elbo = elbo_batch\n",
    "            batch += 1\n",
    "        \n",
    "        return self.ssn_model, self.fogsm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khushu/Desktop/IIB_Project FoGSM 2dSSN/GSM/fogsm.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1)\n",
      "/Users/khushu/Desktop/IIB_Project FoGSM 2dSSN/GSM/fogsm.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the parameters for the FoGSM model\n",
    "thetas = torch.linspace(0, 2 * torch.pi, 8)  # 8 orientations from 0 to 2*pi\n",
    "fogsm_params = {\n",
    "        \"thetas\": thetas,\n",
    "        \"length_scale_feature\": 0.5,\n",
    "        \"length_scale_amplitude\": 1.2,\n",
    "        \"kappa\": 1.0,\n",
    "        \"jitter\": 1e-4,\n",
    "        \"grid_size\": 3,\n",
    "        \"frequency\": 0.9,\n",
    "        \"sigma\": 0.1,\n",
    "    }\n",
    "fogsm_model = FoGSMModel(**fogsm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set network parameters\n",
    "n = 2\n",
    "k = 0.4\n",
    "tauE = 20.0\n",
    "tauI = 10.0\n",
    "grid_pars = {'grid_size_Nx': 3}\n",
    "conn_pars = {'num_orientations': 8}\n",
    "thetas = np.linspace(0, np.pi, conn_pars['num_orientations'])\n",
    "\n",
    "ssn_params = {\n",
    "        \"n\": 2,\n",
    "        \"k\": 0.04,\n",
    "        \"tauE\": 20,\n",
    "        \"tauI\": 10,\n",
    "        \"grid_pars\": grid_pars,\n",
    "        \"thetas\": thetas,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xy_dist.shape: torch.Size([144, 144]), ori_dist.shape: torch.Size([144, 144])\n",
      "W_ee.shape: torch.Size([72, 72]), W_ei.shape: torch.Size([72, 72]), W_ie.shape: torch.Size([72, 72]), W_ii.shape: torch.Size([72, 72])\n",
      "W shape: torch.Size([144, 144])\n",
      "Batch size:  32\n",
      "Input shape:  torch.Size([32, 3, 3])\n",
      "tensor([[[[-39.7896,  -5.3572, -18.7189],\n",
      "          [  2.9520,  58.4735,  -0.1313],\n",
      "          [ -4.9396,   6.8304, -18.0139]],\n",
      "\n",
      "         [[-39.7896,  -5.3572, -18.7189],\n",
      "          [  2.9520,  58.4735,  -0.1313],\n",
      "          [ -4.9396,   6.8304, -18.0139]],\n",
      "\n",
      "         [[-39.7896,  -5.3572, -18.7189],\n",
      "          [  2.9520,  58.4735,  -0.1313],\n",
      "          [ -4.9396,   6.8304, -18.0139]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-39.7896,  -5.3572, -18.7189],\n",
      "          [  2.9520,  58.4735,  -0.1313],\n",
      "          [ -4.9396,   6.8304, -18.0139]],\n",
      "\n",
      "         [[-39.7896,  -5.3572, -18.7189],\n",
      "          [  2.9520,  58.4735,  -0.1313],\n",
      "          [ -4.9396,   6.8304, -18.0139]],\n",
      "\n",
      "         [[-39.7896,  -5.3572, -18.7189],\n",
      "          [  2.9520,  58.4735,  -0.1313],\n",
      "          [ -4.9396,   6.8304, -18.0139]]],\n",
      "\n",
      "\n",
      "        [[[-10.7435, -26.4543, -33.2106],\n",
      "          [-20.5472,   4.8740,  -5.7136],\n",
      "          [ -1.9564, 121.3371,  -3.6615]],\n",
      "\n",
      "         [[-10.7435, -26.4543, -33.2106],\n",
      "          [-20.5472,   4.8740,  -5.7136],\n",
      "          [ -1.9564, 121.3371,  -3.6615]],\n",
      "\n",
      "         [[-10.7435, -26.4543, -33.2106],\n",
      "          [-20.5472,   4.8740,  -5.7136],\n",
      "          [ -1.9564, 121.3371,  -3.6615]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-10.7435, -26.4543, -33.2106],\n",
      "          [-20.5472,   4.8740,  -5.7136],\n",
      "          [ -1.9564, 121.3371,  -3.6615]],\n",
      "\n",
      "         [[-10.7435, -26.4543, -33.2106],\n",
      "          [-20.5472,   4.8740,  -5.7136],\n",
      "          [ -1.9564, 121.3371,  -3.6615]],\n",
      "\n",
      "         [[-10.7435, -26.4543, -33.2106],\n",
      "          [-20.5472,   4.8740,  -5.7136],\n",
      "          [ -1.9564, 121.3371,  -3.6615]]],\n",
      "\n",
      "\n",
      "        [[[-73.1699, -11.9331,  -3.0778],\n",
      "          [ -3.1196,  46.9933,  -8.3186],\n",
      "          [-26.8420, -47.7548, -41.8533]],\n",
      "\n",
      "         [[-73.1699, -11.9331,  -3.0778],\n",
      "          [ -3.1196,  46.9933,  -8.3186],\n",
      "          [-26.8420, -47.7548, -41.8533]],\n",
      "\n",
      "         [[-73.1699, -11.9331,  -3.0778],\n",
      "          [ -3.1196,  46.9933,  -8.3186],\n",
      "          [-26.8420, -47.7548, -41.8533]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-73.1699, -11.9331,  -3.0778],\n",
      "          [ -3.1196,  46.9933,  -8.3186],\n",
      "          [-26.8420, -47.7548, -41.8533]],\n",
      "\n",
      "         [[-73.1699, -11.9331,  -3.0778],\n",
      "          [ -3.1196,  46.9933,  -8.3186],\n",
      "          [-26.8420, -47.7548, -41.8533]],\n",
      "\n",
      "         [[-73.1699, -11.9331,  -3.0778],\n",
      "          [ -3.1196,  46.9933,  -8.3186],\n",
      "          [-26.8420, -47.7548, -41.8533]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.6031,  -3.5963, -32.3277],\n",
      "          [-23.0766,   2.4177, -53.2350],\n",
      "          [-42.2902, -82.0499, -26.2404]],\n",
      "\n",
      "         [[-15.6031,  -3.5963, -32.3277],\n",
      "          [-23.0766,   2.4177, -53.2350],\n",
      "          [-42.2902, -82.0499, -26.2404]],\n",
      "\n",
      "         [[-15.6031,  -3.5963, -32.3277],\n",
      "          [-23.0766,   2.4177, -53.2350],\n",
      "          [-42.2902, -82.0499, -26.2404]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-15.6031,  -3.5963, -32.3277],\n",
      "          [-23.0766,   2.4177, -53.2350],\n",
      "          [-42.2902, -82.0499, -26.2404]],\n",
      "\n",
      "         [[-15.6031,  -3.5963, -32.3277],\n",
      "          [-23.0766,   2.4177, -53.2350],\n",
      "          [-42.2902, -82.0499, -26.2404]],\n",
      "\n",
      "         [[-15.6031,  -3.5963, -32.3277],\n",
      "          [-23.0766,   2.4177, -53.2350],\n",
      "          [-42.2902, -82.0499, -26.2404]]],\n",
      "\n",
      "\n",
      "        [[[ 42.9244,  20.0911,  28.8535],\n",
      "          [-20.2552,  15.0270,  24.8701],\n",
      "          [-55.2348, -48.2179, -48.7964]],\n",
      "\n",
      "         [[ 42.9244,  20.0911,  28.8535],\n",
      "          [-20.2552,  15.0270,  24.8701],\n",
      "          [-55.2348, -48.2179, -48.7964]],\n",
      "\n",
      "         [[ 42.9244,  20.0911,  28.8535],\n",
      "          [-20.2552,  15.0270,  24.8701],\n",
      "          [-55.2348, -48.2179, -48.7964]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 42.9244,  20.0911,  28.8535],\n",
      "          [-20.2552,  15.0270,  24.8701],\n",
      "          [-55.2348, -48.2179, -48.7964]],\n",
      "\n",
      "         [[ 42.9244,  20.0911,  28.8535],\n",
      "          [-20.2552,  15.0270,  24.8701],\n",
      "          [-55.2348, -48.2179, -48.7964]],\n",
      "\n",
      "         [[ 42.9244,  20.0911,  28.8535],\n",
      "          [-20.2552,  15.0270,  24.8701],\n",
      "          [-55.2348, -48.2179, -48.7964]]],\n",
      "\n",
      "\n",
      "        [[[-30.7475,  -3.7643,  14.5901],\n",
      "          [ 35.0527,  42.2063,  -3.0394],\n",
      "          [ 40.4902,  22.9399,   6.3662]],\n",
      "\n",
      "         [[-30.7475,  -3.7643,  14.5901],\n",
      "          [ 35.0527,  42.2063,  -3.0394],\n",
      "          [ 40.4902,  22.9399,   6.3662]],\n",
      "\n",
      "         [[-30.7475,  -3.7643,  14.5901],\n",
      "          [ 35.0527,  42.2063,  -3.0394],\n",
      "          [ 40.4902,  22.9399,   6.3662]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-30.7475,  -3.7643,  14.5901],\n",
      "          [ 35.0527,  42.2063,  -3.0394],\n",
      "          [ 40.4902,  22.9399,   6.3662]],\n",
      "\n",
      "         [[-30.7475,  -3.7643,  14.5901],\n",
      "          [ 35.0527,  42.2063,  -3.0394],\n",
      "          [ 40.4902,  22.9399,   6.3662]],\n",
      "\n",
      "         [[-30.7475,  -3.7643,  14.5901],\n",
      "          [ 35.0527,  42.2063,  -3.0394],\n",
      "          [ 40.4902,  22.9399,   6.3662]]]], grad_fn=<ExpandBackward0>)\n",
      "Input expanded shape:  torch.Size([32, 100, 3, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3200, 144]' is invalid for input of size 28800",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run the ELBO optimisation\u001b[39;00m\n\u001b[1;32m      7\u001b[0m input_data, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfogsm_dataset.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdirect_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimise_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimiser\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[224], line 105\u001b[0m, in \u001b[0;36mDirectFit.optimise_elbo\u001b[0;34m(self, batch_size, num_samples_a, num_samples_g, convergence_threshold, optimizer)\u001b[0m\n\u001b[1;32m    102\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfogsm_model\u001b[38;5;241m.\u001b[39mgenerate_fogsm_dataset(batch_size)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Calculate the ELBO for the mini-batch\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m elbo_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m elbo \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m elbo_batch\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Optimise the ELBO with respect to the model parameters\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[224], line 71\u001b[0m, in \u001b[0;36mDirectFit.calculate_elbo\u001b[0;34m(self, input_batch, num_samples_g, A_samples, duration, dt)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_elbo\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_batch, num_samples_g, A_samples, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Sample trajectories from the SSN\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     trajectories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# Calculate the first two terms of the ELBO using Monte Carlo approximation\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     log_p_g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_log_p_g(trajectories)\n",
      "Cell \u001b[0;32mIn[224], line 29\u001b[0m, in \u001b[0;36mDirectFit.sample_trajectories\u001b[0;34m(self, input_batch, num_samples_g, duration, dt)\u001b[0m\n\u001b[1;32m     26\u001b[0m total_neurons \u001b[38;5;241m=\u001b[39m grid_height \u001b[38;5;241m*\u001b[39m grid_width \u001b[38;5;241m*\u001b[39m neurons_per_grid_point  \u001b[38;5;66;03m# 3*3*16 = 144\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Reshape input_expanded to (batch_size * num_samples, total_neurons)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m input_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43minput_expanded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_samples_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_neurons\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput reshaped shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m, input_reshaped\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Ensure input_reshaped has correct dimensions before calling simulate\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3200, 144]' is invalid for input of size 28800"
     ]
    }
   ],
   "source": [
    "direct_fit = DirectFit(ssn_params, fogsm_params)\n",
    "\n",
    "# Create an optimiser for the ELBO\n",
    "optimiser = Adam(list(direct_fit.ssn_model.parameters()), lr=0.001)\n",
    "\n",
    "# Run the ELBO optimisation\n",
    "input_data, _ = torch.load(\"fogsm_dataset.pt\")\n",
    "direct_fit.optimise_elbo(batch_size=32, num_samples_a=10, num_samples_g=100, optimizer=optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SSN2DTopoV1\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "# Define the parameters for the SSN model\n",
    "grid_pars = GridParameters(\n",
    "    gridsize_Nx=17,  # Number of grid points in one dimension\n",
    "    gridsize_deg=3.2,  # Size of the grid in degrees of visual angle\n",
    "    magnif_factor=2,  # Magnification factor to convert degrees to mm\n",
    "    hyper_col=800,  # Hypercolumn\n",
    "    )\n",
    "psi = torch.tensor(0.774)\n",
    "conn_pars = {\n",
    "        'J_2x2': torch.tensor([[1.124, -0.931], [1.049, -0.537]], dtype=torch.float64) * torch.pi * psi,\n",
    "        's_2x2': torch.tensor([[0.2955, 0.09], [0.5542, 0.09]]),\n",
    "        'p_local': [0.72, 0.7],\n",
    "        'sigma_oris': 45,\n",
    "    }\n",
    "ssn_params = {\n",
    "        \"n\": 2,\n",
    "        \"k\": 0.04,\n",
    "        \"tauE\": 20,\n",
    "        \"tauI\": 10,\n",
    "        \"grid_pars\": grid_pars,\n",
    "        \"conn_pars\": conn_pars,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbatched DirectFit archived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        self.ssn_model = SSN2DTopoV1(**ssn_params)\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "    def sample_trajectories(self, input, num_samples, duration=500, dt=1):\n",
    "        trajectories = []\n",
    "        for _ in range(num_samples):\n",
    "            traj = self.ssn_model.run_simulation(input, duration, dt)\n",
    "            trajectories.append(traj)\n",
    "        return torch.stack(trajectories)\n",
    "\n",
    "    def calculate_log_p_g(self, trajectories):\n",
    "        mu = torch.zeros_like(trajectories[0])\n",
    "        log_p_g = MultivariateNormal(mu, self.fogsm_model.K_g).log_prob(trajectories).mean()\n",
    "        return log_p_g\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, trajectories, num_samples_a=10):\n",
    "        # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "        amplitude_fields = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "        \n",
    "        # Calculate log p(I|g,A) for each sample\n",
    "        log_likelihood = []\n",
    "        for a in amplitude_fields:\n",
    "            log_p = 0\n",
    "            for g in trajectories:\n",
    "                I = g * a\n",
    "                log_p += self.fogsm_model.log_likelihood(I)\n",
    "            log_likelihood.append(log_p / len(trajectories))\n",
    "        \n",
    "        # Approximate the expectation over A using Monte Carlo sampling\n",
    "        p_I_given_g = torch.exp(torch.stack(log_likelihood)).mean()\n",
    "        log_p_I_given_g = torch.log(p_I_given_g)\n",
    "\n",
    "        return log_p_I_given_g\n",
    "\n",
    "    def calculate_elbo(self, input, num_samples, duration=500, dt=1):\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories = self.sample_trajectories(input, num_samples, duration, dt)\n",
    "        \n",
    "        # Calculate the first two terms of the ELBO using Monte Carlo approximation\n",
    "        log_p_g = self.calculate_log_p_g(trajectories)\n",
    "        log_p_I_given_g = self.calculate_log_p_I_given_g(trajectories)\n",
    "        \n",
    "        # Approximate the entropy term\n",
    "        cov_matrix = torch.cov(trajectories.reshape(num_samples, -1).T)\n",
    "        entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "        \n",
    "        elbo = log_p_g + log_p_I_given_g - entropy_term\n",
    "        return elbo\n",
    "\n",
    "    def optimise_elbo(self, input, num_samples, num_epochs, optimizer):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Calculate the ELBO\n",
    "            elbo = self.calculate_elbo(input, num_samples)\n",
    "            \n",
    "            #resample As for each minibatch\n",
    "\n",
    "            # Optimise the ELBO with respect to the model parameters\n",
    "            elbo.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Print the ELBO for monitoring\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], ELBO: {elbo.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
