{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch related imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data visualisation and numerical computing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Network analysis\n",
    "import networkx as nx\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Additional useful imports\n",
    "import pandas as pd  \n",
    "import seaborn as sns  \n",
    "import os  \n",
    "import sys  \n",
    "import logging  \n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSNBase(torch.nn.Module):\n",
    "    def __init__(self, n, k, Ne, Ni, tau_e, tau_i, device='cpu', dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.N = self.Ne + self.Ni\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.register_buffer('EI', torch.cat([torch.ones(Ne), torch.zeros(Ni)]).to(device).bool())\n",
    "        self.register_buffer('tau_vec', torch.cat([tau_e * torch.ones(Ne), tau_i * torch.ones(Ni)]).to(device, dtype))\n",
    "        self.W = torch.nn.Parameter(torch.zeros((self.N, self.N), device=device, dtype=dtype))\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def drdt(self, r, inp_vec):\n",
    "        return (-r + self.powlaw(self.W @ r + inp_vec)) / self.tau_vec\n",
    "    \n",
    "    def powlaw(self, u):\n",
    "        return self.k * F.relu(u).pow(self.n)\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def simulate(self, inp_vec, r_init=None, t_final=100, dt=0.1):\n",
    "        if r_init is None:\n",
    "            r_init = torch.zeros((self.N,), device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        r = r_init\n",
    "        t = 0\n",
    "        while t < t_final:\n",
    "            dr = self.drdt(r, inp_vec)\n",
    "            r += dt * dr\n",
    "            t += dt\n",
    "        return r\n",
    "    \n",
    "    def jacobian(self, r):\n",
    "        Phi = self.gains_from_r(r)\n",
    "        return -torch.eye(self.N, device=self.device, dtype=self.dtype) + Phi[:, None] * self.W\n",
    "    \n",
    "    def gains_from_r(self, r):\n",
    "        return self.n * self.k**(1/self.n) * r.pow(1 - 1/self.n)\n",
    "    \n",
    "    def fixed_point(self, inp_vec, tol=1e-6, max_iter=1000):\n",
    "        r = torch.zeros((self.N,), device=self.device, dtype=self.dtype)\n",
    "        for _ in range(max_iter):\n",
    "            dr = self.drdt(r, inp_vec)\n",
    "            r_new = r + dr\n",
    "            if torch.norm(r_new - r) < tol:\n",
    "                return r_new\n",
    "            r = r_new\n",
    "        raise RuntimeError(f\"Fixed point not found after {max_iter} iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSN2DTopo(SSNBase):\n",
    "    def __init__(self, n, k, tauE, tauI, grid_pars, conn_pars, thetas, device='cpu', dtype=torch.float64):\n",
    "        num_orientations = thetas.shape[0]\n",
    "        grid_size = grid_pars['grid_size_Nx']\n",
    "        \n",
    "        Ne = num_orientations * (grid_size ** 2)\n",
    "        Ni = num_orientations * (grid_size ** 2)\n",
    "\n",
    "        super(SSN2DTopo, self).__init__(n=n, k=k, Ne=Ne, Ni=Ni, tau_e=tauE, tau_i=tauI, device=device, dtype=dtype)\n",
    "        \n",
    "        self.num_orientations = num_orientations\n",
    "        self.grid_size = grid_size\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self._make_maps(thetas)\n",
    "        \n",
    "        self.J_2x2 = nn.Parameter(torch.rand(2, 2, device=device, dtype=dtype))\n",
    "        self.s_2x2 = nn.Parameter(torch.rand(2, 2, device=device, dtype=dtype))\n",
    "        self.p_local = nn.Parameter(torch.rand(2, device=device, dtype=dtype))\n",
    "        self.sigma_oris = nn.Parameter(torch.rand(1, device=device, dtype=dtype))\n",
    "        \n",
    "        self.make_W()\n",
    "\n",
    "    def _make_maps(self,thetas):\n",
    "        \n",
    "        self.ori_map = torch.tensor(thetas, device=self.device, dtype=self.dtype).flatten()\n",
    "        self.ori_vec = self.ori_map.repeat(self.grid_size ** 2)\n",
    "        self.ori_vec = self.ori_vec.repeat(2)\n",
    "\n",
    "        self.x_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations).repeat(self.grid_size)\n",
    "        self.y_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations * self.grid_size)\n",
    "\n",
    "        self.x_vec = self.x_vec.repeat(2)\n",
    "        self.y_vec = self.y_vec.repeat(2)\n",
    "\n",
    "    def make_W(self):\n",
    "        \n",
    "        xy_dist = self.calc_xy_dist()\n",
    "        ori_dist = self.calc_ori_dist()\n",
    "        \n",
    "        W_ee = self.calc_W_block(xy_dist[:self.Ne, :self.Ne], ori_dist[:self.Ne, :self.Ne], self.s_2x2[0, 0], self.sigma_oris)\n",
    "        W_ei = self.calc_W_block(xy_dist[:self.Ne, self.Ne:], ori_dist[:self.Ne, self.Ne:], self.s_2x2[0, 1], self.sigma_oris)\n",
    "        W_ie = self.calc_W_block(xy_dist[self.Ne:, :self.Ne], ori_dist[self.Ne:, :self.Ne], self.s_2x2[1, 0], self.sigma_oris)\n",
    "        W_ii = self.calc_W_block(xy_dist[self.Ne:, self.Ne:], ori_dist[self.Ne:, self.Ne:], self.s_2x2[1, 1], self.sigma_oris)\n",
    "        \n",
    "        W_ee = self.p_local[0] * torch.eye(self.Ne, device=self.device, dtype=self.dtype) + (1 - self.p_local[0]) * W_ee\n",
    "        W_ei = self.p_local[1] * torch.eye(self.Ni, device=self.device, dtype=self.dtype) + (1 - self.p_local[1]) * W_ei\n",
    "        \n",
    "        self.W = nn.Parameter(torch.cat([\n",
    "            torch.cat([self.J_2x2[0, 0] * W_ee, self.J_2x2[0, 1] * W_ei], dim=1),\n",
    "            torch.cat([self.J_2x2[1, 0] * W_ie, self.J_2x2[1, 1] * W_ii], dim=1)\n",
    "        ], dim=0).double())\n",
    "        \n",
    "        return self.W\n",
    "    \n",
    "    def calc_xy_dist(self):\n",
    "        Ne = Ni = self.Ne\n",
    "        x_vec_e = self.x_vec[:Ne]\n",
    "        y_vec_e = self.y_vec[:Ne]\n",
    "        x_vec_i = self.x_vec[Ne:Ne+Ni]\n",
    "        y_vec_i = self.y_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        xy_dist = torch.cdist(torch.stack([x_vec_e, y_vec_e], dim=1), torch.stack([x_vec_i, y_vec_i], dim=1), p=2).repeat(2, 2) #Distance Squared\n",
    "\n",
    "        return xy_dist\n",
    "    \n",
    "    def calc_ori_dist(self,L=np.pi, method=\"absolute\"):\n",
    "\n",
    "        Ne = Ni = self.num_orientations * self.grid_size ** 2\n",
    "        \n",
    "        ori_vec_e = self.ori_vec[:Ne]\n",
    "        ori_vec_i = self.ori_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        if method == \"absolute\":\n",
    "            ori_dist = torch.cdist(ori_vec_e.unsqueeze(1), ori_vec_i.unsqueeze(1)).repeat(2,2)\n",
    "        elif method == \"cos\":\n",
    "            ori_vec_e_norm = ori_vec_e / ori_vec_e.norm(dim=1, keepdim=True)\n",
    "            ori_vec_i_norm = ori_vec_i / ori_vec_i.norm(dim=1, keepdim=True)\n",
    "            ori_dist = 1 - torch.mm(ori_vec_e_norm, ori_vec_i_norm.t())\n",
    "            ori_dist = ori_dist.repeat(2, 2)\n",
    "        else:\n",
    "            #1 - cos(2(pi/L) * |theta1 - theta2|)\n",
    "            ori_dist = 1 - torch.cos((2 * np.pi / L) * torch.abs(ori_vec_e.unsqueeze(1) - ori_vec_i.unsqueeze(1)))\n",
    "            ori_dist = ori_dist.repeat(2, 2)\n",
    "\n",
    "        return ori_dist\n",
    "\n",
    "    def calc_W_block(self, xy_dist, ori_dist, s, sigma_oris,CellWiseNormalised = True):\n",
    "\n",
    "        #Add a small constant to s and sigma_oris to avoid division by zero\n",
    "        s = s + 1e-8\n",
    "        sigma_oris = sigma_oris + 1e-8\n",
    "\n",
    "        W =  torch.exp(-xy_dist / s - ori_dist ** 2 / (2 * sigma_oris ** 2))\n",
    "        W = torch.where(W < 1e-4, torch.zeros_like(W), W)\n",
    "        \n",
    "        sW = torch.sum(W, dim=1, keepdim=True)\n",
    "        if CellWiseNormalised:\n",
    "            W = W / sW[:, None]\n",
    "        else:\n",
    "            sW = sW.mean()\n",
    "            W = W / sW\n",
    "            \n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set network parameters\n",
    "n = 2\n",
    "k = 0.4\n",
    "tauE = 20.0\n",
    "tauI = 10.0\n",
    "grid_pars = {'grid_size_Nx': 3}\n",
    "conn_pars = {'num_orientations': 8}\n",
    "thetas = np.linspace(0, np.pi, conn_pars['num_orientations'])\n",
    "\n",
    "# Create an instance of SSN2DTopo\n",
    "ssn_topo = SSN2DTopo(n, k, tauE, tauI, grid_pars, conn_pars, thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GSM._imports import *\n",
    "from torch.optim import Adam\n",
    "from SSN._imports import *\n",
    "from SSN.params import GridParameters\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class FoGSMModel(nn.Module):\n",
    "    def __init__(self,thetas=None, length_scale_feature=1.0, length_scale_amplitude=1.2, kappa=1.0, jitter=1e-5, grid_size=10, frequency=1.0,sigma=0.1):\n",
    "        super(FoGSMModel, self).__init__()\n",
    "\n",
    "        self.dtype = torch.float64\n",
    "\n",
    "        self.length_scale_feature = Parameter(torch.tensor(length_scale_feature, dtype=self.dtype))\n",
    "        self.length_scale_amplitude = Parameter(torch.tensor(length_scale_amplitude, dtype=self.dtype))\n",
    "        self.kappa = Parameter(torch.tensor(kappa, dtype=self.dtype))\n",
    "        self.frequency = Parameter(torch.tensor(frequency, dtype=self.dtype)) \n",
    "        self.sigma = Parameter(torch.tensor(sigma))\n",
    "\n",
    "        if thetas is None:\n",
    "            thetas = torch.linspace(0, 2 * np.pi, 8)  # 8 orientations from 0 to 2*pi\n",
    "        self.thetas = thetas\n",
    "\n",
    "        self.jitter = jitter\n",
    "        self.grid_size = grid_size\n",
    "        self.grid = torch.stack(torch.meshgrid(torch.linspace(-5, 5, grid_size), \n",
    "                                               torch.linspace(-5, 5, grid_size)), \n",
    "                                dim=-1).reshape(-1, 2)\n",
    "        \n",
    "        self.K_g = self.generate_K_g()\n",
    "        \n",
    "    def von_mises_kernel(self, theta1, theta2):\n",
    "        theta_diff = theta1 - theta2  \n",
    "        return torch.clamp(torch.exp(self.kappa * torch.cos(theta_diff)), min=1e-6)\n",
    "    \n",
    "    def squared_exponential_kernel(self, x1, x2, length_scale,jitter=\"True\"):\n",
    "        x1 = x1.unsqueeze(1) # Shape: [N, 1, 2]\n",
    "        x2 = x2.unsqueeze(0) # Shape: [1, N, 2]\n",
    "        sq_dist = torch.sum((x1 - x2) ** 2, dim=2) # Shape: [N, N]\n",
    "\n",
    "        exp_term = torch.exp(-sq_dist / (2*length_scale**2))\n",
    "\n",
    "        if jitter:\n",
    "            return exp_term + self.jitter * torch.eye(x1.size(0))\n",
    "        else:\n",
    "            return exp_term\n",
    "\n",
    "    def composite_feature_kernel(self, theta1, theta2):\n",
    "         \n",
    "        sq_exp_component = self.squared_exponential_kernel(self.grid, self.grid, self.length_scale_feature,jitter=\"False\")        \n",
    "        \n",
    "        # Ensure theta1 and theta2 are tensors\n",
    "        theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
    "        theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n",
    "\n",
    "        x1 = self.grid.unsqueeze(1) # Shape: [N, 1, 2]\n",
    "        x2 = self.grid.unsqueeze(0) # Shape: [1, N, 2]\n",
    "\n",
    "        n1 = torch.tensor([torch.cos(theta1), torch.sin(theta1)]).view(1, 1, 2)  # Shape: [1, 1, 2]\n",
    "        n2 = torch.tensor([torch.cos(theta2), torch.sin(theta2)]).view(1, 1, 2)  # Shape: [1, 1, 2]\n",
    "        average_orientation = (n1 + n2) / 2\n",
    "\n",
    "        # Broadcasting average_orientation for dot product computation\n",
    "        average_orientation = average_orientation.repeat(x1.size(0), x1.size(1), 1)\n",
    "        dot_product = torch.sum((x1 - x2) * average_orientation, dim=2)\n",
    "        periodic_component = torch.cos(2 * torch.pi * self.frequency * dot_product)\n",
    "\n",
    "        # Composite Kernel\n",
    "        return sq_exp_component * periodic_component\n",
    "\n",
    "    def generate_K_g(self):\n",
    "        \n",
    "        theta1_grid, theta2_grid = torch.meshgrid(self.thetas, self.thetas)\n",
    "        ori_kernel_val = self.von_mises_kernel(theta1_grid, theta2_grid)\n",
    "    \n",
    "        # Spatial kernel\n",
    "        loc_kernel_val = torch.zeros((len(self.thetas), len(self.thetas), self.grid_size**2, self.grid_size**2))\n",
    "\n",
    "        for i in range(len(self.thetas)):\n",
    "            for j in range(len(self.thetas)):\n",
    "                loc_kernel_val[i,j] = self.composite_feature_kernel(self.thetas[i], self.thetas[j])\n",
    "        \n",
    "        #print(\"LOC \",loc_kernel_val.size())\n",
    "        K_spatial = torch.sum(loc_kernel_val, dim=[0, 1])\n",
    "        #print(\"K_spatial \",K_spatial.size())\n",
    "        K_g = torch.kron(K_spatial, ori_kernel_val)\n",
    "        \n",
    "        #K_g = ori_kernel_val.unsqueeze(-1).unsqueeze(-1) * loc_kernel_val\n",
    "        #K_g = K_g.transpose(0, 2).transpose(1, 3).reshape((len(self.thetas) * self.grid_size**2, len(self.thetas) * self.grid_size**2))\n",
    "        \n",
    "        K_g = K_g + self.jitter * torch.eye(len(self.thetas)*self.grid_size**2)\n",
    "        return K_g\n",
    "\n",
    "    def compute_A(self):\n",
    "        kernel_vals = self.squared_exponential_kernel(self.grid, self.grid, self.length_scale_amplitude)\n",
    "        return torch.sqrt(torch.exp(MultivariateNormal(torch.zeros(self.grid.size(0)), kernel_vals).sample()))\n",
    "\n",
    "    def samples(self):\n",
    "\n",
    "        g = MultivariateNormal(torch.zeros(len(self.thetas)*(self.grid_size**2)), self.K_g).sample()  \n",
    "        A = self.compute_A()\n",
    "        \n",
    "        # Tile amplitudes to match feature fields \n",
    "        A = A.repeat(len(self.thetas))\n",
    "    \n",
    "        # Combine\n",
    "        I = g * A  + torch.randn_like(g) * self.sigma\n",
    "        #I = torch.sum(I.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "\n",
    "        return I, g\n",
    "    \n",
    "    def log_likelihood(self, I, g,A):\n",
    "        A = A.repeat(len(self.thetas))\n",
    "        I_hat = g * A\n",
    "        #I_hat = torch.sum(I_hat.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "        print(\"Log likelihood I_hat \",I_hat.size())\n",
    "        print(\"Log likelihood I \",I.size())\n",
    "        return MultivariateNormal(I_hat.flatten(), self.sigma * torch.eye(self.grid_size**2)).log_prob(I.flatten())\n",
    "\n",
    "    def likelihood(self, I, g,A):\n",
    "        A = A.repeat(len(self.thetas))\n",
    "        I_hat = g * A     \n",
    "            # Ensure I_hat and I are valid\n",
    "            \n",
    "        if torch.isnan(I_hat).any() or torch.isinf(I_hat).any():\n",
    "            print(\"NaN or inf detected in I_hat calculation\")\n",
    "            return torch.tensor(float('nan'))\n",
    "\n",
    "        if torch.isnan(I).any() or torch.isinf(I).any():\n",
    "            print(\"NaN or inf detected in I calculation\")\n",
    "            return torch.tensor(float('nan'))\n",
    "\n",
    "        # Ensure positive definite covariance matrix\n",
    "        cov_matrix = self.sigma * torch.eye(I_hat.size(0))\n",
    "        if not torch.isfinite(cov_matrix).all():\n",
    "            print(\"Non-finite values in covariance matrix\")\n",
    "            return torch.tensor(float('nan'))\n",
    "        return torch.exp(MultivariateNormal(I_hat, self.sigma * torch.eye(I_hat.size(0))).log_prob(I))\n",
    "\n",
    "    def visualise(self, combined_fields):\n",
    "\n",
    "        # Normalise the combined image for visualisation\n",
    "        combined_fields_normalised = combined_fields / combined_fields.max()\n",
    "\n",
    "        # Reshape to image format\n",
    "        combined_image = combined_fields_normalised.view(self.grid_size, self.grid_size).detach().numpy()\n",
    "\n",
    "        # Visualise the combined image\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(combined_image, cmap='gray') \n",
    "        plt.title('FoGSM Sample')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    def generate_fogsm_dataset(self, num_samples, save=False,save_path=None):\n",
    "        samples = []\n",
    "        for _ in range(num_samples):\n",
    "            I, g = self.samples()\n",
    "            samples.append((I, g))\n",
    "    \n",
    "        # Convert samples to tensors\n",
    "        images, gs = zip(*samples)\n",
    "        images = torch.stack(images)\n",
    "        gs = torch.stack(gs)\n",
    "    \n",
    "        if save:\n",
    "            torch.save(images, gs, save_path)\n",
    "        else:\n",
    "            return images\n",
    "\n",
    "    def visualise_samples(self, save_path, num_samples_to_visualise, grid_size):\n",
    "        # Load the saved samples\n",
    "        images, _ = torch.load(save_path)\n",
    "\n",
    "        # Select a subset of samples to visualise\n",
    "        selected_samples = images[:num_samples_to_visualise]\n",
    "\n",
    "        # Create a grid of images\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))\n",
    "        fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i < num_samples_to_visualise:\n",
    "                image = selected_samples[i].detach().numpy()\n",
    "                image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "                ax.imshow(image, cmap='gray')\n",
    "        \n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the parameters for the FoGSM model\n",
    "thetas = torch.linspace(0, 2 * torch.pi, 8)  # 8 orientations from 0 to 2*pi\n",
    "fogsm_params = {\n",
    "        \"thetas\": thetas,\n",
    "        \"length_scale_feature\": 1.0,\n",
    "        \"length_scale_amplitude\": 1.5,\n",
    "        \"kappa\": .5,\n",
    "        \"jitter\": 1e-4,\n",
    "        \"grid_size\": 3,\n",
    "        \"frequency\": .2,\n",
    "        \"sigma\": 0.1,\n",
    "    }\n",
    "fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "# Generate and visualise a sample from the FoGSM model\n",
    "I, g = fogsm_model.samples()\n",
    "#fogsm_model.visualise(I)\n",
    "\n",
    "\n",
    "class SSNBase(torch.nn.Module):\n",
    "    def __init__(self, n, k, Ne, Ni, tau_e, tau_i, device='cpu', dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.N = self.Ne + self.Ni\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.register_buffer('EI', torch.cat([torch.ones(Ne), torch.zeros(Ni)]).to(device).bool())\n",
    "        self.register_buffer('tau_vec', torch.cat([tau_e * torch.ones(Ne), tau_i * torch.ones(Ni)]).to(device, dtype))\n",
    "    \n",
    "    def drdt(self, r, inp_vec):\n",
    "        return (-r + self.powlaw(self.W @ r + inp_vec)) / self.tau_vec\n",
    "\n",
    "    def powlaw(self, u):\n",
    "        return self.k * F.relu(u).pow(self.n)\n",
    "    \n",
    "    def dvdt_batch(self, v, inp_vec):\n",
    "        # Ensure v and inp_vec are 2D tensors for batch processing\n",
    "        if v.ndim == 1:\n",
    "            v = v.unsqueeze(0)\n",
    "        if inp_vec.ndim == 1:\n",
    "            inp_vec = inp_vec.unsqueeze(0)\n",
    "\n",
    "        #print(f\"dvdt: v.shape={v.shape}, inp_vec.shape={inp_vec.shape}, W.shape={self.W.shape}\")\n",
    "\n",
    "        # Compute W @ r for batch processing\n",
    "        W_r = self.W @ self.powlaw(v).T\n",
    "        W_r = W_r.T  # Transpose back to match batch dimension\n",
    "    \n",
    "        return (-v + W_r + inp_vec) / self.tau_vec\n",
    "\n",
    "    def simulate_batch(self, inp_vec, v_init=None, duration=500, dt=0.1):\n",
    "        # inp_vec: [batch_size, num_neurons]\n",
    "        # v_init: [batch_size, num_neurons]\n",
    "        # returns: [batch_size, time_steps, num_neurons]\n",
    "\n",
    "        # Check if inp_vec is a batch of inputs\n",
    "        if inp_vec.ndim == 2:\n",
    "            # inp_vec: [batch_size, num_neurons]\n",
    "            batch_size, self.N = inp_vec.shape\n",
    "            time_steps = int(duration / dt)\n",
    "\n",
    "            #print duration, dt, time_steps\n",
    "            #print(\"duration, dt, time_steps\",duration, dt, time_steps)\n",
    "                  \n",
    "            inp_vec = inp_vec.unsqueeze(1).expand(-1, time_steps, -1)\n",
    "        else:\n",
    "            raise ValueError(\"inp_vec must be a 2D tensor of shape [batch_size, num_neurons].\")\n",
    "\n",
    "        print(f\"simulate: batch_size={batch_size}, time_steps={time_steps}, inp_vec.shape={inp_vec.shape}\")\n",
    "\n",
    "        # Initialise v_init if not provided\n",
    "        if v_init is None:\n",
    "            v_init = torch.zeros((batch_size, self.N), device=self.device, dtype=self.dtype)\n",
    "        else:\n",
    "            if isinstance(v_init, (int, float)):\n",
    "                v_init = torch.full((batch_size, self.N), v_init, device=self.device, dtype=self.dtype)\n",
    "            if v_init.shape[0] != batch_size or v_init.shape[1] != self.N:\n",
    "                raise ValueError(\"v_init shape does not match batch_size or neuron count N.\")\n",
    "\n",
    "        # rates: [batch_size, time_steps, Ne]\n",
    "        rates_E = torch.zeros((batch_size, time_steps, self.Ne), device=self.device, dtype=self.dtype)\n",
    "        v = v_init\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            # Calculate dv for each element in the batch at the current time step\n",
    "            dv = self.dvdt_batch(v, inp_vec[:, t, :])  # dv: [batch_size, num_neurons]\n",
    "\n",
    "            # Update the membrane potentials for the current time step\n",
    "            v += dt * dv\n",
    "\n",
    "            # Compute the firing rates from the updated membrane potentials\n",
    "            r = self.powlaw(v) # r: [batch_size, num_neurons]\n",
    "\n",
    "            # Store the rates for the current time step\n",
    "            rates_E[:, t, :] = r[:, :self.Ne] # rates: [batch_size, time_steps, Ne]\n",
    "\n",
    "            #print(f\"t={t}, v.shape={r.shape}, dv.shape={dv.shape}\")\n",
    "\n",
    "\n",
    "        return rates_E\n",
    "\n",
    "class SSN2DTopo(SSNBase):\n",
    "    def __init__(self, n, k, tauE, tauI, grid_pars, conn_pars, thetas, L = np.pi,device='cpu', dtype=torch.float64):\n",
    "         \n",
    "        num_orientations = thetas.shape[0]\n",
    "        grid_size = grid_pars['grid_size_Nx']\n",
    "                \n",
    "        Ne = num_orientations * (grid_size ** 2)\n",
    "        Ni = num_orientations * (grid_size ** 2)\n",
    "\n",
    "        super(SSN2DTopo, self).__init__(n=n, k=k, Ne=Ne, Ni=Ni, tau_e=tauE, tau_i=tauI, device=device, dtype=dtype)\n",
    "        \n",
    "        self.num_orientations = num_orientations\n",
    "        self.grid_size = grid_size\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.L = L\n",
    "        self._make_maps(thetas)\n",
    "        \n",
    "        # Initialise trainable parameters\n",
    "        if conn_pars is None:\n",
    "            conn_pars = {\n",
    "                'J_2x2': torch.rand(2, 2, device=device, dtype=dtype),  # Interaction strengths\n",
    "                's_2x2': torch.rand(2, 2, device=device, dtype=dtype),  \n",
    "                'p_local': torch.rand(2, device=device, dtype=dtype),  \n",
    "                'sigma_oris': torch.rand(1, device=device, dtype=dtype)  \n",
    "            }\n",
    "            \n",
    "        self.J_2x2 = nn.Parameter(conn_pars['J_2x2'])  # Interaction strengths\n",
    "        self.s_2x2 = nn.Parameter(conn_pars['s_2x2']) # Spatial length scales\n",
    "        self.p_local = nn.Parameter(conn_pars['p_local']) # Local connectivity strengths\n",
    "        self.sigma_oris = nn.Parameter(conn_pars['sigma_oris']) # Orientation tuning width\n",
    "        \n",
    "        self.make_W()\n",
    "\n",
    "    def _make_maps(self,thetas):\n",
    "\n",
    "        self.ori_map = torch.tensor(thetas, device=self.device, dtype=self.dtype).flatten()\n",
    "        self.ori_vec = self.ori_map.repeat(self.grid_size ** 2)  # Repeat orientation values for each grid cell\n",
    "        self.ori_vec = self.ori_vec.repeat(2) # Repeat for E and I populations\n",
    "\n",
    "        # Create x and y vectors for grid cells\n",
    "        self.x_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations).repeat(self.grid_size)\n",
    "        self.y_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_orientations * self.grid_size)\n",
    "\n",
    "        # Repeat for E and I populations\n",
    "        self.x_vec = self.x_vec.repeat(2)\n",
    "        self.y_vec = self.y_vec.repeat(2)\n",
    "    \n",
    "    def calc_xy_dist(self):\n",
    "        Ne = Ni = self.Ne\n",
    "        x_vec_e = self.x_vec[:Ne]\n",
    "        y_vec_e = self.y_vec[:Ne]\n",
    "        x_vec_i = self.x_vec[Ne:Ne+Ni]\n",
    "        y_vec_i = self.y_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        xy_dist = torch.cdist(torch.stack([x_vec_e, y_vec_e], dim=1), torch.stack([x_vec_i, y_vec_i], dim=1), p=2).repeat(2, 2) #Distance Squared\n",
    "\n",
    "        return xy_dist\n",
    "    \n",
    "    def calc_ori_dist(self,L=np.pi, method=None):\n",
    "\n",
    "        Ne = Ni = self.num_orientations * self.grid_size ** 2\n",
    "        \n",
    "        ori_vec_e = self.ori_vec[:Ne]\n",
    "        ori_vec_i = self.ori_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        # define everything as squared distance ori_sqdist = (ori_vec_e - ori_vec_i) ** 2\n",
    "        if method == \"absolute\":\n",
    "            ori_dist = torch.cdist(ori_vec_e.unsqueeze(1), ori_vec_i.unsqueeze(1)).repeat(2,2)\n",
    "        elif method == \"cos\":\n",
    "            ori_vec_e_norm = ori_vec_e / ori_vec_e.norm(dim=1, keepdim=True)\n",
    "            ori_vec_i_norm = ori_vec_i / ori_vec_i.norm(dim=1, keepdim=True)\n",
    "            ori_dist = 1 - torch.mm(ori_vec_e_norm, ori_vec_i_norm.t())\n",
    "        else:\n",
    "            #1 - cos(2(pi/L) * |theta1 - theta2|^2)\n",
    "            ori_dist = (1 - torch.cos((2 * np.pi / L) * (ori_vec_e.unsqueeze(1) - ori_vec_i.unsqueeze(0))**2)) / (2 * np.pi / L)**2\n",
    "\n",
    "            #ori_vec[:,None] - ori_ve\n",
    "        \n",
    "        ori_dist = ori_dist.repeat(2, 2)\n",
    "\n",
    "        return ori_dist\n",
    "\n",
    "    def make_W(self):\n",
    "        \n",
    "        xy_dist = self.calc_xy_dist()\n",
    "        ori_dist = self.calc_ori_dist()\n",
    "\n",
    "        # Compute weight blocks\n",
    "        W_ee = self.calc_W_block(xy_dist[:self.Ne, :self.Ne], ori_dist[:self.Ne, :self.Ne], self.s_2x2[0][0], self.sigma_oris)\n",
    "        W_ei = self.calc_W_block(xy_dist[:self.Ne, self.Ne:], ori_dist[:self.Ne, self.Ne:], self.s_2x2[0][1], self.sigma_oris)\n",
    "        W_ie = self.calc_W_block(xy_dist[self.Ne:, :self.Ne], ori_dist[self.Ne:, :self.Ne], self.s_2x2[1][0], self.sigma_oris)\n",
    "        W_ii = self.calc_W_block(xy_dist[self.Ne:, self.Ne:], ori_dist[self.Ne:, self.Ne:], self.s_2x2[1][1], self.sigma_oris)\n",
    "        \n",
    "        # Apply local connectivity strengths\n",
    "        W_ee = self.p_local[0] * torch.eye(self.Ne, device=self.device, dtype=self.dtype) + (1 - self.p_local[0]) * W_ee\n",
    "        W_ei = self.p_local[1] * torch.eye(self.Ni, device=self.device, dtype=self.dtype) + (1 - self.p_local[1]) * W_ei\n",
    "        \n",
    "        print(\"J_2x2 shape:\", self.J_2x2.shape)\n",
    "        print(\"W_ie shape:\", W_ie.shape)\n",
    "        print(\"W_ii shape:\", W_ii.shape)\n",
    "    \n",
    "        print(\"Is J_2x2 NaN or Inf?\", torch.isnan(self.J_2x2).any() or torch.isinf(self.J_2x2).any())\n",
    "        print(\"Is W_ie NaN or Inf?\", torch.isnan(W_ie).any() or torch.isinf(W_ie).any())\n",
    "        print(\"Is W_ii NaN or Inf?\", torch.isnan(W_ii).any() or torch.isinf(W_ii).any())\n",
    "    \n",
    "        \n",
    "        # Concatenate submatrices to form W\n",
    "        W = torch.cat([\n",
    "            torch.cat([self.J_2x2[0, 0] * W_ee, self.J_2x2[0, 1] * W_ei], dim=1).clone().detach(),\n",
    "            torch.cat([self.J_2x2[1, 0] * W_ie, self.J_2x2[1, 1] * W_ii], dim=1).clone().detach()\n",
    "        ], dim=0).double()\n",
    "\n",
    "        # Register W as a buffer\n",
    "        self.register_buffer('W', W)\n",
    "        \n",
    "        return self.W\n",
    "\n",
    "    def calc_W_block(self, xy_dist, ori_dist, s, sigma_oris, CellWiseNormalised = True):\n",
    "\n",
    "        #Add a small constant to s and sigma_oris to avoid division by zero\n",
    "        s = s + 1e-8\n",
    "        sigma_oris = 2*np.pi*sigma_oris/self.L + 1e-8\n",
    "        \n",
    "        W =  torch.exp(-xy_dist / s - ori_dist ** 2 / (2 * sigma_oris ** 2))\n",
    "        W = torch.where(W < 1e-4, torch.zeros_like(W), W)\n",
    "\n",
    "        \n",
    "        sW = torch.sum(W, dim=1, keepdim=True)\n",
    "        if CellWiseNormalised:\n",
    "            W = torch.div(W, sW)\n",
    "        else:\n",
    "            sW = sW.mean()\n",
    "            W = W / sW\n",
    "\n",
    "        return W.squeeze()\n",
    "    \n",
    "# Set network parameters - TODO take from echeveste et al, double check that theb weight matrix is set up according to the paper \n",
    "n = 2\n",
    "k = 0.3\n",
    "tauE = 20.0\n",
    "tauI = 10.0\n",
    "grid_pars = {'grid_size_Nx': 3}\n",
    "\n",
    "psi = torch.tensor(0.774)\n",
    "conn_pars = {\n",
    "    'J_2x2': torch.tensor([[1.124, -0.931], [1.049, -0.537]],dtype=torch.float64) *torch.pi * psi, #TODO: take their a and multiply by 2 * num thetas in echeveste\n",
    "    's_2x2': torch.tensor([[0.2955, 0.09], [0.5542, 0.09]]),  # TODO: set to be 10x grid size \n",
    "    'p_local': torch.tensor([0.72,0.7]),  \n",
    "    'sigma_oris': torch.tensor(45.0),\n",
    "    'num_orientations': 8}\n",
    "\n",
    "thetas = np.linspace(0, np.pi, conn_pars['num_orientations'])\n",
    "\n",
    "ssn_params = {\n",
    "        \"n\": 2,\n",
    "        \"k\": k,\n",
    "        \"tauE\": 20,\n",
    "        \"tauI\": 10,\n",
    "        \"grid_pars\": grid_pars,\n",
    "        \"conn_pars\": conn_pars,\n",
    "        \"thetas\": thetas,\n",
    "    }\n",
    "\n",
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        super(DirectFit, self).__init__()\n",
    "        self.ssn_model = SSN2DTopo(**ssn_params)\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "        self.C_E = nn.Parameter(torch.tensor(2.4)) # taken from Echeveste et al. 2020\n",
    "        self.C_I = nn.Parameter(torch.tensor(2.4)) # taken from Echeveste et al. 2020\n",
    "        # TODO: 1.5 * overall standard deviation of an image from FoGSM model - compute the sd over a large number of sample images empirically and set this value\n",
    "        s = 0.1\n",
    "        self.beta = nn.Parameter(torch.tensor(1.5 * s))\n",
    "        self.gamma = nn.Parameter(torch.tensor(0.6)) # taken from Echeveste et al. 2020\n",
    "\n",
    "    def sample_trajectories(self, input_batch, duration=500, dt=.1):\n",
    "\n",
    "        # shape of input_batch: [batch_size, num_neurons]\n",
    "        batch_size = input_batch.shape[0]   \n",
    "        #print(\"Input batch shape: \", input_batch.shape)  \n",
    "\n",
    "        # Non-linearity for the input to the network\n",
    "        input_processed = F.relu(input_batch)\n",
    "        input_processed = (self.beta + input_processed)**self.gamma\n",
    "\n",
    "        # Multiply the input batch by C_E and C_I scalars\n",
    "        input_weighted = torch.cat([\n",
    "            self.C_E * input_processed,\n",
    "            self.C_I * input_processed\n",
    "        ], dim=-1)\n",
    "        #print(\"Input weighted shape: \", input_weighted.shape)\n",
    "\n",
    "        # Ensure input_reshaped has correct dimensions before calling simulate\n",
    "        if input_weighted.shape[1] != self.ssn_model.N:\n",
    "            input_weighted = input_weighted.view(input_weighted.shape[0], self.ssn_model.N)\n",
    "\n",
    "        # Generate trajectories for the reshaped input\n",
    "        trajectories = self.ssn_model.simulate_batch(input_weighted, duration=duration, dt=dt)\n",
    "        #print(\"Trajectories shape after simulation: \", trajectories.shape)\n",
    "\n",
    "        return trajectories\n",
    "\n",
    "    def calculate_log_p_g(self, trajectory):\n",
    "        # trajectory: [num_samples_g, dim]\n",
    "        # expectation over g in Eq (25) (1st term), i.e., (sub-sampled) time-steps of SSN simulation, corresponding to samples from variational posterior of g\n",
    "\n",
    "        num_neurons = trajectory.shape[1]  # Number of neurons\n",
    "        dim = trajectory.shape[0]            # Number of time points\n",
    "\n",
    "        # Mean vector for the multivariate normal (zero mean)\n",
    "        mean = torch.zeros(num_neurons, device=trajectory.device, dtype=trajectory.dtype)\n",
    "    \n",
    "        # Covariance matrix for the multivariate normal\n",
    "        cov = self.fogsm_model.K_g\n",
    "\n",
    "        # Check covariance matrix shape\n",
    "        assert cov.shape == (num_neurons, num_neurons), f\"Expected covariance matrix of shape ({num_neurons}, {num_neurons}), but got {cov.shape}\"\n",
    "\n",
    "        # Multivariate normal distribution\n",
    "        mvg = MultivariateNormal(mean, cov)\n",
    "\n",
    "        #print(\"Logpg Trajectory shape: \", trajectory.shape)  \n",
    "        #print(\"Mean shape: \", mean.shape)\n",
    "        #print(\"Covariance matrix shape: \", cov.shape)\n",
    "\n",
    "        # Calculate log probabilities for all samples in the trajectory\n",
    "        log_probs = []\n",
    "        for g in trajectory:\n",
    "            log_probs.append(mvg.log_prob(g))  # log_probs: [num_samples_g]\n",
    "\n",
    "        log_probs = torch.tensor(log_probs, device=trajectory.device, dtype=trajectory.dtype)\n",
    "        if torch.isnan(log_probs).any():\n",
    "            print(\"NaN detected in log_probs\")\n",
    "\n",
    "        # Return the mean log probability\n",
    "        log_p_g = log_probs.mean()\n",
    "\n",
    "        return log_p_g\n",
    "\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, I_data, trajectory, A_samples, epsilon=1e-6):\n",
    "\n",
    "        log_likelihood = 0\n",
    "\n",
    "        # expectation over g in Eq (25) (2nd term)\n",
    "        for g in trajectory: # runs over (sub-sampled) time-steps of SSN simulation, corresponding to samples from variational posterior of g\n",
    "            p_I_g = 0\n",
    "\n",
    "            # expectation over A in Eq (25)\n",
    "            for a in A_samples: # for computational cost reasons, currently using the same samples for A for all images in a batch (but we resample across mini-batches) \n",
    "                p_I_g = p_I_g + self.fogsm_model.likelihood(I_data, g, a) # I_data is a single image from the dataset and g is a single sample\n",
    "                                                                          # for g from the SSN\n",
    "                #check if p_I_g is zero or negative\n",
    "                if p_I_g < 0:\n",
    "                    print(\"p_I_g is zero\")\n",
    "\n",
    "            avg_p_I_g = p_I_g / len(A_samples)\n",
    "            avg_p_I_g = torch.clamp(avg_p_I_g, min=epsilon) # to avoid log(0)\n",
    "\n",
    "            log_likelihood = log_likelihood + torch.log(avg_p_I_g)\n",
    "        \n",
    "        if torch.isnan(log_likelihood).any():\n",
    "            print(\"NaN detected in log_likelihood\")\n",
    "\n",
    "        return log_likelihood / len(trajectory)\n",
    "\n",
    "        \n",
    "    def calculate_elbo(self, input_batch, A_samples, duration=500, dt=.1):\n",
    "\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories = self.sample_trajectories(input_batch=input_batch, duration=duration, dt=dt)\n",
    "        #print(\"ELBO trajectories received\")\n",
    "\n",
    "        elbo = 0\n",
    "        for I, trajectory in zip(input_batch, trajectories): # trajectory is the trajectory for a single image\n",
    "            #print(\"Trajectory shape for single image: \", trajectory.shape)\n",
    "            log_p_g = self.calculate_log_p_g(trajectory)\n",
    "            #print(\"Log p_g calculated\")\n",
    "            log_p_I_given_g = self.calculate_log_p_I_given_g(I, trajectory, A_samples)\n",
    "            #print(\"Log p_I_given_g calculated\")\n",
    "\n",
    "            # cov_matrix = torch.cov(trajectory.reshape(trajectory.shape[0], -1))\n",
    "            cov_matrix = torch.cov(trajectory.T)\n",
    "            # Ensure covariance matrix is positive definite\n",
    "            if not torch.isfinite(cov_matrix).all():\n",
    "                print(\"Non-finite values in covariance matrix\")\n",
    "            \n",
    "            if torch.isnan(cov_matrix).any():\n",
    "                print(\"NaN detected in cov_matrix\")\n",
    "            \n",
    "            cov_matrix = cov_matrix + 1e-6 * torch.eye(cov_matrix.size(0))\n",
    "            entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "\n",
    "            print(\"ELBO terms: \", log_p_g, log_p_I_given_g, entropy_term)\n",
    "\n",
    "            elbo = elbo + log_p_g + log_p_I_given_g + entropy_term\n",
    "            if torch.isnan(elbo).any():\n",
    "                print(\"NaN detected in elbo\")\n",
    "\n",
    "        return elbo / len(input_batch)\n",
    "        \n",
    "    def optimise_elbo(self, batch_size, num_samples_a, convergence_threshold=1e-3, optimizer_cls=Adam, lr=1e-3):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.ssn_model.to(device)\n",
    "        self.fogsm_model.to(device)\n",
    "\n",
    "        optimizer = optimizer_cls(list(self.ssn_model.parameters()) + \n",
    "                              [self.C_E, self.C_I, self.beta, self.gamma], lr=lr)\n",
    "        batch = 0\n",
    "        prev_elbo = float('-inf')\n",
    "        elbo = 0\n",
    "\n",
    "        # plot the batch elbo values\n",
    "        elbo_values = []  \n",
    "\n",
    "        while True:\n",
    "            \n",
    "            optimizer.zero_grad()  # Zero gradients at the beginning of each batch\n",
    "\n",
    "            elbo_batch = 0\n",
    "\n",
    "            # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "            A_samples = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "\n",
    "            # Generate a mini-batch of input data\n",
    "            input_batch = self.fogsm_model.generate_fogsm_dataset(batch_size).to(device)\n",
    "\n",
    "            # Calculate the ELBO for the mini-batch\n",
    "            elbo_batch = self.calculate_elbo(input_batch, A_samples, duration=500, dt=0.2)\n",
    "\n",
    "            if torch.isnan(elbo_batch).any():\n",
    "                print(\"NaN detected in elbo_batch\")\n",
    "                break\n",
    "\n",
    "            # Optimise the ELBO with respect to the model parameters\n",
    "            elbo_batch.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print the ELBO for monitoring\n",
    "            if (batch + 1) % 1 == 0:\n",
    "                print(f\"Batch [{batch+1}], ELBO: {elbo_batch / batch_size:.4f}\")\n",
    "\n",
    "            # Check for convergence\n",
    "            if abs(elbo_batch - prev_elbo) < convergence_threshold:\n",
    "                print(f\"Converged after {batch+1} batches.\")\n",
    "                break\n",
    "\n",
    "            prev_elbo = elbo_batch\n",
    "            batch = batch + 1\n",
    "            elbo_values.append(elbo_batch.item())\n",
    "        \n",
    "\n",
    "        return self.ssn_model, self.fogsm_model\n",
    "    \n",
    "direct_fit = DirectFit(ssn_params, fogsm_params)\n",
    "\n",
    "# Create an optimiser for the ELBO\n",
    "optimiser = Adam(list(direct_fit.ssn_model.parameters()), lr=0.001)\n",
    "\n",
    "# Run the ELBO optimisation\n",
    "input_data, _ = torch.load(\"fogsm_dataset.pt\")\n",
    "direct_fit.optimise_elbo(batch_size=3, num_samples_a=10, optimizer_cls=Adam, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
