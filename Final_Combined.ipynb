{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fd3db1d98b0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GSM._imports import *\n",
    "from torch.optim import Adam\n",
    "from SSN._imports import *\n",
    "from SSN.params import GridParameters\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FoGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoGSMModel(nn.Module):\n",
    "    def __init__(self,thetas=None, l_feature=1.0, l_amplitude=1.2, kappa=1.0, jitter=1e-5, grid_size=10, frequency=1.0,sigma=0.1):\n",
    "        super(FoGSMModel, self).__init__()\n",
    "\n",
    "        self.dtype = torch.float64\n",
    "\n",
    "        self.l_feature = Parameter(torch.tensor(l_feature, dtype=self.dtype))\n",
    "        self.l_amplitude = Parameter(torch.tensor(l_amplitude, dtype=self.dtype))\n",
    "        self.kappa = Parameter(torch.tensor(kappa, dtype=self.dtype))\n",
    "        self.frequency = Parameter(torch.tensor(frequency, dtype=self.dtype)) \n",
    "        self.sigma = Parameter(torch.tensor(sigma))\n",
    "\n",
    "        if thetas is None:\n",
    "            thetas = torch.linspace(0, 2 * np.pi, 8)  # 8 orientations from 0 to 2*pi\n",
    "        self.thetas = thetas\n",
    "\n",
    "        self.jitter = jitter\n",
    "        self.grid_size = grid_size\n",
    "        self.grid = torch.stack(torch.meshgrid(torch.linspace(-5, 5, grid_size), \n",
    "                                               torch.linspace(-5, 5, grid_size)), \n",
    "                                dim=-1).reshape(-1, 2)\n",
    "        \n",
    "        self.K_g = self.generate_K_g()\n",
    "        \n",
    "    def von_mises_kernel(self, theta1, theta2):\n",
    "        theta_diff = theta1 - theta2  \n",
    "        return torch.clamp(torch.exp(self.kappa * torch.cos(theta_diff)), min=1e-6)\n",
    "    \n",
    "    def squared_exponential_kernel(self, x1, x2, length_scale,jitter=\"True\"):\n",
    "        x1 = x1.unsqueeze(1) # Shape: [N, 1, 2]\n",
    "        x2 = x2.unsqueeze(0) # Shape: [1, N, 2]\n",
    "        sq_dist = torch.sum((x1 - x2) ** 2, dim=2) # Shape: [N, N]\n",
    "\n",
    "        exp_term = torch.exp(-sq_dist / (2*length_scale**2))\n",
    "\n",
    "        if jitter:\n",
    "            return exp_term + self.jitter * torch.eye(x1.size(0))\n",
    "        else:\n",
    "            return exp_term\n",
    "\n",
    "    def composite_feature_kernel(self, theta1, theta2):\n",
    "         \n",
    "        sq_exp_component = self.squared_exponential_kernel(self.grid, self.grid, self.l_feature,jitter=\"False\")        \n",
    "        \n",
    "        # Ensure theta1 and theta2 are tensors\n",
    "        theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
    "        theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n",
    "\n",
    "        x1 = self.grid.unsqueeze(1) # Shape: [N, 1, 2]\n",
    "        x2 = self.grid.unsqueeze(0) # Shape: [1, N, 2]\n",
    "\n",
    "        n1 = torch.tensor([torch.cos(theta1), torch.sin(theta1)]).view(1, 1, 2)  # Shape: [1, 1, 2]\n",
    "        n2 = torch.tensor([torch.cos(theta2), torch.sin(theta2)]).view(1, 1, 2)  # Shape: [1, 1, 2]\n",
    "        average_orientation = (n1 + n2) / 2\n",
    "\n",
    "        # Broadcasting average_orientation for dot product computation\n",
    "        average_orientation = average_orientation.repeat(x1.size(0), x1.size(1), 1)\n",
    "        dot_product = torch.sum((x1 - x2) * average_orientation, dim=2)\n",
    "        periodic_component = torch.cos(2 * torch.pi * self.frequency * dot_product)\n",
    "\n",
    "        # Composite Kernel\n",
    "        return sq_exp_component * periodic_component\n",
    "\n",
    "    def generate_K_g(self):\n",
    "        \n",
    "        theta1_grid, theta2_grid = torch.meshgrid(self.thetas, self.thetas)\n",
    "        ori_kernel_val = self.von_mises_kernel(theta1_grid, theta2_grid)\n",
    "    \n",
    "        # Spatial kernel\n",
    "        loc_kernel_val = torch.zeros((len(self.thetas), len(self.thetas), self.grid_size**2, self.grid_size**2))\n",
    "\n",
    "        for i in range(len(self.thetas)):\n",
    "            for j in range(len(self.thetas)):\n",
    "                loc_kernel_val[i,j] = self.composite_feature_kernel(self.thetas[i], self.thetas[j])\n",
    "        \n",
    "        K_spatial = torch.sum(loc_kernel_val, dim=[0, 1])\n",
    "        K_g = torch.kron(K_spatial, ori_kernel_val)\n",
    "        \n",
    "        K_g = K_g + self.jitter * torch.eye(len(self.thetas)*self.grid_size**2)\n",
    "        return K_g\n",
    "\n",
    "    def compute_A(self):\n",
    "        kernel_vals = self.squared_exponential_kernel(self.grid, self.grid, self.l_amplitude)\n",
    "        return torch.sqrt(torch.exp(MultivariateNormal(torch.zeros(self.grid.size(0)), kernel_vals).sample()))\n",
    "\n",
    "    def samples(self):\n",
    "\n",
    "        g = MultivariateNormal(torch.zeros(len(self.thetas)*(self.grid_size**2)), self.K_g).sample()  \n",
    "        A = self.compute_A()\n",
    "        \n",
    "        # Tile amplitudes to match feature fields \n",
    "        A = A.repeat(len(self.thetas))\n",
    "    \n",
    "        # Combine\n",
    "        I = g * A  + torch.randn_like(g) * self.sigma\n",
    "        #I = torch.sum(I.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "\n",
    "        return I, g\n",
    "    \n",
    "    def log_likelihood(self, I, g,A):\n",
    "        A = A.repeat(len(self.thetas))\n",
    "        I_hat = g * A\n",
    "        #I_hat = torch.sum(I_hat.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "        print(\"Log likelihood I_hat \",I_hat.size())\n",
    "        print(\"Log likelihood I \",I.size())\n",
    "        return MultivariateNormal(I_hat.flatten(), self.sigma * torch.eye(self.grid_size**2)).log_prob(I.flatten())\n",
    "\n",
    "    def likelihood(self, I, g,A):\n",
    "        A = A.repeat(len(self.thetas))\n",
    "        I_hat = g * A     \n",
    "\n",
    "        # Ensure positive definite covariance matrix\n",
    "        cov_matrix = self.sigma * torch.eye(I_hat.size(0))\n",
    "        if not torch.isfinite(cov_matrix).all():\n",
    "            print(\"Non-finite values in covariance matrix\")\n",
    "            return torch.tensor(float('nan'))\n",
    "        \n",
    "        return torch.exp(MultivariateNormal(I_hat, self.sigma * torch.eye(I_hat.size(0))).log_prob(I))\n",
    "\n",
    "    def visualise(self, combined_fields):\n",
    "\n",
    "        combined_fields = torch.sum(combined_fields.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "\n",
    "        # Normalise the combined image for visualisation\n",
    "        combined_fields_normalised = combined_fields / combined_fields.max()\n",
    "\n",
    "        # Reshape to image format\n",
    "        combined_image = combined_fields_normalised.view(self.grid_size, self.grid_size).detach().numpy()\n",
    "\n",
    "        # Visualise the combined image\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(combined_image, cmap='gray') \n",
    "        plt.title('FoGSM Sample')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    def generate_fogsm_dataset(self, num_samples, save=False,save_path=None):\n",
    "        samples = []\n",
    "        for _ in range(num_samples):\n",
    "            I, g = self.samples()\n",
    "            samples.append((I, g))\n",
    "    \n",
    "        # Convert samples to tensors\n",
    "        images, gs = zip(*samples)\n",
    "        images = torch.stack(images)\n",
    "        gs = torch.stack(gs)\n",
    "    \n",
    "        if save:\n",
    "            torch.save(images, gs, save_path)\n",
    "        else:\n",
    "            return images\n",
    "\n",
    "    def visualise_samples(self, save_path, num_samples_to_visualise, grid_size):\n",
    "        # Load the saved samples\n",
    "        images, _ = torch.load(save_path)\n",
    "\n",
    "        # Select a subset of samples to visualise\n",
    "        selected_samples = images[:num_samples_to_visualise]\n",
    "\n",
    "        # Create a grid of images\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))\n",
    "        fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i < num_samples_to_visualise:\n",
    "                image = selected_samples[i].detach().numpy()\n",
    "                image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "                ax.imshow(image, cmap='gray')\n",
    "        \n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3445253102.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3445253102.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "num_oris = 8\n",
    "thetas = torch.linspace(0, 2 * torch.pi, num_oris)  # 8 orientations from 0 to 2*pi\n",
    "fogsm_params = {\n",
    "        \"thetas\": thetas,\n",
    "        \"l_feature\": 1.0,\n",
    "        \"l_amplitude\": 1.5,\n",
    "        \"kappa\": .5,\n",
    "        \"jitter\": 1e-5,\n",
    "        \"grid_size\": 3,\n",
    "        \"frequency\": .2,\n",
    "        \"sigma\": 0.1,\n",
    "    }\n",
    "fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "# Generate and visualise a sample from the FoGSM model\n",
    "I, g = fogsm_model.samples()\n",
    "#fogsm_model.visualise(I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSN Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSNBase(torch.nn.Module):\n",
    "    def __init__(self, n, k, Ne, Ni, tau_e, tau_i, device='cpu', dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.N = self.Ne + self.Ni\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.register_buffer('EI', torch.cat([torch.ones(Ne), torch.zeros(Ni)]).to(device).bool())\n",
    "        self.register_buffer('tau_vec', torch.cat([tau_e * torch.ones(Ne), tau_i * torch.ones(Ni)]).to(device, dtype))\n",
    "\n",
    "        self.C_E = nn.Parameter(torch.tensor(2.4)) # taken from Echeveste et al. 2020\n",
    "        self.C_I = nn.Parameter(torch.tensor(2.4)) # taken from Echeveste et al. 2020\n",
    "\n",
    "        b = 13.24\n",
    "        self.beta = nn.Parameter(torch.tensor(1.5 * b))\n",
    "        self.gamma = nn.Parameter(torch.tensor(0.6)) # taken from Echeveste et al. 2020\n",
    "    \n",
    "    def drdt(self, r, inp_vec):\n",
    "        return (-r + self.powlaw(self.W @ r + inp_vec)) / self.tau_vec\n",
    "\n",
    "    def powlaw(self, u):\n",
    "        return self.k * F.relu(u).pow(self.n)\n",
    "    \n",
    "    def dvdt_batch(self, v, inp_vec,noise=None):\n",
    "        # Ensure v and inp_vec are 2D tensors for batch processing\n",
    "        if v.ndim == 1:\n",
    "            v = v.unsqueeze(0)\n",
    "        if inp_vec.ndim == 1:\n",
    "            inp_vec = inp_vec.unsqueeze(0)\n",
    "\n",
    "        #print(f\"dvdt: v.shape={v.shape}, inp_vec.shape={inp_vec.shape}, W.shape={self.W.shape}\")\n",
    "\n",
    "        # Compute W @ r for batch processing\n",
    "        W_r = self.W @ self.powlaw(v).T\n",
    "        W_r = W_r.T  # Transpose back to match batch dimension\n",
    "\n",
    "        if noise is None:\n",
    "            noise = torch.zeros_like(v)\n",
    "\n",
    "        return (-v + W_r + inp_vec + noise) / self.tau_vec\n",
    "    \n",
    "    def process_input(self, input_batch):\n",
    "\n",
    "        # Non-linearity for the input to the network\n",
    "        input_rectified = F.relu(self.beta + input_batch)\n",
    "        input_processed = input_rectified**self.gamma\n",
    "\n",
    "        # Multiply the input batch by C_E and C_I scalars\n",
    "        input_weighted = torch.cat([\n",
    "            self.C_E * input_processed,\n",
    "            self.C_I * input_processed\n",
    "        ], dim=-1)\n",
    "\n",
    "        return input_weighted\n",
    "\n",
    "    def simulate_batch(self, inp_vec, v_init=None, duration=500, dt=1,noise=None):\n",
    "        # inp_vec: [batch_size, num_neurons]\n",
    "        # v_init: [batch_size, num_neurons]\n",
    "        # returns: [batch_size, time_steps, num_neurons]\n",
    "        \n",
    "        time_steps = int(duration/dt)\n",
    "        print(f\"simulate: time_steps={time_steps}, dt={dt}, duration={duration}\")\n",
    "        # Check if inp_vec is a batch of inputs\n",
    "        if inp_vec.ndim == 2:\n",
    "            batch_size, self.N = inp_vec.shape \n",
    "            inp_vec = inp_vec.unsqueeze(1).expand(-1, time_steps, -1)\n",
    "        else:\n",
    "            raise ValueError(\"inp_vec must be a 2D tensor of shape [batch_size, num_neurons].\")\n",
    "\n",
    "        #print(f\"simulate: batch_size={batch_size}, time_steps={time_steps}, inp_vec.shape={inp_vec.shape}\")\n",
    "\n",
    "        # Initialise v_init if not provided\n",
    "        if v_init is None:\n",
    "            v_init = torch.zeros((batch_size, self.N), device=self.device, dtype=self.dtype)\n",
    "        else:\n",
    "            if isinstance(v_init, (int, float)):\n",
    "                v_init = torch.full((batch_size, self.N), v_init, device=self.device, dtype=self.dtype)\n",
    "            if v_init.shape[0] != batch_size or v_init.shape[1] != self.N:\n",
    "                raise ValueError(\"v_init shape does not match batch_size or neuron count N.\")\n",
    "\n",
    "        # rates: [batch_size, time_steps, Ne]\n",
    "        rates_E = torch.zeros((batch_size, time_steps, self.Ne), device=self.device, dtype=self.dtype)\n",
    "        v = v_init\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            # Calculate dv for each element in the batch at the current time step\n",
    "            dv = self.dvdt_batch(v, inp_vec[:, t, :]+noise[t])  # dv: [batch_size, num_neurons]\n",
    "\n",
    "            # Update the membrane potentials for the current time step\n",
    "            v += dt * dv\n",
    "\n",
    "            # take an average of membrane potentials over trials at each time step is constant over time\n",
    "            # but trials doesny ecist so instead average over neurons but not image\n",
    "\n",
    "            # TODO: throw away the first 100 ms burn-in time of the simulation to allow the network to settle to a stable state before recording the firing rates\n",
    "\n",
    "            # Compute the firing rates from the updated membrane potentials\n",
    "            r = self.powlaw(v) # r: [batch_size, num_neurons]\n",
    "\n",
    "            # Store the rates for the current time step\n",
    "            if t % 5 == 0:\n",
    "                rates_E[:, t, :] = r[:, :self.Ne] # rates: [batch_size, time_steps, Ne]\n",
    "\n",
    "        return rates_E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSN 2DTopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSN2DTopo(SSNBase):\n",
    "    def __init__(self, n, k, tauE, tauI, grid_pars, conn_pars, thetas, L = np.pi,device='cpu', dtype=torch.float64):\n",
    "         \n",
    "        num_oris = thetas.shape[0]\n",
    "        grid_size = grid_pars['grid_size_Nx']\n",
    "                \n",
    "        Ne = num_oris * (grid_size ** 2)\n",
    "        Ni = num_oris * (grid_size ** 2)\n",
    "\n",
    "        super(SSN2DTopo, self).__init__(n=n, k=k, Ne=Ne, Ni=Ni, tau_e=tauE, tau_i=tauI, device=device, dtype=dtype)\n",
    "        \n",
    "        self.num_oris = num_oris\n",
    "        self.grid_size = grid_size\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.L = L\n",
    "        self._make_maps(thetas)\n",
    "        \n",
    "        # Initialise trainable parameters\n",
    "        if conn_pars is None:\n",
    "            conn_pars = {\n",
    "                'J_2x2': torch.rand(2, 2, device=device, dtype=dtype),  \n",
    "                's_2x2': torch.rand(2, 2, device=device, dtype=dtype),  \n",
    "                'p_local': torch.rand(2, device=device, dtype=dtype),  \n",
    "                'sigma_oris': torch.rand(1, device=device, dtype=dtype)  \n",
    "            }\n",
    "            \n",
    "        self.J_2x2 = nn.Parameter(conn_pars['J_2x2'])  # Interaction strengths\n",
    "        self.s_2x2 = nn.Parameter(conn_pars['s_2x2']) # Spatial length scales\n",
    "        self.p_local = nn.Parameter(conn_pars['p_local']) # Local connectivity strengths\n",
    "        self.sigma_oris = nn.Parameter(conn_pars['sigma_oris']) # Orientation tuning width\n",
    "        \n",
    "        self.make_W()\n",
    "\n",
    "    def _make_maps(self,thetas):\n",
    "\n",
    "        self.ori_map = torch.tensor(thetas, device=self.device, dtype=self.dtype).flatten()\n",
    "        self.ori_vec = self.ori_map.repeat(self.grid_size ** 2)  # Repeat orientation values for each grid cell\n",
    "        self.ori_vec = self.ori_vec.repeat(2) # Repeat for E and I populations\n",
    "\n",
    "        # Create x and y vectors for grid cells\n",
    "        self.x_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_oris).repeat(self.grid_size)\n",
    "        self.y_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_oris * self.grid_size)\n",
    "\n",
    "        # Repeat for E and I populations\n",
    "        self.x_vec = self.x_vec.repeat(2)\n",
    "        self.y_vec = self.y_vec.repeat(2)\n",
    "    \n",
    "    def calc_xy_dist(self):\n",
    "        Ne = Ni = self.Ne\n",
    "        x_vec_e = self.x_vec[:Ne]\n",
    "        y_vec_e = self.y_vec[:Ne]\n",
    "        x_vec_i = self.x_vec[Ne:Ne+Ni]\n",
    "        y_vec_i = self.y_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        xy_dist = torch.cdist(torch.stack([x_vec_e, y_vec_e], dim=1), torch.stack([x_vec_i, y_vec_i], dim=1), p=2).repeat(2, 2) \n",
    "\n",
    "        return xy_dist\n",
    "    \n",
    "    def calc_ori_dist(self,L=np.pi, method=None):\n",
    "\n",
    "        Ne = self.num_oris * self.grid_size ** 2\n",
    "        ori_vec = self.ori_vec[:Ne]\n",
    "\n",
    "        if method == \"absolute\":\n",
    "            ori_dist = torch.cdist(ori_vec.unsqueeze(1), ori_vec.unsqueeze(1)).repeat(2,2)\n",
    "        else:\n",
    "            #1 - cos(2(pi/L) * |theta1 - theta2|^2)\n",
    "            ori_diff = torch.abs(ori_vec.unsqueeze(1) - ori_vec.unsqueeze(0))\n",
    "            ori_diff = torch.min(ori_diff, 2*np.pi - ori_diff)\n",
    "            sq_ori_dist = 1 - torch.cos((2*np.pi / L) * ori_diff**2)\n",
    "                    \n",
    "        sq_ori_dist = sq_ori_dist.repeat(2, 2)\n",
    "\n",
    "        return sq_ori_dist\n",
    "\n",
    "    def make_W(self):\n",
    "        \n",
    "        xy_dist = self.calc_xy_dist()\n",
    "        sq_ori_dist = self.calc_ori_dist()\n",
    "\n",
    "        # Compute weight blocks\n",
    "        W_ee = self.calc_W_block(xy_dist[:self.Ne, :self.Ne], sq_ori_dist[:self.Ne, :self.Ne], self.s_2x2[0][0], self.sigma_oris, excitatory=True)\n",
    "        W_ei = self.calc_W_block(xy_dist[:self.Ne, self.Ne:], sq_ori_dist[:self.Ne, self.Ne:], self.s_2x2[0][1], self.sigma_oris, excitatory=True)\n",
    "        W_ie = self.calc_W_block(xy_dist[self.Ne:, :self.Ne], sq_ori_dist[self.Ne:, :self.Ne], self.s_2x2[1][0], self.sigma_oris)\n",
    "        W_ii = self.calc_W_block(xy_dist[self.Ne:, self.Ne:], sq_ori_dist[self.Ne:, self.Ne:], self.s_2x2[1][1], self.sigma_oris)\n",
    "        \n",
    "        # Apply local connectivity strengths\n",
    "        W_ee = self.p_local[0] * torch.eye(self.Ne, device=self.device, dtype=self.dtype) + (1 - self.p_local[0]) * W_ee\n",
    "        W_ei = self.p_local[1] * torch.eye(self.Ni, device=self.device, dtype=self.dtype) + (1 - self.p_local[1]) * W_ei\n",
    "                \n",
    "        # Concatenate submatrices to form W\n",
    "        W = torch.cat([\n",
    "            torch.cat([self.J_2x2[0, 0] * W_ee, self.J_2x2[0, 1] * W_ei], dim=1).clone().detach(),\n",
    "            torch.cat([self.J_2x2[1, 0] * W_ie, self.J_2x2[1, 1] * W_ii], dim=1).clone().detach()\n",
    "        ], dim=0).double()\n",
    "\n",
    "        # Register W as a buffer\n",
    "        self.register_buffer('W', W)\n",
    "        \n",
    "        return self.W\n",
    "\n",
    "    def calc_W_block(self, xy_dist, sq_ori_dist, s, sigma_oris, CellWiseNormalised = True, excitatory=False):\n",
    "\n",
    "        #Add a small constant to s and sigma_oris to avoid division by zero\n",
    "        s = s + 1e-8\n",
    "        sigma_oris = 2*np.pi*sigma_oris/self.L + 1e-8\n",
    "        \n",
    "        if excitatory:\n",
    "            W =  torch.exp(-xy_dist / s - sq_ori_dist / (2 * sigma_oris ** 2))\n",
    "        else:\n",
    "            W =  torch.exp(-xy_dist ** 2 / (2 * s ** 2) - sq_ori_dist / (2 * sigma_oris ** 2))\n",
    "                               \n",
    "        W = torch.where(W < 1e-4, torch.zeros_like(W), W)\n",
    "\n",
    "        \n",
    "        sW = torch.sum(W, dim=1, keepdim=True)\n",
    "        if CellWiseNormalised:\n",
    "            W = torch.div(W, sW)\n",
    "        else:\n",
    "            sW = sW.mean()\n",
    "            W = W / sW\n",
    "\n",
    "        return W.squeeze()\n",
    "    \n",
    "    def make_correlated_noise(self, dt, Nt, corr_time, grid_size=3,thetas=thetas):\n",
    "\n",
    "        # Generate temporally correlated noise\n",
    "        Tfilt = 10 * corr_time\n",
    "        Nfilt = int(Tfilt / dt)\n",
    "        ttfilt = torch.arange(0, Nfilt+1,dtype=torch.float32) * dt\n",
    "        assert Nt > len(ttfilt)\n",
    "        filter = torch.exp(-ttfilt / corr_time) * dt / corr_time\n",
    "\n",
    "        white_noise = torch.randn(self.N, Nt + Nfilt) / torch.sqrt(torch.tensor(dt)) * torch.sqrt(torch.tensor(2 * corr_time))\n",
    "\n",
    "        noise = []\n",
    "        for nn in range(self.N):\n",
    "            coloured = torch.conv1d(white_noise[nn:nn+1, :].unsqueeze(0), filter.unsqueeze(0).unsqueeze(0), padding='valid').squeeze()\n",
    "            noise.append(coloured)\n",
    "        noise = torch.stack(noise)\n",
    "\n",
    "        # params taken from Echeveste et al. 2020 - optimised values\n",
    "        noise_var_EI=torch.tensor([6.399186720550809504,3.533514014946008697]) \n",
    "        noise_std_EI = torch.sqrt(noise_var_EI)\n",
    "        rho = 0.992852418877574472 \n",
    "        d_sigma = 0.477952645032425183\n",
    "\n",
    "        # Introduce spatial correlations\n",
    "        sigma_e = noise_std_EI[0]\n",
    "        sigma_i = noise_std_EI[1]\n",
    "        \n",
    "        theta_unsq = thetas.unsqueeze(1)  # Add singleton dimension for second axis\n",
    "        theta_unsq_T = thetas.unsqueeze(0)  # Add singleton dimension for first axis\n",
    "\n",
    "        sigma_ee = sigma_e**2 * torch.exp((torch.cos(2 * (theta_unsq - theta_unsq_T)) - 1) / d_sigma**2)\n",
    "        sigma_ii = sigma_i**2 * torch.exp((torch.cos(2 * (theta_unsq - theta_unsq_T)) - 1) / d_sigma**2)\n",
    "        sigma_ei = rho * sigma_e * sigma_i * torch.exp((torch.cos(2 * (theta_unsq - theta_unsq_T)) - 1) / d_sigma**2)\n",
    "        sigma_ie = rho * sigma_e * sigma_i * torch.exp((torch.cos(2 * (theta_unsq_T - theta_unsq)) - 1) / d_sigma**2)\n",
    "\n",
    "        print(\"Sigma_ee\",sigma_ee.size())\n",
    "        blocks = [\n",
    "            torch.kron(torch.eye(9), sigma_ee),\n",
    "            torch.kron(torch.eye(9), sigma_ei),\n",
    "            torch.kron(torch.eye(grid_size), sigma_ie),\n",
    "            torch.kron(torch.eye(9), sigma_ii)\n",
    "        ]\n",
    "        print(\"Blocks\",blocks[0].size())\n",
    "\n",
    "        sigma = torch.cat([\n",
    "            torch.cat([blocks[0], blocks[1]], dim=1),\n",
    "            torch.cat([blocks[2], blocks[3]], dim=1)\n",
    "        ], dim=0).double()\n",
    "\n",
    "        print(\"Sigma\",sigma.size())\n",
    "        sigma = sigma + 1e-6 * torch.eye(sigma.size(0))\n",
    "        cholesky = torch.linalg.cholesky(sigma)\n",
    "\n",
    "        correlated_noise = cholesky @ noise\n",
    "\n",
    "        return correlated_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSN Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "k = 0.3\n",
    "tauE = 20.0\n",
    "tauI = 10.0\n",
    "grid_pars = {'grid_size_Nx': 3}\n",
    "\n",
    "psi = torch.tensor(0.774)\n",
    "conn_pars = {\n",
    "    'J_2x2': torch.tensor([[1.124, -0.931], [1.049, -0.537]],dtype=torch.float64) *torch.pi * psi, #TODO: take their a and multiply by 2 * num thetas in echeveste\n",
    "    's_2x2': torch.tensor([[0.2955, 0.09], [0.5542, 0.09]])/0.4,  # TODO: divide by 0.4\n",
    "    'p_local': torch.tensor([0.72,0.7]),  \n",
    "    'sigma_oris': torch.tensor(45.0),\n",
    "    'num_oris': 8}\n",
    "\n",
    "thetas = np.linspace(0, np.pi, conn_pars['num_oris'])\n",
    "\n",
    "ssn_params = {\n",
    "        \"n\": 2,\n",
    "        \"k\": k,\n",
    "        \"tauE\": 20,\n",
    "        \"tauI\": 10,\n",
    "        \"grid_pars\": grid_pars,\n",
    "        \"conn_pars\": conn_pars,\n",
    "        \"thetas\": thetas,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        super(DirectFit, self).__init__()\n",
    "        self.ssn_model = SSN2DTopo(**ssn_params)\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "    def sample_trajectories(self, input_batch, duration=500, dt=.2):\n",
    "\n",
    "        input_weighted = self.ssn_model.process_input(input_batch)\n",
    "\n",
    "        # Ensure input_reshaped has correct dimensions before calling simulate\n",
    "        if input_weighted.shape[1] != self.ssn_model.N:\n",
    "            input_weighted = input_weighted.view(input_weighted.shape[0], self.ssn_model.N)\n",
    "        \n",
    "        # Geenrate noise\n",
    "        noise = self.ssn_model.make_correlated_noise(dt=dt, Nt=int(duration/dt),corr_time=0.1,grid_size=3,thetas=self.fogsm_model.thetas)\n",
    "            \n",
    "        # Generate trajectories for the reshaped input\n",
    "        trajectories = self.ssn_model.simulate_batch(input_weighted, duration=duration, dt=dt)\n",
    "\n",
    "        return trajectories\n",
    "\n",
    "    def calculate_log_p_g(self, trajectory):\n",
    "        # trajectory: [num_samples_g, dim]\n",
    "        # expectation over g in Eq (25) (1st term), i.e., (sub-sampled) time-steps of SSN simulation, corresponding to samples from variational posterior of g\n",
    "\n",
    "        num_neurons = trajectory.shape[1]  # Number of neurons\n",
    "        dim = trajectory.shape[0]            # Number of time points\n",
    "\n",
    "        # Mean vector for the multivariate normal (zero mean)\n",
    "        mean = torch.zeros(num_neurons, device=trajectory.device, dtype=trajectory.dtype)\n",
    "    \n",
    "        # Covariance matrix for the multivariate normal\n",
    "        cov = self.fogsm_model.K_g\n",
    "\n",
    "        # Check covariance matrix shape\n",
    "        assert cov.shape == (num_neurons, num_neurons), f\"Expected covariance matrix of shape ({num_neurons}, {num_neurons}), but got {cov.shape}\"\n",
    "\n",
    "        # Multivariate normal distribution\n",
    "        mvg = MultivariateNormal(mean, cov)\n",
    "\n",
    "        # Calculate log probabilities for all samples in the trajectory\n",
    "        log_probs = []\n",
    "        for g in trajectory:\n",
    "            if torch.isnan(g).any() or torch.isinf(g).any():\n",
    "                print(\"Invalid values in g:\", g)\n",
    "            log_probs.append(mvg.log_prob(g))  # log_probs: [num_samples_g]\n",
    "\n",
    "        log_probs = torch.tensor(log_probs, device=trajectory.device, dtype=trajectory.dtype)\n",
    "        if torch.isnan(log_probs).any():\n",
    "            print(\"NaN detected in log_probs\")\n",
    "\n",
    "        # Return the mean log probability\n",
    "        log_p_g = log_probs.mean()\n",
    "\n",
    "        return log_p_g\n",
    "\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, I_data, trajectory, A_samples, epsilon=1e-6):\n",
    "\n",
    "        log_likelihood = 0\n",
    "\n",
    "        # expectation over g in Eq (25) (2nd term)\n",
    "        for g in trajectory: # runs over (sub-sampled) time-steps of SSN simulation, corresponding to samples from variational posterior of g\n",
    "            p_I_g = 0\n",
    "\n",
    "            # expectation over A in Eq (25)\n",
    "            for a in A_samples: # for computational cost reasons, currently using the same samples for A for all images in a batch (but we resample across mini-batches) \n",
    "                p_I_g = p_I_g + self.fogsm_model.likelihood(I_data, g, a) # I_data is a single image from the dataset and g is a single sample\n",
    "                                                                          # for g from the SSN\n",
    "                #check if p_I_g is zero or negative\n",
    "                if p_I_g < 0:\n",
    "                    print(\"p_I_g is zero\")\n",
    "\n",
    "            avg_p_I_g = p_I_g / len(A_samples)\n",
    "            avg_p_I_g = torch.clamp(avg_p_I_g, min=epsilon) # to avoid log(0)\n",
    "\n",
    "            log_likelihood = log_likelihood + torch.log(avg_p_I_g)\n",
    "        \n",
    "        return log_likelihood / len(trajectory)\n",
    "\n",
    "        \n",
    "    def calculate_elbo(self, input_batch, A_samples, duration=500, dt=.2):\n",
    "\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories = self.sample_trajectories(input_batch=input_batch, duration=duration, dt=dt)\n",
    "\n",
    "        elbo = 0\n",
    "        for I, trajectory in zip(input_batch, trajectories): # trajectory is the trajectory for a single image\n",
    "            log_p_g = self.calculate_log_p_g(trajectory)\n",
    "            log_p_I_given_g = self.calculate_log_p_I_given_g(I, trajectory, A_samples)\n",
    "\n",
    "            cov_matrix = torch.cov(trajectory.T)\n",
    "\n",
    "            if not torch.isfinite(cov_matrix).all():\n",
    "                print(\"Non-finite values in covariance matrix\")\n",
    "            \n",
    "            if torch.isnan(cov_matrix).any():\n",
    "                print(\"NaN detected in cov_matrix\")\n",
    "            \n",
    "            cov_matrix = cov_matrix + 1e-6 * torch.eye(cov_matrix.size(0))\n",
    "            entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "\n",
    "            print(\"ELBO terms: \", log_p_g, log_p_I_given_g, entropy_term)\n",
    "\n",
    "            # TODO: add a penalty term for nearest neighbour correlation in g \n",
    "            elbo = elbo + log_p_g + log_p_I_given_g + entropy_term \n",
    "\n",
    "        return elbo / len(input_batch)\n",
    "        \n",
    "    def optimise_elbo(self, batch_size, num_samples_a, threshold=1e-3, optimizer_cls=Adam, lr=1e-3,duration=10, dt=0.2):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.ssn_model.to(device)\n",
    "        self.fogsm_model.to(device)\n",
    "\n",
    "        optimizer = optimizer_cls(list(self.ssn_model.parameters()), lr=lr)\n",
    "        batch = 0\n",
    "        prev_elbo = float('-inf')\n",
    "        elbo_values = []  \n",
    "\n",
    "        while True:\n",
    "            \n",
    "            optimizer.zero_grad()  # Zero gradients at the beginning of each batch\n",
    "\n",
    "            elbo_batch = 0\n",
    "\n",
    "            # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "            A_samples = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "\n",
    "            # Generate a mini-batch of input data\n",
    "            input_batch = self.fogsm_model.generate_fogsm_dataset(batch_size).to(device)\n",
    "\n",
    "            # Calculate the ELBO for the mini-batch\n",
    "            elbo_batch = self.calculate_elbo(input_batch, A_samples, duration=duration, dt=dt)\n",
    "\n",
    "            if torch.isnan(elbo_batch).any():\n",
    "                print(\"NaN detected in elbo_batch\")\n",
    "                break\n",
    "\n",
    "            # Optimise the ELBO with respect to the model parameters\n",
    "            elbo_batch.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print the ELBO for monitoring\n",
    "            if (batch + 1) % 1 == 0:\n",
    "                print(f\"Batch [{batch+1}], ELBO: {elbo_batch / batch_size:.4f}\")\n",
    "\n",
    "            # Check for convergence\n",
    "            if abs(elbo_batch - prev_elbo) < threshold:\n",
    "                print(f\"Converged after {batch+1} batches.\")\n",
    "                break\n",
    "\n",
    "            prev_elbo = elbo_batch\n",
    "            batch = batch + 1\n",
    "            elbo_values.append(elbo_batch.item())\n",
    "\n",
    "            if batch > 100:\n",
    "                # plot the elbo values\n",
    "                plt.plot(elbo_values)\n",
    "                plt.xlabel(\"Batch\")\n",
    "                plt.ylabel(\"ELBO\")\n",
    "                plt.title(\"ELBO values\")\n",
    "                plt.show()\n",
    "\n",
    "                break\n",
    "        \n",
    "        return self.ssn_model, self.fogsm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3445253102.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3445253102.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma_ee torch.Size([8, 8])\n",
      "Blocks torch.Size([24, 24])\n",
      "Sigma torch.Size([48, 48])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (48x48 and 144x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[316], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m direct_fit \u001b[38;5;241m=\u001b[39m DirectFit(ssn_params, fogsm_params)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdirect_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimise_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[315], line 135\u001b[0m, in \u001b[0;36mDirectFit.optimise_elbo\u001b[0;34m(self, batch_size, num_samples_a, threshold, optimizer_cls, lr, duration, dt)\u001b[0m\n\u001b[1;32m    132\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfogsm_model\u001b[38;5;241m.\u001b[39mgenerate_fogsm_dataset(batch_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Calculate the ELBO for the mini-batch\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m elbo_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(elbo_batch)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN detected in elbo_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[315], line 87\u001b[0m, in \u001b[0;36mDirectFit.calculate_elbo\u001b[0;34m(self, input_batch, A_samples, duration, dt)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_elbo\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_batch, A_samples, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.2\u001b[39m):\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Sample trajectories from the SSN\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     trajectories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     elbo \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m I, trajectory \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(input_batch, trajectories): \u001b[38;5;66;03m# trajectory is the trajectory for a single image\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[315], line 17\u001b[0m, in \u001b[0;36mDirectFit.sample_trajectories\u001b[0;34m(self, input_batch, duration, dt)\u001b[0m\n\u001b[1;32m     14\u001b[0m     input_weighted \u001b[38;5;241m=\u001b[39m input_weighted\u001b[38;5;241m.\u001b[39mview(input_weighted\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssn_model\u001b[38;5;241m.\u001b[39mN)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Geenrate noise\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_correlated_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcorr_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mthetas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfogsm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthetas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Generate trajectories for the reshaped input\u001b[39;00m\n\u001b[1;32m     20\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssn_model\u001b[38;5;241m.\u001b[39msimulate_batch(input_weighted, duration\u001b[38;5;241m=\u001b[39mduration, dt\u001b[38;5;241m=\u001b[39mdt)\n",
      "Cell \u001b[0;32mIn[313], line 179\u001b[0m, in \u001b[0;36mSSN2DTopo.make_correlated_noise\u001b[0;34m(self, dt, Nt, corr_time, grid_size, thetas)\u001b[0m\n\u001b[1;32m    176\u001b[0m sigma \u001b[38;5;241m=\u001b[39m sigma \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(sigma\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    177\u001b[0m cholesky \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky(sigma)\n\u001b[0;32m--> 179\u001b[0m correlated_noise \u001b[38;5;241m=\u001b[39m \u001b[43mcholesky\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m correlated_noise\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (48x48 and 144x100)"
     ]
    }
   ],
   "source": [
    "direct_fit = DirectFit(ssn_params, fogsm_params)\n",
    "direct_fit.optimise_elbo(batch_size=3, num_samples_a=10, optimizer_cls=Adam, lr=0.001, duration=100, dt=1) #TODO: grab samples every 5ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3445253102.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3445253102.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of images:  tensor(13.2183, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute the standard deviation of FoGSM images\n",
    "\n",
    "fogsm_model = FoGSMModel(**fogsm_params)\n",
    "num_samples = 10000\n",
    "samples = []\n",
    "for _ in range(num_samples):\n",
    "    I, g = fogsm_model.samples()\n",
    "    samples.append((I, g))\n",
    "images, _ = zip(*samples)\n",
    "images = torch.stack(images)\n",
    "sd = images.std()\n",
    "print(\"Standard deviation of images: \", sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
