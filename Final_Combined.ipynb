{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f8dc8c48580>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GSM._imports import *\n",
    "from torch.optim import Adam\n",
    "from SSN._imports import *\n",
    "from SSN.params import GridParameters\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FoGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoGSMModel(nn.Module):\n",
    "    def __init__(self,thetas=None, l_feature=1.0, l_amplitude=1.2, kappa=1.0, jitter=1e-5, grid_size=10, frequency=1.0,sigma=0.1):\n",
    "        super(FoGSMModel, self).__init__()\n",
    "\n",
    "        self.dtype = torch.float64\n",
    "\n",
    "        self.l_feature = Parameter(torch.tensor(l_feature, dtype=self.dtype))\n",
    "        self.l_amplitude = Parameter(torch.tensor(l_amplitude, dtype=self.dtype))\n",
    "        self.kappa = Parameter(torch.tensor(kappa, dtype=self.dtype))\n",
    "        self.frequency = Parameter(torch.tensor(frequency, dtype=self.dtype)) \n",
    "        self.sigma = Parameter(torch.tensor(sigma))\n",
    "\n",
    "        if thetas is None:\n",
    "            thetas = torch.linspace(0, 2 * np.pi, 8)  # 8 orientations from 0 to 2*pi\n",
    "        self.thetas = thetas\n",
    "\n",
    "        self.jitter = jitter\n",
    "        self.grid_size = grid_size\n",
    "        self.grid = torch.stack(torch.meshgrid(torch.linspace(-5, 5, grid_size), \n",
    "                                               torch.linspace(-5, 5, grid_size)), \n",
    "                                dim=-1).reshape(-1, 2)\n",
    "        \n",
    "        self.K_g = self.generate_K_g()\n",
    "        \n",
    "    def von_mises_kernel(self, theta1, theta2):\n",
    "        theta_diff = theta1 - theta2  \n",
    "        return torch.clamp(torch.exp(self.kappa * torch.cos(theta_diff)), min=1e-6)\n",
    "    \n",
    "    def squared_exponential_kernel(self, x1, x2, length_scale,jitter=\"True\"):\n",
    "        x1 = x1.unsqueeze(1) # Shape: [N, 1, 2]\n",
    "        x2 = x2.unsqueeze(0) # Shape: [1, N, 2]\n",
    "        sq_dist = torch.sum((x1 - x2) ** 2, dim=2) # Shape: [N, N]\n",
    "\n",
    "        exp_term = torch.exp(-sq_dist / (2*length_scale**2))\n",
    "\n",
    "        if jitter:\n",
    "            return exp_term + self.jitter * torch.eye(x1.size(0))\n",
    "        else:\n",
    "            return exp_term\n",
    "\n",
    "    def composite_feature_kernel(self, theta1, theta2):\n",
    "         \n",
    "        sq_exp_component = self.squared_exponential_kernel(self.grid, self.grid, self.l_feature,jitter=\"False\")        \n",
    "        \n",
    "        # Ensure theta1 and theta2 are tensors\n",
    "        theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
    "        theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n",
    "\n",
    "        x1 = self.grid.unsqueeze(1) # Shape: [N, 1, 2]\n",
    "        x2 = self.grid.unsqueeze(0) # Shape: [1, N, 2]\n",
    "\n",
    "        n1 = torch.tensor([torch.cos(theta1), torch.sin(theta1)]).view(1, 1, 2)  # Shape: [1, 1, 2]\n",
    "        n2 = torch.tensor([torch.cos(theta2), torch.sin(theta2)]).view(1, 1, 2)  # Shape: [1, 1, 2]\n",
    "        average_orientation = (n1 + n2) / 2\n",
    "\n",
    "        # Broadcasting average_orientation for dot product computation\n",
    "        average_orientation = average_orientation.repeat(x1.size(0), x1.size(1), 1)\n",
    "        dot_product = torch.sum((x1 - x2) * average_orientation, dim=2)\n",
    "        periodic_component = torch.cos(2 * torch.pi * self.frequency * dot_product)\n",
    "\n",
    "        # Composite Kernel\n",
    "        return sq_exp_component * periodic_component\n",
    "\n",
    "    def generate_K_g(self):\n",
    "        \n",
    "        theta1_grid, theta2_grid = torch.meshgrid(self.thetas, self.thetas)\n",
    "        ori_kernel_val = self.von_mises_kernel(theta1_grid, theta2_grid)\n",
    "    \n",
    "        # Spatial kernel\n",
    "        loc_kernel_val = torch.zeros((len(self.thetas), len(self.thetas), self.grid_size**2, self.grid_size**2))\n",
    "\n",
    "        for i in range(len(self.thetas)):\n",
    "            for j in range(len(self.thetas)):\n",
    "                loc_kernel_val[i,j] = self.composite_feature_kernel(self.thetas[i], self.thetas[j])\n",
    "        \n",
    "        K_spatial = torch.sum(loc_kernel_val, dim=[0, 1])\n",
    "        K_g = torch.kron(K_spatial, ori_kernel_val)\n",
    "        \n",
    "        K_g = K_g + self.jitter * torch.eye(len(self.thetas)*self.grid_size**2)\n",
    "        return K_g\n",
    "\n",
    "    def compute_A(self):\n",
    "        kernel_vals = self.squared_exponential_kernel(self.grid, self.grid, self.l_amplitude)\n",
    "        return torch.sqrt(torch.exp(MultivariateNormal(torch.zeros(self.grid.size(0)), kernel_vals).sample()))\n",
    "\n",
    "    def samples(self):\n",
    "\n",
    "        g = MultivariateNormal(torch.zeros(len(self.thetas)*(self.grid_size**2)), self.K_g).sample()  \n",
    "        A = self.compute_A()\n",
    "        \n",
    "        # Tile amplitudes to match feature fields \n",
    "        A = A.repeat(len(self.thetas))\n",
    "    \n",
    "        # Combine\n",
    "        I = g * A  + torch.randn_like(g) * self.sigma\n",
    "        #I = torch.sum(I.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "\n",
    "        return I, g\n",
    "    \n",
    "    def log_likelihood(self, I, g,A):\n",
    "        A = A.repeat(len(self.thetas))\n",
    "        I_hat = g * A\n",
    "        #I_hat = torch.sum(I_hat.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "        print(\"Log likelihood I_hat \",I_hat.size())\n",
    "        print(\"Log likelihood I \",I.size())\n",
    "        return MultivariateNormal(I_hat.flatten(), self.sigma * torch.eye(self.grid_size**2)).log_prob(I.flatten())\n",
    "\n",
    "    def likelihood(self, I, g,A):\n",
    "        A = A.repeat(len(self.thetas))\n",
    "        I_hat = g * A     \n",
    "\n",
    "        # Ensure positive definite covariance matrix\n",
    "        cov_matrix = self.sigma * torch.eye(I_hat.size(0))\n",
    "        if not torch.isfinite(cov_matrix).all():\n",
    "            print(\"Non-finite values in covariance matrix\")\n",
    "            return torch.tensor(float('nan'))\n",
    "        \n",
    "        return torch.exp(MultivariateNormal(I_hat, self.sigma * torch.eye(I_hat.size(0))).log_prob(I))\n",
    "\n",
    "    def visualise(self, combined_fields):\n",
    "\n",
    "        combined_fields = torch.sum(combined_fields.reshape(len(self.thetas), self.grid_size, self.grid_size), dim=0)\n",
    "\n",
    "        # Normalise the combined image for visualisation\n",
    "        combined_fields_normalised = combined_fields / combined_fields.max()\n",
    "\n",
    "        # Reshape to image format\n",
    "        combined_image = combined_fields_normalised.view(self.grid_size, self.grid_size).detach().numpy()\n",
    "\n",
    "        # Visualise the combined image\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(combined_image, cmap='gray') \n",
    "        plt.title('FoGSM Sample')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    def generate_fogsm_dataset(self, num_samples, save=False,save_path=None):\n",
    "        samples = []\n",
    "        for _ in range(num_samples):\n",
    "            I, g = self.samples()\n",
    "            samples.append((I, g))\n",
    "    \n",
    "        # Convert samples to tensors\n",
    "        images, gs = zip(*samples)\n",
    "        images = torch.stack(images)\n",
    "        gs = torch.stack(gs)\n",
    "    \n",
    "        if save:\n",
    "            torch.save(images, gs, save_path)\n",
    "        else:\n",
    "            return images\n",
    "\n",
    "    def visualise_samples(self, save_path, num_samples_to_visualise, grid_size):\n",
    "        # Load the saved samples\n",
    "        images, _ = torch.load(save_path)\n",
    "\n",
    "        # Select a subset of samples to visualise\n",
    "        selected_samples = images[:num_samples_to_visualise]\n",
    "\n",
    "        # Create a grid of images\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))\n",
    "        fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i < num_samples_to_visualise:\n",
    "                image = selected_samples[i].detach().numpy()\n",
    "                image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "                ax.imshow(image, cmap='gray')\n",
    "        \n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_18419/3850355274.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_18419/3850355274.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "num_oris = 8\n",
    "thetas = torch.linspace(0, torch.pi, num_oris)  # 8 orientations from 0 to pi\n",
    "fogsm_params = {\n",
    "        \"thetas\": thetas,\n",
    "        \"l_feature\": 1.0,\n",
    "        \"l_amplitude\": 1.5,\n",
    "        \"kappa\": .5,\n",
    "        \"jitter\": 1e-5,\n",
    "        \"grid_size\": 3,\n",
    "        \"frequency\": .2,\n",
    "        \"sigma\": 0.1,\n",
    "    }\n",
    "fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "# Generate and visualise a sample from the FoGSM model\n",
    "I, g = fogsm_model.samples()\n",
    "#fogsm_model.visualise(I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSN Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSNBase(torch.nn.Module):\n",
    "    def __init__(self, n, k, Ne, Ni, tau_e, tau_i, device='cpu', dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.N = self.Ne + self.Ni\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.register_buffer('EI', torch.cat([torch.ones(Ne), torch.zeros(Ni)]).to(device).bool())\n",
    "        self.register_buffer('tau_vec', torch.cat([tau_e * torch.ones(Ne), tau_i * torch.ones(Ni)]).to(device, dtype))\n",
    "\n",
    "        self.C_E = nn.Parameter(torch.tensor(2.4)) # taken from Echeveste et al. 2020\n",
    "        self.C_I = nn.Parameter(torch.tensor(2.4)) # taken from Echeveste et al. 2020\n",
    "\n",
    "        b = 13.24\n",
    "        self.beta = nn.Parameter(torch.tensor(1.5 * b))\n",
    "        self.gamma = nn.Parameter(torch.tensor(0.6)) # taken from Echeveste et al. 2020\n",
    "    \n",
    "    def drdt(self, r, inp_vec):\n",
    "        return (-r + self.powlaw(self.W @ r + inp_vec)) / self.tau_vec\n",
    "\n",
    "    def powlaw(self, u):\n",
    "        return self.k * F.relu(u).pow(self.n)\n",
    "    \n",
    "    def dvdt_batch(self, v, inp_vec):\n",
    "        # Ensure v and inp_vec are 2D tensors for batch processing\n",
    "        if v.ndim == 1:\n",
    "            v = v.unsqueeze(0)\n",
    "        if inp_vec.ndim == 1:\n",
    "            inp_vec = inp_vec.unsqueeze(0)\n",
    "\n",
    "        #print(f\"dvdt: v.shape={v.shape}, inp_vec.shape={inp_vec.shape}, W.shape={self.W.shape}\")\n",
    "\n",
    "        # Compute W @ r for batch processing\n",
    "        W_r = self.W @ self.powlaw(v).T\n",
    "        W_r = W_r.T  # Transpose back to match batch dimension\n",
    "\n",
    "        return (-v + W_r + inp_vec) / self.tau_vec\n",
    "    \n",
    "    def process_input(self, input_batch):\n",
    "\n",
    "        # Non-linearity for the input to the network\n",
    "        input_rectified = F.relu(self.beta + input_batch)\n",
    "        epsilon = 1e-6  # Small value to avoid zero\n",
    "        input_processed = (input_rectified + epsilon) ** self.gamma\n",
    "\n",
    "        # Multiply the input batch by C_E and C_I scalars\n",
    "        input_weighted = torch.cat([\n",
    "            self.C_E * input_processed,\n",
    "            self.C_I * input_processed\n",
    "        ], dim=-1)\n",
    "\n",
    "        return input_weighted\n",
    "\n",
    "    def simulate_batch_rates(self, inp_vec, v_init=None, duration=500, dt=1,noise=None):\n",
    "        # inp_vec: [batch_size, num_neurons]\n",
    "        # v_init: [batch_size, num_neurons]\n",
    "        # returns: [batch_size, time_steps, num_neurons]\n",
    "        \n",
    "        time_steps = int(duration/dt)\n",
    "        print(f\"simulate: time_steps={time_steps}, dt={dt}, duration={duration}\")\n",
    "        # Check if inp_vec is a batch of inputs\n",
    "        if inp_vec.ndim == 2:\n",
    "            batch_size, self.N = inp_vec.shape \n",
    "            inp_vec = inp_vec.unsqueeze(1).expand(-1, time_steps, -1)\n",
    "        else:\n",
    "            raise ValueError(\"inp_vec must be a 2D tensor of shape [batch_size, num_neurons].\")\n",
    "\n",
    "        #print(f\"simulate: batch_size={batch_size}, time_steps={time_steps}, inp_vec.shape={inp_vec.shape}\")\n",
    "\n",
    "        # Initialise v_init if not provided\n",
    "        if v_init is None:\n",
    "            v_init = torch.zeros((batch_size, self.N), device=self.device, dtype=self.dtype)\n",
    "        else:\n",
    "            if isinstance(v_init, (int, float)):\n",
    "                v_init = torch.full((batch_size, self.N), v_init, device=self.device, dtype=self.dtype)\n",
    "            if v_init.shape[0] != batch_size or v_init.shape[1] != self.N:\n",
    "                raise ValueError(\"v_init shape does not match batch_size or neuron count N.\")\n",
    "        \n",
    "        # Initialise noise if not provided\n",
    "        if noise is None:\n",
    "            noise = torch.zeros((time_steps, self.N), device=self.device, dtype=self.dtype)\n",
    "        else:\n",
    "            if noise.shape[0] != time_steps or noise.shape[1] != self.N:\n",
    "                raise ValueError(\"noise shape does not match time_steps or neuron count N.\")\n",
    "\n",
    "        # rates: [batch_size, time_steps, Ne]\n",
    "        rates_E = torch.zeros((batch_size, time_steps, self.Ne), device=self.device, dtype=self.dtype)\n",
    "        v = v_init\n",
    "        t = dt\n",
    "        while t < duration:\n",
    "            # Calculate dv for each element in the batch at the current time step\n",
    "            dv = self.dvdt_batch(v, inp_vec[:, t, :]+noise[t])  # dv: [batch_size, num_neurons]\n",
    "\n",
    "            # Update the membrane potentials for the current time step\n",
    "            v += dt * dv\n",
    "\n",
    "            # take an average of membrane potentials over trials at each time step is constant over time\n",
    "            # but trials doesny ecist so instead average over neurons but not image\n",
    "\n",
    "            # TODO: throw away the first 100 ms burn-in time of the simulation to allow the network to settle to a stable state before recording the firing rates\n",
    "\n",
    "            # Compute the firing rates from the updated membrane potentials\n",
    "            r = self.powlaw(v) # r: [batch_size, num_neurons]\n",
    "\n",
    "            # Store the rates for the current time step\n",
    "            if t % 5 == 0:\n",
    "                rates_E[:, t, :] = r[:, :self.Ne] # rates: [batch_size, time_steps, Ne]\n",
    "\n",
    "            t = t + dt\n",
    "\n",
    "        return rates_E\n",
    "    \n",
    "    def simulate_batch(self, inp_vec, v_init=None, duration=500, dt=1,burn_in_time=100,noise=None):\n",
    "        # inp_vec: [batch_size, num_neurons]\n",
    "        # v_init: [batch_size, num_neurons]\n",
    "        # returns: [batch_size, time_steps, num_neurons]\n",
    "        \n",
    "        time_steps = int(duration/dt)\n",
    "\n",
    "        print(f\"simulate: time_steps={time_steps}, dt={dt}, duration={duration}\")\n",
    "\n",
    "        if inp_vec.ndim == 2:\n",
    "            batch_size, self.N = inp_vec.shape \n",
    "            inp_vec = inp_vec.unsqueeze(1).expand(-1, time_steps, -1)\n",
    "        else:\n",
    "            raise ValueError(\"inp_vec must be a 2D tensor of shape [batch_size, num_neurons].\")\n",
    "        \n",
    "        # Initialise v_init if not provided\n",
    "        if v_init is None:\n",
    "            v_init = torch.zeros((batch_size, self.N), device=self.device, dtype=self.dtype)\n",
    "        else:\n",
    "            if isinstance(v_init, (int, float)):\n",
    "                v_init = torch.full((batch_size, self.N), v_init, device=self.device, dtype=self.dtype)\n",
    "            if v_init.shape[0] != batch_size or v_init.shape[1] != self.N:\n",
    "                raise ValueError(\"v_init shape does not match batch_size or neuron count N.\")\n",
    "        \n",
    "        # Initialise noise if not provided\n",
    "        if noise is None:\n",
    "            noise = torch.zeros((time_steps, self.N), device=self.device, dtype=self.dtype)\n",
    "        else:\n",
    "            if noise.shape[0] != time_steps or noise.shape[1] != self.N:\n",
    "                raise ValueError(\"noise shape does not match time_steps or neuron count N.\")\n",
    "\n",
    "        # rates: [batch_size, time_steps, Ne]\n",
    "        potentials_E = torch.zeros((batch_size, time_steps, self.Ne), device=self.device, dtype=self.dtype)\n",
    "        v = v_init\n",
    "        t = 0\n",
    "\n",
    "        while t < duration:\n",
    "            # Calculate dv for each element in the batch at the current time step\n",
    "            dv = self.dvdt_batch(v, inp_vec[:, t, :]+noise[t])  # dv: [batch_size, num_neurons]\n",
    "\n",
    "            # Update the membrane potentials for the current time step\n",
    "            v += dt * dv # v: [batch_size, num_neurons]\n",
    "\n",
    "            # Store every 5th time step\n",
    "            if t >= burn_in_time:\n",
    "                # Store every 5th time step after the burn-in period\n",
    "                if (t - burn_in_time) % 5 == 0:\n",
    "                    potentials_E[:, t, :] = v[:, :self.Ne] # rates: [batch_size, time_steps, Ne]\n",
    "\n",
    "            t = t + dt\n",
    "\n",
    "        return potentials_E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSN 2DTopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSN2DTopo(SSNBase):\n",
    "    def __init__(self, n, k, tauE, tauI, grid_pars, conn_pars, thetas, L = np.pi,device='cpu', dtype=torch.float64):\n",
    "         \n",
    "        num_oris = thetas.shape[0]\n",
    "        grid_size = grid_pars['grid_size_Nx']\n",
    "                \n",
    "        Ne = num_oris * (grid_size ** 2)\n",
    "        Ni = num_oris * (grid_size ** 2)\n",
    "\n",
    "        super(SSN2DTopo, self).__init__(n=n, k=k, Ne=Ne, Ni=Ni, tau_e=tauE, tau_i=tauI, device=device, dtype=dtype)\n",
    "        \n",
    "        self.num_oris = num_oris\n",
    "        self.grid_size = grid_size\n",
    "        self.Ne = Ne\n",
    "        self.Ni = Ni\n",
    "        self.L = L\n",
    "        self.thetas = thetas\n",
    "        self._make_maps()\n",
    "        \n",
    "        # Initialise trainable parameters\n",
    "        if conn_pars is None:\n",
    "            conn_pars = {\n",
    "                'J_2x2': torch.rand(2, 2, device=device, dtype=dtype),  \n",
    "                's_2x2': torch.rand(2, 2, device=device, dtype=dtype),  \n",
    "                'p_local': torch.rand(2, device=device, dtype=dtype),  \n",
    "                'sigma_oris': torch.rand(1, device=device, dtype=dtype)  \n",
    "            }\n",
    "            \n",
    "        self.J_2x2 = nn.Parameter(conn_pars['J_2x2'])  # Interaction strengths\n",
    "        self.s_2x2 = nn.Parameter(conn_pars['s_2x2']) # Spatial length scales\n",
    "        self.p_local = nn.Parameter(conn_pars['p_local']) # Local connectivity strengths\n",
    "        self.sigma_oris = nn.Parameter(conn_pars['sigma_oris']) # Orientation tuning width\n",
    "        \n",
    "        self.make_W()\n",
    "\n",
    "    def _make_maps(self):\n",
    "\n",
    "        self.ori_map = torch.tensor(self.thetas, device=self.device, dtype=self.dtype).flatten()\n",
    "        self.ori_vec = self.ori_map.repeat(self.grid_size ** 2)  # Repeat orientation values for each grid cell\n",
    "        self.ori_vec = self.ori_vec.repeat(2) # Repeat for E and I populations\n",
    "\n",
    "        # Create x and y vectors for grid cells\n",
    "        self.x_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_oris).repeat(self.grid_size)\n",
    "        self.y_vec = torch.arange(self.grid_size, device=self.device, dtype=self.dtype).repeat_interleave(self.num_oris * self.grid_size)\n",
    "\n",
    "        # Repeat for E and I populations\n",
    "        self.x_vec = self.x_vec.repeat(2)\n",
    "        self.y_vec = self.y_vec.repeat(2)\n",
    "    \n",
    "    def calc_xy_dist(self):\n",
    "        Ne = Ni = self.Ne\n",
    "        x_vec_e = self.x_vec[:Ne]\n",
    "        y_vec_e = self.y_vec[:Ne]\n",
    "        x_vec_i = self.x_vec[Ne:Ne+Ni]\n",
    "        y_vec_i = self.y_vec[Ne:Ne+Ni]\n",
    "        \n",
    "        xy_dist = torch.cdist(torch.stack([x_vec_e, y_vec_e], dim=1), torch.stack([x_vec_i, y_vec_i], dim=1), p=2).repeat(2, 2) \n",
    "\n",
    "        return xy_dist\n",
    "    \n",
    "    def calc_ori_dist(self,L=np.pi, method=None):\n",
    "\n",
    "        Ne = self.num_oris * self.grid_size ** 2\n",
    "        ori_vec = self.ori_vec[:Ne]\n",
    "\n",
    "        if method == \"absolute\":\n",
    "            ori_dist = torch.cdist(ori_vec.unsqueeze(1), ori_vec.unsqueeze(1)).repeat(2,2)\n",
    "        else:\n",
    "            #1 - cos(2(pi/L) * |theta1 - theta2|^2)\n",
    "            ori_diff = torch.abs(ori_vec.unsqueeze(1) - ori_vec.unsqueeze(0))\n",
    "            ori_diff = torch.min(ori_diff, 2*np.pi - ori_diff)\n",
    "            sq_ori_dist = 1 - torch.cos((2*np.pi / L) * ori_diff**2)\n",
    "                    \n",
    "        sq_ori_dist = sq_ori_dist.repeat(2, 2)\n",
    "\n",
    "        return sq_ori_dist\n",
    "\n",
    "    def make_W(self):\n",
    "        \n",
    "        xy_dist = self.calc_xy_dist()\n",
    "        sq_ori_dist = self.calc_ori_dist()\n",
    "\n",
    "        # Compute weight blocks\n",
    "        W_ee = self.calc_W_block(xy_dist[:self.Ne, :self.Ne], sq_ori_dist[:self.Ne, :self.Ne], self.s_2x2[0][0], self.sigma_oris, excitatory='EE')\n",
    "        W_ei = self.calc_W_block(xy_dist[:self.Ne, self.Ne:], sq_ori_dist[:self.Ne, self.Ne:], self.s_2x2[0][1], self.sigma_oris, excitatory='EI')\n",
    "        W_ie = self.calc_W_block(xy_dist[self.Ne:, :self.Ne], sq_ori_dist[self.Ne:, :self.Ne], self.s_2x2[1][0], self.sigma_oris)\n",
    "        W_ii = self.calc_W_block(xy_dist[self.Ne:, self.Ne:], sq_ori_dist[self.Ne:, self.Ne:], self.s_2x2[1][1], self.sigma_oris)\n",
    "        \n",
    "        # Apply local connectivity strengths\n",
    "        W_ee = self.p_local[0] * torch.eye(self.Ne, device=self.device, dtype=self.dtype) + (1 - self.p_local[0]) * W_ee\n",
    "        W_ei = self.p_local[1] * torch.eye(self.Ni, device=self.device, dtype=self.dtype) + (1 - self.p_local[1]) * W_ei\n",
    "                \n",
    "        # Concatenate submatrices to form W\n",
    "        W = torch.cat([\n",
    "            torch.cat([self.J_2x2[0, 0] * W_ee, self.J_2x2[0, 1] * W_ei], dim=1).clone().detach(),\n",
    "            torch.cat([self.J_2x2[1, 0] * W_ie, self.J_2x2[1, 1] * W_ii], dim=1).clone().detach()\n",
    "        ], dim=0).double()\n",
    "\n",
    "        # Register W as a buffer\n",
    "        self.register_buffer('W', W)\n",
    "        \n",
    "        return self.W\n",
    "\n",
    "    def calc_W_block(self, xy_dist, sq_ori_dist, s, sigma_oris, CellWiseNormalised = True, excitatory=None):\n",
    "\n",
    "        #Add a small constant to s and sigma_oris to avoid division by zero\n",
    "        s = s + 1e-8\n",
    "        sigma_oris = 2*np.pi*sigma_oris/self.L + 1e-8\n",
    "        \n",
    "        if excitatory == 'EE':\n",
    "            W =  torch.exp(-xy_dist / s - sq_ori_dist / (2 * sigma_oris ** 2))\n",
    "        else:\n",
    "            W =  torch.exp(-xy_dist ** 2 / (2 * s ** 2) - sq_ori_dist / (2 * sigma_oris ** 2))\n",
    "                               \n",
    "        W = torch.where(W < 1e-4, torch.zeros_like(W), W)\n",
    "\n",
    "        sW = torch.sum(W, dim=1, keepdim=True)\n",
    "        if CellWiseNormalised:\n",
    "            W = torch.div(W, sW)\n",
    "        else:\n",
    "            sW = sW.mean()\n",
    "            W = W / sW\n",
    "\n",
    "        return W.squeeze()\n",
    "    \n",
    "    def make_correlated_noise(self, dt, Nt, corr_time, grid_size=3):\n",
    "\n",
    "        # Generate temporally correlated noise\n",
    "        Tfilt = 10 * corr_time\n",
    "        Nfilt = int(Tfilt / dt)\n",
    "        ttfilt = torch.arange(0, Nfilt+1,dtype=torch.float32) * dt\n",
    "        assert Nt > len(ttfilt)\n",
    "        filter = torch.exp(-ttfilt / corr_time) * dt / corr_time\n",
    "\n",
    "        white_noise = torch.randn(self.N, Nt + Nfilt) / torch.sqrt(torch.tensor(dt)) * torch.sqrt(torch.tensor(2 * corr_time))\n",
    "\n",
    "        noise = []\n",
    "        for nn in range(self.N):\n",
    "            coloured = torch.conv1d(white_noise[nn:nn+1, :].unsqueeze(0), filter.unsqueeze(0).unsqueeze(0), padding='valid').squeeze()\n",
    "            noise.append(coloured)\n",
    "        noise = torch.stack(noise)\n",
    "\n",
    "        # params taken from Echeveste et al. 2020 - optimised values\n",
    "        noise_var_EI=torch.tensor([6.399186720550809504,3.533514014946008697]) \n",
    "        noise_std_EI = torch.sqrt(noise_var_EI)\n",
    "        rho = 0.992852418877574472 \n",
    "        d_sigma = 0.477952645032425183\n",
    "\n",
    "        # Introduce spatial correlations\n",
    "        sigma_e = noise_std_EI[0]\n",
    "        sigma_i = noise_std_EI[1]\n",
    "        \n",
    "        theta_unsq = self.thetas.unsqueeze(1)  \n",
    "        theta_unsq_T = self.thetas.unsqueeze(0)  \n",
    "\n",
    "        sigma_ee = sigma_e**2 * torch.exp((torch.cos(2 * (theta_unsq - theta_unsq_T)) - 1) / d_sigma**2)\n",
    "        sigma_ii = sigma_i**2 * torch.exp((torch.cos(2 * (theta_unsq - theta_unsq_T)) - 1) / d_sigma**2)\n",
    "        sigma_ei = rho * sigma_e * sigma_i * torch.exp((torch.cos(2 * (theta_unsq - theta_unsq_T)) - 1) / d_sigma**2)\n",
    "        sigma_ie = rho * sigma_e * sigma_i * torch.exp((torch.cos(2 * (theta_unsq_T - theta_unsq)) - 1) / d_sigma**2)\n",
    "\n",
    "        blocks = [\n",
    "            torch.kron(torch.eye(grid_size**2), sigma_ee),\n",
    "            torch.kron(torch.eye(grid_size**2), sigma_ei),\n",
    "            torch.kron(torch.eye(grid_size**2), sigma_ie),\n",
    "            torch.kron(torch.eye(grid_size**2), sigma_ii)\n",
    "        ]\n",
    "\n",
    "        sigma = torch.cat([\n",
    "            torch.cat([blocks[0], blocks[1]], dim=1),\n",
    "            torch.cat([blocks[2], blocks[3]], dim=1)\n",
    "        ], dim=0).double()\n",
    "\n",
    "        sigma = sigma + 1e-6 * torch.eye(sigma.size(0))\n",
    "        cholesky = torch.linalg.cholesky(sigma)\n",
    "\n",
    "        # set dtype to float64\n",
    "        noise = noise.double()\n",
    "        cholesky = cholesky.double()\n",
    "\n",
    "        correlated_noise = cholesky @ noise\n",
    "\n",
    "        return correlated_noise.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSN Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "k = 0.3\n",
    "tauE = 20.0\n",
    "tauI = 10.0\n",
    "grid_pars = {'grid_size_Nx': 3}\n",
    "\n",
    "psi = torch.tensor(0.774)\n",
    "conn_pars = {\n",
    "    'J_2x2': torch.tensor([[.624, -1.931], [1.049, -0.537]],dtype=torch.float64) *torch.pi * psi, #TODO: take their a and multiply by 2 * num thetas in echeveste\n",
    "    's_2x2': torch.tensor([[0.2955, 0.09], [0.5542, 0.09]])/0.4,  # TODO: divide by 0.4\n",
    "    'p_local': torch.tensor([0.72,0.7]),  \n",
    "    'sigma_oris': torch.tensor(45.0),\n",
    "    'num_oris': 8}\n",
    "\n",
    "thetas = torch.linspace(0, torch.pi, conn_pars['num_oris'])\n",
    "\n",
    "ssn_params = {\n",
    "        \"n\": 2,\n",
    "        \"k\": k,\n",
    "        \"tauE\": 20,\n",
    "        \"tauI\": 10,\n",
    "        \"grid_pars\": grid_pars,\n",
    "        \"conn_pars\": conn_pars,\n",
    "        \"thetas\": thetas,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_18419/1401682589.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ori_map = torch.tensor(self.thetas, device=self.device, dtype=self.dtype).flatten()\n"
     ]
    }
   ],
   "source": [
    "# produce a fogsm sample\n",
    "I, g = fogsm_model.samples()\n",
    "\n",
    "# simulate the SSN model\n",
    "ssn_model = SSN2DTopo(**ssn_params)\n",
    "\n",
    "# process the input\n",
    "inp_vec = ssn_model.process_input(I)\n",
    "inp_vec = inp_vec.unsqueeze(0)\n",
    "\n",
    "# create correlated noise\n",
    "dt = 1\n",
    "Nt = 500\n",
    "corr_time = 10\n",
    "noise = ssn_model.make_correlated_noise(dt, Nt, corr_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulate: time_steps=500, dt=1, duration=500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simulate the SSN model\n",
    "potentials = ssn_model.simulate_batch(inp_vec, duration=500, dt=1,noise=noise)\n",
    "rates = ssn_model.powlaw(potentials)\n",
    "\n",
    "# plot the rate of ith neuron over time\n",
    "for i in range (ssn_model.Ne):\n",
    "    if rates[0,:,i].max() < 10000:\n",
    "        plt.plot(rates[0,:,i].detach().numpy())\n",
    "    else:\n",
    "        print(\"Rate of neuron \",i,\" is too high to plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        super(DirectFit, self).__init__()\n",
    "        self.ssn_model = SSN2DTopo(**ssn_params)\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "    def sample_trajectories(self, input_batch, duration=500, dt=.2):\n",
    "\n",
    "        input_weighted = self.ssn_model.process_input(input_batch)\n",
    "\n",
    "        # Ensure input_reshaped has correct dimensions before calling simulate\n",
    "        if input_weighted.shape[1] != self.ssn_model.N:\n",
    "            input_weighted = input_weighted.view(input_weighted.shape[0], self.ssn_model.N)\n",
    "        \n",
    "        # Geenrate noise\n",
    "        noise = self.ssn_model.make_correlated_noise(dt=dt, Nt=int(duration/dt),corr_time=0.5,grid_size=3)\n",
    "            \n",
    "        # Generate trajectories for the reshaped input\n",
    "        potentials = self.ssn_model.simulate_batch(input_weighted, duration=duration, dt=dt,noise=noise)\n",
    "        trajectories = self.ssn_model.powlaw(potentials)\n",
    "\n",
    "        return trajectories,potentials\n",
    "\n",
    "    def calculate_log_p_g(self, trajectory):\n",
    "        # trajectory: [num_samples_g, dim]\n",
    "        # expectation over g in Eq (25) (1st term), i.e., (sub-sampled) time-steps of SSN simulation, corresponding to samples from variational posterior of g\n",
    "\n",
    "        num_neurons = trajectory.shape[1]  # Number of neurons\n",
    "        dim = trajectory.shape[0]            # Number of time points\n",
    "\n",
    "        # Mean vector for the multivariate normal (zero mean)\n",
    "        mean = torch.zeros(num_neurons, device=trajectory.device, dtype=trajectory.dtype)\n",
    "    \n",
    "        # Covariance matrix for the multivariate normal\n",
    "        cov = self.fogsm_model.K_g\n",
    "\n",
    "        # Check covariance matrix shape\n",
    "        assert cov.shape == (num_neurons, num_neurons), f\"Expected covariance matrix of shape ({num_neurons}, {num_neurons}), but got {cov.shape}\"\n",
    "\n",
    "        # Multivariate normal distribution\n",
    "        mvg = MultivariateNormal(mean, cov)\n",
    "\n",
    "        # Calculate log probabilities for all samples in the trajectory\n",
    "        log_probs = []\n",
    "        for g in trajectory:\n",
    "            if torch.isnan(g).any() or torch.isinf(g).any():\n",
    "                print(\"Invalid values in g:\", g)\n",
    "            log_probs.append(mvg.log_prob(g))  # log_probs: [num_samples_g]\n",
    "\n",
    "        log_probs = torch.tensor(log_probs, device=trajectory.device, dtype=trajectory.dtype)\n",
    "        if torch.isnan(log_probs).any():\n",
    "            print(\"NaN detected in log_probs\")\n",
    "\n",
    "        # Return the mean log probability\n",
    "        log_p_g = log_probs.mean()\n",
    "\n",
    "        return log_p_g\n",
    "\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, I_data, trajectory, A_samples, epsilon=1e-6):\n",
    "\n",
    "        log_likelihood = 0\n",
    "\n",
    "        # expectation over g in Eq (25) (2nd term)\n",
    "        for g in trajectory: # runs over (sub-sampled) time-steps of SSN simulation, corresponding to samples from variational posterior of g\n",
    "            p_I_g = 0\n",
    "\n",
    "            # expectation over A in Eq (25)\n",
    "            for a in A_samples: # for computational cost reasons, currently using the same samples for A for all images in a batch (but we resample across mini-batches) \n",
    "                p_I_g = p_I_g + self.fogsm_model.likelihood(I_data, g, a) # I_data is a single image from the dataset and g is a single sample\n",
    "                                                                          # for g from the SSN\n",
    "                #check if p_I_g is zero or negative\n",
    "                if p_I_g < 0:\n",
    "                    print(\"p_I_g is zero\")\n",
    "\n",
    "            avg_p_I_g = p_I_g / len(A_samples)\n",
    "            avg_p_I_g = torch.clamp(avg_p_I_g, min=epsilon) # to avoid log(0)\n",
    "\n",
    "            log_likelihood = log_likelihood + torch.log(avg_p_I_g)\n",
    "        \n",
    "        return log_likelihood / len(trajectory)\n",
    "\n",
    "    def calc_lambda_0(self,elbo_batches,potentials):\n",
    "        # potentials: [batch_size, time_steps, num_neurons]\n",
    "        # elbo: [batch_size]\n",
    "\n",
    "        # Calculate the mean of squared potentials\n",
    "        v_squared = potentials**2\n",
    "        avg_v_squared = torch.mean(v_squared, dim=-1) # Average over neurons - [batch_size, time_steps]\n",
    "\n",
    "        print(\"Avg v squared: \", avg_v_squared.shape)\n",
    "        print(\"ELBO batches: \", elbo_batches.shape)\n",
    "        lambda_0 = elbo_batches.unsqueeze(1) / avg_v_squared # [batch_size, time_steps]\n",
    "\n",
    "        return lambda_0\n",
    "    \n",
    "    def regularisation_term(self, potentials, elbo_image, skip_steps=10, lambda_factor=1.0, option='b'):\n",
    "        # potentials: [batch_size, time_steps, num_neurons]\n",
    "\n",
    "        # Calculate the average of squared potentials over neurons\n",
    "        v_mean = torch.mean(potentials**2, dim=-1) # shape: [batch_size, time_steps]\n",
    "\n",
    "        # Calculate the regularization term\n",
    "        time_steps = v_mean.shape[0]\n",
    "\n",
    "        indices = torch.arange(0, time_steps, skip_steps)\n",
    "        v_mean = v_mean[indices]\n",
    "\n",
    "        if option == 'a':\n",
    "            # Option a) Taking the absolute difference of nearest neighbor time steps\n",
    "            diff_a = torch.abs(v_mean[1:] - v_mean[:-1])\n",
    "            reg_term = torch.sum(diff_a)\n",
    "        else:\n",
    "            # Option b) Taking the difference across all pairs of time steps\n",
    "            diff_b = torch.abs(v_mean.unsqueeze(0) - v_mean.unsqueeze(1)) \n",
    "            reg_term = torch.sum(diff_b) \n",
    "        \n",
    "        lambda_0 = self.calc_lambda_0(elbo_image,potentials)\n",
    "        \n",
    "        # reg_term shape: [batch_size]\n",
    "        # lambda_0 shape: [batch_size, time_steps]\n",
    "        \n",
    "        print(\"Reg term: \", reg_term.shape)\n",
    "        print(\"Lambda_0: \", lambda_0.shape)\n",
    "        \n",
    "        reg_term = lambda_factor * lambda_0 * reg_term\n",
    "\n",
    "        return reg_term\n",
    "\n",
    "    def calculate_elbo(self, input_batch, A_samples, duration=500, dt=.2):\n",
    "\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories,potentials = self.sample_trajectories(input_batch=input_batch, duration=duration, dt=dt)\n",
    "\n",
    "        elbo = 0\n",
    "        for I, trajectory in zip(input_batch, trajectories): # trajectory is the trajectory for a single image\n",
    "            log_p_g = self.calculate_log_p_g(trajectory)\n",
    "            log_p_I_given_g = self.calculate_log_p_I_given_g(I, trajectory, A_samples)\n",
    "\n",
    "            cov_matrix = torch.cov(trajectory.T)\n",
    "\n",
    "            if not torch.isfinite(cov_matrix).all():\n",
    "                print(\"Non-finite values in covariance matrix\")\n",
    "            \n",
    "            if torch.isnan(cov_matrix).any():\n",
    "                print(\"NaN detected in cov_matrix\")\n",
    "            \n",
    "            cov_matrix = cov_matrix + 1e-6 * torch.eye(cov_matrix.size(0))\n",
    "            entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "\n",
    "            print(\"ELBO terms: \", log_p_g, log_p_I_given_g, entropy_term)\n",
    " \n",
    "            elbo_image = log_p_g + log_p_I_given_g + entropy_term \n",
    "\n",
    "            # TODO: add a penalty term for nearest neighbour correlation in g \n",
    "            elbo = elbo + elbo_image + self.regularisation_term(potentials,elbo_image)\n",
    "\n",
    "        return elbo / len(input_batch)\n",
    "        \n",
    "    def optimise_elbo(self, batch_size, num_samples_a, threshold=1e-3, optimizer_cls=Adam, lr=1e-3,duration=10, dt=0.2):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.ssn_model.to(device)\n",
    "        self.fogsm_model.to(device)\n",
    "\n",
    "        optimizer = optimizer_cls(list(self.ssn_model.parameters()), lr=lr)\n",
    "        batch = 0\n",
    "        prev_elbo = float('-inf')\n",
    "        elbo_values = []  \n",
    "\n",
    "        while True:\n",
    "            \n",
    "            optimizer.zero_grad()  # Zero gradients at the beginning of each batch\n",
    "\n",
    "            elbo_batch = 0\n",
    "\n",
    "            # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "            A_samples = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "\n",
    "            # Generate a mini-batch of input data\n",
    "            input_batch = self.fogsm_model.generate_fogsm_dataset(batch_size).to(device)\n",
    "\n",
    "            # Calculate the ELBO for the mini-batch\n",
    "            elbo_batch = self.calculate_elbo(input_batch, A_samples, duration=duration, dt=dt)\n",
    "\n",
    "            if torch.isnan(elbo_batch).any():\n",
    "                print(\"NaN detected in elbo_batch\")\n",
    "                break\n",
    "\n",
    "            # Optimise the ELBO with respect to the model parameters\n",
    "            elbo_batch.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print the ELBO for monitoring\n",
    "            if (batch + 1) % 1 == 0:\n",
    "                print(f\"Batch [{batch+1}], ELBO: {elbo_batch / batch_size:.4f}\")\n",
    "\n",
    "            # Check for convergence\n",
    "            if abs(elbo_batch - prev_elbo) < threshold:\n",
    "                print(f\"Converged after {batch+1} batches.\")\n",
    "                break\n",
    "\n",
    "            prev_elbo = elbo_batch\n",
    "            batch = batch + 1\n",
    "            elbo_values.append(elbo_batch.item())\n",
    "\n",
    "            if batch > 100:\n",
    "                # plot the elbo values\n",
    "                plt.plot(elbo_values)\n",
    "                plt.xlabel(\"Batch\")\n",
    "                plt.ylabel(\"ELBO\")\n",
    "                plt.title(\"ELBO values\")\n",
    "                plt.show()\n",
    "\n",
    "                break\n",
    "        \n",
    "        return self.ssn_model, self.fogsm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_18419/1401682589.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ori_map = torch.tensor(self.thetas, device=self.device, dtype=self.dtype).flatten()\n",
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_18419/3850355274.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_18419/3850355274.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "simulate: time_steps=100, dt=1, duration=100\n",
      "ELBO terms:  tensor(-94.5970, dtype=torch.float64) tensor(-13.8155, grad_fn=<DivBackward0>) tensor(-497.3584, dtype=torch.float64)\n",
      "Avg v squared:  torch.Size([3, 100])\n",
      "ELBO batches:  torch.Size([])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m direct_fit \u001b[38;5;241m=\u001b[39m DirectFit(ssn_params, fogsm_params)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdirect_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimise_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[134], line 184\u001b[0m, in \u001b[0;36mDirectFit.optimise_elbo\u001b[0;34m(self, batch_size, num_samples_a, threshold, optimizer_cls, lr, duration, dt)\u001b[0m\n\u001b[1;32m    181\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfogsm_model\u001b[38;5;241m.\u001b[39mgenerate_fogsm_dataset(batch_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Calculate the ELBO for the mini-batch\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m elbo_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(elbo_batch)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN detected in elbo_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[134], line 157\u001b[0m, in \u001b[0;36mDirectFit.calculate_elbo\u001b[0;34m(self, input_batch, A_samples, duration, dt)\u001b[0m\n\u001b[1;32m    154\u001b[0m     elbo_image \u001b[38;5;241m=\u001b[39m log_p_g \u001b[38;5;241m+\u001b[39m log_p_I_given_g \u001b[38;5;241m+\u001b[39m entropy_term \n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# TODO: add a penalty term for nearest neighbour correlation in g \u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     elbo \u001b[38;5;241m=\u001b[39m elbo \u001b[38;5;241m+\u001b[39m elbo_image \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregularisation_term\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpotentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43melbo_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m elbo \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_batch)\n",
      "Cell \u001b[0;32mIn[134], line 119\u001b[0m, in \u001b[0;36mDirectFit.regularisation_term\u001b[0;34m(self, potentials, elbo_image, skip_steps, lambda_factor, option)\u001b[0m\n\u001b[1;32m    116\u001b[0m     diff_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(v_mean\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m v_mean\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)) \n\u001b[1;32m    117\u001b[0m     reg_term \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(diff_b) \n\u001b[0;32m--> 119\u001b[0m lambda_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_lambda_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43melbo_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpotentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# reg_term shape: [batch_size]\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# lambda_0 shape: [batch_size, time_steps]\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReg term: \u001b[39m\u001b[38;5;124m\"\u001b[39m, reg_term\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[134], line 94\u001b[0m, in \u001b[0;36mDirectFit.calc_lambda_0\u001b[0;34m(self, elbo_batches, potentials)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvg v squared: \u001b[39m\u001b[38;5;124m\"\u001b[39m, avg_v_squared\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mELBO batches: \u001b[39m\u001b[38;5;124m\"\u001b[39m, elbo_batches\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 94\u001b[0m lambda_0 \u001b[38;5;241m=\u001b[39m \u001b[43melbo_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m avg_v_squared \u001b[38;5;66;03m# [batch_size, time_steps]\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lambda_0\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "direct_fit = DirectFit(ssn_params, fogsm_params)\n",
    "direct_fit.optimise_elbo(batch_size=3, num_samples_a=10, optimizer_cls=Adam, lr=0.001, duration=100, dt=1) #TODO: grab samples every 5ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3445253102.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1).clone().detach().requires_grad_(True)\n",
      "/var/folders/l7/fy1r11ts4_3988dhm6lgmr2w0000gn/T/ipykernel_83470/3445253102.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2).clone().detach().requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of images:  tensor(13.2183, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute the standard deviation of FoGSM images\n",
    "\n",
    "fogsm_model = FoGSMModel(**fogsm_params)\n",
    "num_samples = 10000\n",
    "samples = []\n",
    "for _ in range(num_samples):\n",
    "    I, g = fogsm_model.samples()\n",
    "    samples.append((I, g))\n",
    "images, _ = zip(*samples)\n",
    "images = torch.stack(images)\n",
    "sd = images.std()\n",
    "print(\"Standard deviation of images: \", sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
