{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct fit SSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from GSM._imports import *\n",
    "from GSM.fogsm import FoGSMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSN._imports import *\n",
    "from SSN.ssn_2dtopoV1 import SSN2DTopoV1\n",
    "from SSN.params import GridParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        super(DirectFit, self).__init__()\n",
    "        self.ssn_model = SSN2DTopoV1(**ssn_params)\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "    def sample_trajectories(self, input_batch, num_samples_g, duration=500, dt=1):\n",
    "        batch_size = input_batch.shape[0]\n",
    "\n",
    "        # Expand input_batch to match the number of samples\n",
    "        input_expanded = input_batch.unsqueeze(1).expand(batch_size, num_samples_g, -1)\n",
    "\n",
    "        # Reshape input_expanded to (batch_size * num_samples, input_size)\n",
    "        input_reshaped = input_expanded.reshape(-1, input_batch.shape[-1])\n",
    "\n",
    "        # Generate trajectories for the reshaped input\n",
    "        trajectories = self.ssn_model.run_simulation(input_reshaped, duration, dt)\n",
    "\n",
    "        # Reshape trajectories to (batch_size, num_samples, N)\n",
    "        trajectories = trajectories.reshape(batch_size, num_samples_g)\n",
    "\n",
    "        return trajectories\n",
    "\n",
    "    def calculate_log_p_g(self, trajectories):\n",
    "        mu = torch.zeros_like(trajectories[0])\n",
    "        log_p_g = MultivariateNormal(mu, self.fogsm_model.K_g).log_prob(trajectories).mean()\n",
    "        return log_p_g\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, trajectories, A_samples):\n",
    "        \n",
    "        # Calculate log p(I|g,A) for each sample\n",
    "        log_likelihood = []\n",
    "        for a in A_samples:\n",
    "            log_p = 0\n",
    "            for g in trajectories:\n",
    "                I = g * a\n",
    "                log_p += self.fogsm_model.log_likelihood(I)\n",
    "            log_likelihood.append(log_p / len(trajectories))\n",
    "        \n",
    "        # Approximate the expectation over A using Monte Carlo sampling\n",
    "        p_I_given_g = torch.exp(torch.stack(log_likelihood)).mean()\n",
    "        log_p_I_given_g = torch.log(p_I_given_g)\n",
    "\n",
    "        return log_p_I_given_g\n",
    "\n",
    "    def calculate_elbo(self, input_batch, num_samples_g, A_samples, duration=500, dt=1):\n",
    "\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories = self.sample_trajectories(input_batch, num_samples_g, duration, dt)\n",
    "\n",
    "        # Calculate the first two terms of the ELBO using Monte Carlo approximation\n",
    "        log_p_g = self.calculate_log_p_g(trajectories)\n",
    "        log_p_I_given_g = self.calculate_log_p_I_given_g(trajectories, A_samples)\n",
    "\n",
    "        # Approximate the entropy term\n",
    "        # cov_matrix = torch.cov(trajectories.reshape(num_samples_g, -1).T)\n",
    "\n",
    "        cov_matrix = torch.cov(trajectories.reshape(trajectories.shape[0], -1))\n",
    "        entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "\n",
    "        elbo = log_p_g + log_p_I_given_g - entropy_term\n",
    "\n",
    "        return elbo\n",
    "    \n",
    "    def optimise_elbo(self, input_data, batch_size, num_samples_a, num_samples_g, num_epochs, optimizer):\n",
    "        dataset = torch.utils.data.TensorDataset(input_data)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            elbo_epoch = 0\n",
    "            for input_batch in dataloader:\n",
    "                input_batch = input_batch[0]\n",
    "\n",
    "                # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "                A_samples = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "\n",
    "                # Calculate the ELBO for the mini-batch\n",
    "                elbo_batch = self.calculate_elbo(input_batch, num_samples_g, A_samples)\n",
    "                elbo += elbo_batch.item()\n",
    "\n",
    "                # Resample As for each mini-batch\n",
    "                self.fogsm_model.resample_A()\n",
    "\n",
    "                # Optimize the ELBO with respect to the model parameters\n",
    "                elbo.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Print the ELBO for monitoring\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], ELBO: {elbo_epoch / len(dataloader):.4f}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSN2DTopoV1.__init__\n",
      "grid_pars:  <SSN.params.GridParameters object at 0x7fea39f147c0>\n",
      "conn_pars:  {'J_2x2': tensor([[ 2.7331, -2.2638],\n",
      "        [ 2.5507, -1.3058]], dtype=torch.float64), 's_2x2': tensor([[0.2955, 0.0900],\n",
      "        [0.5542, 0.0900]]), 'p_local': [0.72, 0.7], 'sigma_oris': 45}\n",
      "Making W\n",
      "W made\n",
      "SSN2DTopoV1.__init__ done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khushu/opt/anaconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1695391836761/work/aten/src/ATen/native/TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/Users/khushu/Desktop/IIB_Project FoGSM 2dSSN/GSM/fogsm.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta1 = torch.tensor(theta1)\n",
      "/Users/khushu/Desktop/IIB_Project FoGSM 2dSSN/GSM/fogsm.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta2 = torch.tensor(theta2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Create an optimiser for the ELBO\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m optimiser \u001b[38;5;241m=\u001b[39m \u001b[43mAdam\u001b[49m(\u001b[38;5;28mlist\u001b[39m(direct_fit\u001b[38;5;241m.\u001b[39mssn_model\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(direct_fit\u001b[38;5;241m.\u001b[39mfogsm_model\u001b[38;5;241m.\u001b[39mparameters()), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Run the ELBO optimisation\u001b[39;00m\n\u001b[1;32m     65\u001b[0m direct_fit\u001b[38;5;241m.\u001b[39moptimise_elbo(\u001b[38;5;28;01mNone\u001b[39;00m, num_samples, num_epochs, optimiser)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the parameters for the FoGSM model\n",
    "length_scale_feature = 0.5\n",
    "length_scale_amplitude = 1.2\n",
    "kappa = 1.0\n",
    "grid_size = 10\n",
    "frequency = 0.9\n",
    "sigma = 0.1\n",
    "thetas = torch.linspace(0, 2 * torch.pi, 8)  # 8 orientations from 0 to 2*pi\n",
    "\n",
    "fogsm_params = {\n",
    "        \"thetas\": thetas,\n",
    "        \"length_scale_feature\": length_scale_feature,\n",
    "        \"length_scale_amplitude\": length_scale_amplitude,\n",
    "        \"kappa\": kappa,\n",
    "        \"jitter\": 1e-4,\n",
    "        \"grid_size\": grid_size,\n",
    "        \"frequency\": frequency,\n",
    "        \"sigma\": sigma,\n",
    "    }\n",
    "\n",
    "# Define the parameters for the SSN model\n",
    "grid_pars = GridParameters(\n",
    "    gridsize_Nx=17,  # Number of grid points in one dimension\n",
    "    gridsize_deg=3.2,  # Size of the grid in degrees of visual angle\n",
    "    magnif_factor=2,  # Magnification factor to convert degrees to mm\n",
    "    hyper_col=800,  # Hypercolumn\n",
    "    )\n",
    "\n",
    "psi = torch.tensor(0.774)\n",
    "\n",
    "#LEARN all the conn parameters in the optimisation \n",
    "conn_pars = {\n",
    "        'J_2x2': torch.tensor([[1.124, -0.931], [1.049, -0.537]], dtype=torch.float64) * torch.pi * psi,\n",
    "        's_2x2': torch.tensor([[0.2955, 0.09], [0.5542, 0.09]]),\n",
    "        'p_local': [0.72, 0.7],\n",
    "        'sigma_oris': 45,\n",
    "    }\n",
    "\n",
    "n = 2\n",
    "k = 0.04\n",
    "tauE = 20  # Time constant for excitatory neurons\n",
    "tauI = 10  # Time constant for inhibitory neurons\n",
    "\n",
    "ssn_params = {\n",
    "        \"n\": n,\n",
    "        \"k\": k,\n",
    "        \"tauE\": tauE,\n",
    "        \"tauI\": tauI,\n",
    "        \"grid_pars\": grid_pars,\n",
    "        \"conn_pars\": conn_pars,\n",
    "    }\n",
    "\n",
    "direct_fit = DirectFit(ssn_params, fogsm_params)\n",
    "\n",
    "# Define the number of samples and epochs for ELBO optimisation\n",
    "num_samples = 100\n",
    "num_epochs = 1000\n",
    "\n",
    "# Create an optimiser for the ELBO\n",
    "optimiser = Adam(list(direct_fit.ssn_model.parameters()), lr=0.001)\n",
    "\n",
    "# Run the ELBO optimisation\n",
    "direct_fit.optimise_elbo(None, num_samples, num_epochs, optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFit:\n",
    "    def __init__(self, ssn_params, fogsm_params):\n",
    "        \n",
    "        self.ssn_model = SSN2DTopoV1(**ssn_params)\n",
    "\n",
    "        self.fogsm_model = FoGSMModel(**fogsm_params)\n",
    "\n",
    "    def sample_trajectories(self, input, num_samples, duration=500, dt=1):\n",
    "        trajectories = []\n",
    "        for _ in range(num_samples):\n",
    "            traj = self.ssn_model.run_simulation(input, duration, dt)\n",
    "            trajectories.append(traj)\n",
    "        return torch.stack(trajectories)\n",
    "\n",
    "    def calculate_log_p_g(self, trajectories):\n",
    "        mu = torch.zeros_like(trajectories[0])\n",
    "        log_p_g = MultivariateNormal(mu, self.fogsm_model.K_g).log_prob(trajectories).mean()\n",
    "        return log_p_g\n",
    "\n",
    "    def calculate_log_p_I_given_g(self, trajectories, num_samples_a=10):\n",
    "        # Sample amplitude fields from the prior p(A) using Monte Carlo sampling\n",
    "        amplitude_fields = [self.fogsm_model.compute_A() for _ in range(num_samples_a)]\n",
    "        \n",
    "        # Calculate log p(I|g,A) for each sample\n",
    "        log_likelihood = []\n",
    "        for a in amplitude_fields:\n",
    "            log_p = 0\n",
    "            for g in trajectories:\n",
    "                I = g * a\n",
    "                log_p += self.fogsm_model.log_likelihood(I)\n",
    "            log_likelihood.append(log_p / len(trajectories))\n",
    "        \n",
    "        # Approximate the expectation over A using Monte Carlo sampling\n",
    "        p_I_given_g = torch.exp(torch.stack(log_likelihood)).mean()\n",
    "        log_p_I_given_g = torch.log(p_I_given_g)\n",
    "\n",
    "        return log_p_I_given_g\n",
    "\n",
    "    def calculate_elbo(self, input, num_samples, duration=500, dt=1):\n",
    "        # Sample trajectories from the SSN\n",
    "        trajectories = self.sample_trajectories(input, num_samples, duration, dt)\n",
    "        \n",
    "        # Calculate the first two terms of the ELBO using Monte Carlo approximation\n",
    "        log_p_g = self.calculate_log_p_g(trajectories)\n",
    "        log_p_I_given_g = self.calculate_log_p_I_given_g(trajectories)\n",
    "        \n",
    "        # Approximate the entropy term\n",
    "        cov_matrix = torch.cov(trajectories.reshape(num_samples, -1).T)\n",
    "        entropy_term = 0.5 * torch.logdet(cov_matrix)\n",
    "        \n",
    "        elbo = log_p_g + log_p_I_given_g - entropy_term\n",
    "        return elbo\n",
    "\n",
    "    def optimise_elbo(self, input, num_samples, num_epochs, optimizer):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Calculate the ELBO\n",
    "            elbo = self.calculate_elbo(input, num_samples)\n",
    "            \n",
    "            #resample As for each minibatch\n",
    "\n",
    "            # Optimise the ELBO with respect to the model parameters\n",
    "            elbo.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Print the ELBO for monitoring\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], ELBO: {elbo.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
